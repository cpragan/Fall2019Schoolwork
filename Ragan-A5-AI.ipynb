{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC471 Artificial Intelligence\n",
    "\n",
    "# Assignment-5: Classification and Regression with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Connor Ragan AN72374* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have learned the fundamentals of Neural Networks and Deep Learning. You have also learned how to train them based on the techniques discussed in lectures and the contents from Chapter 10 of the textbook (and you'll learn more on training deep neural networks in Chapter 11).\n",
    "\n",
    "In Part I of this assignment, you are going to build a NN for classification. In Part II, you will build a NN for regression.\n",
    "\n",
    "Pedagogically, this assignment will help you:\n",
    "- better understand Neural Networks.\n",
    "\n",
    "- practice with Tensorflow and Keras API.\n",
    "\n",
    "- practice the skills you learned in sklearn and combine them with tf/keras to use in your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you should have Tensorflow version 2.0 installed and ready.\n",
    "\n",
    "Alternatively, you may complete the assignment in [Colab](https://colab.research.google.com) but you need to run the following magic command in Colab to switch to version 2.0:\n",
    "\n",
    "`%tensorflow_version 2.x`\n",
    "\n",
    "<b>Important Notice:</b> Some outputs/plots are shared with you in this notebook for your reference. Some outputs are intentionally not shared. Notice that it is the strict course policy NOT to include any (or even parts) of the code solutions and/or answers to the questions in your posts in Piazza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python/tf/keras modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf Version:  2.0.0\n",
      "Eager Execution mode:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"tf Version: \", tf.__version__)\n",
    "print(\"Eager Execution mode: \", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - Classification with NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, [download the data](https://github.com/fereydoonvafaei/UMBC-CMSC-471-Fall-2019/blob/master/Assignment-5/diabetes.csv) `diabetes.csv` The target is to predict the onset of diabetes based on patient's features. You can read more about the data [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load diabetes data with Pandas, it should be in the same working directory.\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "# Create X, y - Notice that X should contain all the features (columns) except 'Outcome'\n",
    "# y should include only 'Outcome' because it's the label!\n",
    "### START CODING HERE ###\n",
    "X = df.drop(columns='Outcome')\n",
    "y = df['Outcome']\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8)\n",
      "(514,)\n",
      "(254, 8)\n",
      "(254,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data to train and test with test_size=0.33 and random_state=66\n",
    "### START CODING HERE ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are different ways to load the data into tf tensors depeneding on your data type (image, text, etc). The following cell is one way of loading pandas dataframes to tensorflow tensors so that you can use tf/keras methods on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data to tf\n",
    "train_tensor = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "test_tensor = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [ 10.    115.     98.      0.      0.     24.      1.022  34.   ], Target: 0\n",
      "Features: [  7.    142.     60.     33.    190.     28.8     0.687  61.   ], Target: 0\n",
      "Features: [  4.    116.     72.     12.     87.     22.1     0.463  37.   ], Target: 0\n",
      "Features: [  1.    126.     60.      0.      0.     30.1     0.349  47.   ], Target: 1\n",
      "Features: [ 3.   78.   70.    0.    0.   32.5   0.27 39.  ], Target: 0\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in train_tensor.take(5):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As discussed in the lectures, data is fed into the network in batches (mini-batches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "# Batch train and test data\n",
    "train_batch = train_tensor.shuffle(len(X_train)).batch(1)\n",
    "test_batch = test_tensor.shuffle(len(X_test)).batch(1)\n",
    "\n",
    "print(type(train_batch))\n",
    "print(type(test_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Now, build the model based on the given architecture specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "# Build a Sequential neural network - a classifier model\n",
    "nn_clf = tf.keras.Sequential([\n",
    "    # Create a dense layer with 12 units, input_dim=8, and 'relu' activation function ~ 1 line\n",
    "    tf.keras.layers.Dense(12, input_dim=8, activation='relu'),\n",
    "    # Create a dense layer with 8 units, and 'relu' activation function ~ 1 line\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    # Create a dense layer with ? unit(s), and '?' activation function ~ 1 line\n",
    "    # YOU should decide on the number of untis and the activation function for this last layer (output layer)\n",
    "    # Hint: What type of ML task is this problem?\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])  \n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "# Compile the model by 'adam' optimizer, 'binary_crossentropy' loss and 'accuracy' as metrics ~ 1 line\n",
    "nn_clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "514/514 [==============================] - 2s 4ms/step - loss: 1.2951 - accuracy: 0.6187\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s 821us/step - loss: 0.7835 - accuracy: 0.6518\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.7174 - accuracy: 0.6479\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s 818us/step - loss: 0.6993 - accuracy: 0.6498\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s 820us/step - loss: 0.6650 - accuracy: 0.6537\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s 836us/step - loss: 0.6642 - accuracy: 0.6751\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s 857us/step - loss: 0.6735 - accuracy: 0.6732\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s 836us/step - loss: 0.6332 - accuracy: 0.6595\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s 845us/step - loss: 0.6206 - accuracy: 0.6732\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.6278 - accuracy: 0.6595\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.6162 - accuracy: 0.6712\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.6146 - accuracy: 0.6537\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s 905us/step - loss: 0.6119 - accuracy: 0.6634\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s 884us/step - loss: 0.6114 - accuracy: 0.6790\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s 854us/step - loss: 0.6195 - accuracy: 0.6595\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s 895us/step - loss: 0.6101 - accuracy: 0.6770\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s 833us/step - loss: 0.6167 - accuracy: 0.6732\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s 857us/step - loss: 0.6105 - accuracy: 0.6732\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s 850us/step - loss: 0.6115 - accuracy: 0.6809\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s 821us/step - loss: 0.6099 - accuracy: 0.6732\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s 846us/step - loss: 0.5950 - accuracy: 0.6926\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s 852us/step - loss: 0.6039 - accuracy: 0.6809\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.5922 - accuracy: 0.6984\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s 810us/step - loss: 0.5953 - accuracy: 0.6887\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s 826us/step - loss: 0.5974 - accuracy: 0.6751\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s 841us/step - loss: 0.6032 - accuracy: 0.6770\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s 849us/step - loss: 0.6059 - accuracy: 0.6615\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s 917us/step - loss: 0.5968 - accuracy: 0.6868\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s 885us/step - loss: 0.5912 - accuracy: 0.6868\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s 867us/step - loss: 0.5888 - accuracy: 0.6848\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s 826us/step - loss: 0.5943 - accuracy: 0.6848\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s 846us/step - loss: 0.5878 - accuracy: 0.6984\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s 879us/step - loss: 0.5814 - accuracy: 0.6868\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s 825us/step - loss: 0.5924 - accuracy: 0.6751\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s 810us/step - loss: 0.5839 - accuracy: 0.7004\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s 852us/step - loss: 0.5726 - accuracy: 0.7082\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s 906us/step - loss: 0.5829 - accuracy: 0.7023\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s 857us/step - loss: 0.5922 - accuracy: 0.6984\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s 894us/step - loss: 0.5794 - accuracy: 0.6984\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s 867us/step - loss: 0.5708 - accuracy: 0.7354\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s 878us/step - loss: 0.5662 - accuracy: 0.7101\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s 892us/step - loss: 0.5680 - accuracy: 0.7023\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s 886us/step - loss: 0.5640 - accuracy: 0.7179\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s 862us/step - loss: 0.5735 - accuracy: 0.6965\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s 910us/step - loss: 0.5654 - accuracy: 0.7004\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s 865us/step - loss: 0.5640 - accuracy: 0.7082\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s 925us/step - loss: 0.5557 - accuracy: 0.7296\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s 854us/step - loss: 0.5677 - accuracy: 0.7043\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s 830us/step - loss: 0.5597 - accuracy: 0.7004\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.5677 - accuracy: 0.7140\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s 838us/step - loss: 0.5520 - accuracy: 0.7315\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s 848us/step - loss: 0.5663 - accuracy: 0.7257\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s 839us/step - loss: 0.5491 - accuracy: 0.7374\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s 862us/step - loss: 0.5579 - accuracy: 0.7257\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s 850us/step - loss: 0.5452 - accuracy: 0.7023\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s 841us/step - loss: 0.5594 - accuracy: 0.7082\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s 829us/step - loss: 0.5462 - accuracy: 0.7257\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s 861us/step - loss: 0.5445 - accuracy: 0.7237\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s 816us/step - loss: 0.5483 - accuracy: 0.7257\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s 814us/step - loss: 0.5344 - accuracy: 0.7412\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s 817us/step - loss: 0.5400 - accuracy: 0.7335\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s 850us/step - loss: 0.5400 - accuracy: 0.7276\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s 830us/step - loss: 0.5409 - accuracy: 0.7101\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s 842us/step - loss: 0.5421 - accuracy: 0.7432\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s 852us/step - loss: 0.5542 - accuracy: 0.7296\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s 819us/step - loss: 0.5397 - accuracy: 0.7393\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s 846us/step - loss: 0.5421 - accuracy: 0.7237\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s 886us/step - loss: 0.5409 - accuracy: 0.7140\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s 925us/step - loss: 0.5318 - accuracy: 0.7393\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s 959us/step - loss: 0.5243 - accuracy: 0.7335\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 1s 980us/step - loss: 0.5303 - accuracy: 0.7374\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s 877us/step - loss: 0.5352 - accuracy: 0.7412\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s 820us/step - loss: 0.5241 - accuracy: 0.7412\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s 834us/step - loss: 0.5256 - accuracy: 0.7354\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s 838us/step - loss: 0.5240 - accuracy: 0.7471\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s 841us/step - loss: 0.5243 - accuracy: 0.7451\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s 822us/step - loss: 0.5266 - accuracy: 0.7451\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s 831us/step - loss: 0.5200 - accuracy: 0.7315\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 853us/step - loss: 0.5266 - accuracy: 0.7218\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s 953us/step - loss: 0.5220 - accuracy: 0.7198\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s 882us/step - loss: 0.5263 - accuracy: 0.7451\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s 877us/step - loss: 0.5175 - accuracy: 0.7451\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s 950us/step - loss: 0.5111 - accuracy: 0.7432\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s 902us/step - loss: 0.5112 - accuracy: 0.7451\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s 873us/step - loss: 0.5108 - accuracy: 0.7412\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s 892us/step - loss: 0.5219 - accuracy: 0.7451\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s 871us/step - loss: 0.5099 - accuracy: 0.7549\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s 842us/step - loss: 0.5023 - accuracy: 0.7568\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s 885us/step - loss: 0.5019 - accuracy: 0.7393\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s 834us/step - loss: 0.5083 - accuracy: 0.7685\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s 877us/step - loss: 0.5036 - accuracy: 0.7490\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.5167 - accuracy: 0.7529\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s 871us/step - loss: 0.5085 - accuracy: 0.7451\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s 851us/step - loss: 0.5154 - accuracy: 0.7490\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s 835us/step - loss: 0.5117 - accuracy: 0.7335\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s 855us/step - loss: 0.5072 - accuracy: 0.7296\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s 884us/step - loss: 0.5057 - accuracy: 0.7393\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s 822us/step - loss: 0.5093 - accuracy: 0.7471\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s 836us/step - loss: 0.5088 - accuracy: 0.7257\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s 945us/step - loss: 0.5034 - accuracy: 0.7510\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s 884us/step - loss: 0.5119 - accuracy: 0.7471\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s 873us/step - loss: 0.4985 - accuracy: 0.7626\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s 865us/step - loss: 0.5045 - accuracy: 0.7568\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s 849us/step - loss: 0.4981 - accuracy: 0.7588\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s 855us/step - loss: 0.4989 - accuracy: 0.7451\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s 873us/step - loss: 0.5039 - accuracy: 0.7607\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s 832us/step - loss: 0.5032 - accuracy: 0.7588\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s 848us/step - loss: 0.5020 - accuracy: 0.7412\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s 881us/step - loss: 0.5053 - accuracy: 0.7646\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s 867us/step - loss: 0.4972 - accuracy: 0.7646\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s 832us/step - loss: 0.4934 - accuracy: 0.7607\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s 857us/step - loss: 0.4959 - accuracy: 0.7646\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s 839us/step - loss: 0.4941 - accuracy: 0.7685\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s 864us/step - loss: 0.4834 - accuracy: 0.7432\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s 826us/step - loss: 0.4890 - accuracy: 0.7607\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s 847us/step - loss: 0.4879 - accuracy: 0.7529\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s 854us/step - loss: 0.4961 - accuracy: 0.7412\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.4946 - accuracy: 0.7704\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.4764 - accuracy: 0.7782\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s 901us/step - loss: 0.4988 - accuracy: 0.7490\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s 882us/step - loss: 0.4851 - accuracy: 0.7782\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s 867us/step - loss: 0.4947 - accuracy: 0.7529\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s 822us/step - loss: 0.4856 - accuracy: 0.7607\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s 871us/step - loss: 0.4865 - accuracy: 0.7549\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.4888 - accuracy: 0.7549\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s 842us/step - loss: 0.4783 - accuracy: 0.7607\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s 826us/step - loss: 0.4888 - accuracy: 0.7432\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s 856us/step - loss: 0.4806 - accuracy: 0.7763\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s 843us/step - loss: 0.4895 - accuracy: 0.7685\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s 827us/step - loss: 0.4773 - accuracy: 0.7568\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s 847us/step - loss: 0.4880 - accuracy: 0.7782\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s 851us/step - loss: 0.4883 - accuracy: 0.7665\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s 826us/step - loss: 0.4811 - accuracy: 0.7646\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s 816us/step - loss: 0.4866 - accuracy: 0.7704\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s 833us/step - loss: 0.4864 - accuracy: 0.7685\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s 852us/step - loss: 0.4661 - accuracy: 0.7763\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s 834us/step - loss: 0.4802 - accuracy: 0.7704\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s 818us/step - loss: 0.4743 - accuracy: 0.7743\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s 820us/step - loss: 0.4700 - accuracy: 0.7665\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s 822us/step - loss: 0.4634 - accuracy: 0.7938\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s 828us/step - loss: 0.4619 - accuracy: 0.7588\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s 824us/step - loss: 0.4626 - accuracy: 0.7899\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s 873us/step - loss: 0.4615 - accuracy: 0.7840\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s 888us/step - loss: 0.4667 - accuracy: 0.7821\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s 820us/step - loss: 0.4651 - accuracy: 0.7607\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s 847us/step - loss: 0.4678 - accuracy: 0.7821\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s 878us/step - loss: 0.4663 - accuracy: 0.7879\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s 863us/step - loss: 0.4590 - accuracy: 0.7724\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s 830us/step - loss: 0.4689 - accuracy: 0.7977\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s 842us/step - loss: 0.4666 - accuracy: 0.7626\n"
     ]
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "# Fit nn_clf model on train_batch with 150 epochs\n",
    "nn_clf_history = nn_clf.fit(train_batch, epochs=150)\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `history` now contains values for `loss` and `accuracy` during training, let's plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(nn_clf_history.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "\n",
    "# set the y-axis range to [0-1]\n",
    "plt.gca().set_ylim(0, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 791us/step - loss: 0.5964 - accuracy: 0.7008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5964058039417076, 0.7007874]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "# evaluate nn_clf model on test_batch using .evaluate method\n",
    "nn_clf.evaluate(test_batch)\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, let's plot ROC curve for this neural network model. Recall from Assignment-4 that you need to get class probabilities, fpr and tpr. To get class probabilities, keras has `predict()` method. Notice that it's applied on `X_test` not `test_batch`. Alternatively, you can use `predict_proba()` method, similar to sklearn, which would generate identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "# Get class probabilities for nn - ignore the warning\n",
    "nn_preds = nn_clf.predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7959636 , 0.13920298, 0.21497205, 0.25881165, 0.6209048 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See class probabilities predicted by nn classifier\n",
    "nn_preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'False Positive Rate')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODING HERE ### \n",
    "# Plot ROC curve for nn_clf - Write as many lines of code as needed\n",
    "# Hint: check back your Assignment-4 code, you need to calculate tpr, fpr, thresholds\n",
    "# Plot should have all the elements that Assignment-4 ROC curves had, title, xlabel and ylabel, xlim & ylim\n",
    "# Plot should also have AUC_NN (roc_auc) shown on lower right\n",
    "nn_fpr, nn_tpr, nn_threshold = metrics.roc_curve(y_test, nn_preds)\n",
    "nn_roc_auc = metrics.auc(nn_fpr, nn_tpr)\n",
    "plt.title('ROC')\n",
    "plt.plot(nn_fpr, nn_tpr, 'b', label = 'AUC_NN = %0.2f' % nn_roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ANSWER THE FOLLOWING QUESTIONS HERE:</b><br>\n",
    "\n",
    "Q1 - If this problem was a multi-class classification, what activation function would you use for the output layer neurons? How many neurons would be required for the output layer for multi-class? What other hyperparameters of nn can you change in different tasks? Name at least 3 other hyperparameters. GIVE COMPLETE ANSWER!\n",
    "\n",
    "If this were a multi-class classification, the output layer would use Softmax as the activation function. A neuron would be required for each class in the classification. Other hyperparameters of the nn are learning rate, batch size, and the number of hidden layers & the number of neurons in those layers.\n",
    "\n",
    "Q2 - Change the batch number from 1 to 10. Would it improve or hurt the results? Make an argument with reasoning on your observation (you may consult with page 326 of the textbook).\n",
    "\n",
    "It would improve the results. A larger batch size is less prone to fluctuation, and the larger batch size will train the model faster because it updates the weights less frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Regression with NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will create a neural network to do a regression task.\n",
    "\n",
    "[Download the data from here](https://github.com/fereydoonvafaei/UMBC-CMSC-471-Fall-2019/blob/master/Assignment-5/auto.csv). This is cars dataset. You can read more about the data [here](https://archive.ics.uci.edu/ml/datasets/auto+mpg). The goal is predicting MPG based on other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   Model Year  Origin  \n",
       "0          70       1  \n",
       "1          70       1  \n",
       "2          70       1  \n",
       "3          70       1  \n",
       "4          70       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_data = pd.read_csv('auto.csv')\n",
    "print(auto_data.shape)\n",
    "auto_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPG             0\n",
       "Cylinders       0\n",
       "Displacement    0\n",
       "Horsepower      6\n",
       "Weight          0\n",
       "Acceleration    0\n",
       "Model Year      0\n",
       "Origin          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPG             0\n",
       "Cylinders       0\n",
       "Displacement    0\n",
       "Horsepower      0\n",
       "Weight          0\n",
       "Acceleration    0\n",
       "Model Year      0\n",
       "Origin          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODING HERE ### \n",
    "# Drop all na's using dataframe .dropna(inplace=True) method ~ 1 line\n",
    "auto_data.dropna(inplace=True)\n",
    "### END CODING HERE ###\n",
    "auto_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">For some datasets like this, a technique in data preprocessing is used to encode categorical features to dummy variables. Here, we convert <b>Origin</b> (which looks numeric but is actually categorical) using pandas [get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) method. This technique is one example of One Hot Encoding of categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   Model Year  Europe  Japan  USA  \n",
       "0          70       0      0    1  \n",
       "1          70       0      0    1  \n",
       "2          70       0      0    1  \n",
       "3          70       0      0    1  \n",
       "4          70       0      0    1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_data['Origin'] = auto_data['Origin'].map(lambda x: {1: 'USA', 2: 'Europe', 3: 'Japan'}.get(x))\n",
    "auto_data = pd.get_dummies(auto_data, prefix='', prefix_sep='')\n",
    "print(auto_data.shape)\n",
    "auto_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n",
      "(392,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n",
       "0          8         307.0       130.0  3504.0          12.0          70   \n",
       "1          8         350.0       165.0  3693.0          11.5          70   \n",
       "2          8         318.0       150.0  3436.0          11.0          70   \n",
       "3          8         304.0       150.0  3433.0          12.0          70   \n",
       "4          8         302.0       140.0  3449.0          10.5          70   \n",
       "\n",
       "   Europe  Japan  USA  \n",
       "0       0      0    1  \n",
       "1       0      0    1  \n",
       "2       0      0    1  \n",
       "3       0      0    1  \n",
       "4       0      0    1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODING HERE ### \n",
    "# Create X and y, X should contain all features except MPG column and y should only contain MPG column\n",
    "# Hint: You can use dataframe .pop() method, but you may need to create a deep copy of the dataframe first\n",
    "# There are usually multiple ways of doing these operations in pnadas dataframes\n",
    "X = auto_data.drop(columns='MPG')\n",
    "y = auto_data['MPG']\n",
    "### END CODING HERE ###\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>Note:</b> The original auto_data dataframe should remain the same and should still include MPG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   Model Year  Europe  Japan  USA  \n",
       "0          70       0      0    1  \n",
       "1          70       0      0    1  \n",
       "2          70       0      0    1  \n",
       "3          70       0      0    1  \n",
       "4          70       0      0    1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Normalization is a good pratice when you work with values with different ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.075915</td>\n",
       "      <td>0.663285</td>\n",
       "      <td>0.619748</td>\n",
       "      <td>-1.283618</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>-0.457538</td>\n",
       "      <td>-0.501749</td>\n",
       "      <td>0.773608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.486832</td>\n",
       "      <td>1.572585</td>\n",
       "      <td>0.842258</td>\n",
       "      <td>-1.464852</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>-0.457538</td>\n",
       "      <td>-0.501749</td>\n",
       "      <td>0.773608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.181033</td>\n",
       "      <td>1.182885</td>\n",
       "      <td>0.539692</td>\n",
       "      <td>-1.646086</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>-0.457538</td>\n",
       "      <td>-0.501749</td>\n",
       "      <td>0.773608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.047246</td>\n",
       "      <td>1.182885</td>\n",
       "      <td>0.536160</td>\n",
       "      <td>-1.283618</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>-0.457538</td>\n",
       "      <td>-0.501749</td>\n",
       "      <td>0.773608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.028134</td>\n",
       "      <td>0.923085</td>\n",
       "      <td>0.554997</td>\n",
       "      <td>-1.827320</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>-0.457538</td>\n",
       "      <td>-0.501749</td>\n",
       "      <td>0.773608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cylinders  Displacement  Horsepower    Weight  Acceleration  Model Year  \\\n",
       "0   1.482053      1.075915    0.663285  0.619748     -1.283618   -1.623241   \n",
       "1   1.482053      1.486832    1.572585  0.842258     -1.464852   -1.623241   \n",
       "2   1.482053      1.181033    1.182885  0.539692     -1.646086   -1.623241   \n",
       "3   1.482053      1.047246    1.182885  0.536160     -1.283618   -1.623241   \n",
       "4   1.482053      1.028134    0.923085  0.554997     -1.827320   -1.623241   \n",
       "\n",
       "     Europe     Japan       USA  \n",
       "0 -0.457538 -0.501749  0.773608  \n",
       "1 -0.457538 -0.501749  0.773608  \n",
       "2 -0.457538 -0.501749  0.773608  \n",
       "3 -0.457538 -0.501749  0.773608  \n",
       "4 -0.457538 -0.501749  0.773608  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize X \n",
    "X = (X - X.mean())/X.std()\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 9)\n",
      "(313,)\n",
      "(79, 9)\n",
      "(79,)\n"
     ]
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "# Split the data to train and test using train_test_split method with test_size=0.2 and random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ### \n",
    "# Build a neural network for regression\n",
    "nn_reg1 = tf.keras.Sequential([\n",
    "    # Create a dense layer with 64 neurons, 'relu' activation function and input_shape=[len(X_train.keys())]\n",
    "    tf.keras.layers.Dense(64, input_shape=[len(X_train.keys())], activation='relu'),\n",
    "    # Create a dense layer with 64 neurons and 'relu' activation function\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # Create a dense layer with ? neuron(s) and ? activation\n",
    "    # YOU should decide how many neuron(s) is/are needed and what activation function (if any) to use for output\n",
    "    # Hint: What type of ML task is this problem?\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is another way of defining the optimizer, you can pass learning_rate and other parameters to it.\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "### START CODING HERE ### \n",
    "# Compile nn_reg1 with 'mse' loss, optimizer=optimizer, metrics=['mae', 'mse']\n",
    "nn_reg1.compile(optimizer=optimizer, loss='mse', metrics=['mae','mse'])\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,865\n",
      "Trainable params: 4,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_reg1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 250 samples, validate on 63 samples\n",
      "Epoch 1/1000\n",
      "250/250 [==============================] - 0s 456us/sample - loss: 558.0719 - mae: 22.2321 - mse: 558.0720 - val_loss: 607.2926 - val_mae: 23.3596 - val_mse: 607.2925\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 502.6912 - mae: 20.8731 - mse: 502.6912 - val_loss: 553.3680 - val_mae: 22.1409 - val_mse: 553.3680\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 449.4547 - mae: 19.4866 - mse: 449.4547 - val_loss: 495.1366 - val_mae: 20.7590 - val_mse: 495.1366\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 393.9499 - mae: 17.9455 - mse: 393.9499 - val_loss: 432.9875 - val_mae: 19.1866 - val_mse: 432.9875\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 335.6201 - mae: 16.2110 - mse: 335.6201 - val_loss: 365.6902 - val_mae: 17.4253 - val_mse: 365.6902\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 274.7455 - mae: 14.4031 - mse: 274.7455 - val_loss: 295.4923 - val_mae: 15.5789 - val_mse: 295.4923\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 214.4542 - mae: 12.6004 - mse: 214.4542 - val_loss: 225.8641 - val_mae: 13.5879 - val_mse: 225.8642\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 157.6684 - mae: 10.7808 - mse: 157.6684 - val_loss: 160.8935 - val_mae: 11.4699 - val_mse: 160.8935\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 106.9722 - mae: 8.8728 - mse: 106.9722 - val_loss: 105.1413 - val_mae: 9.2326 - val_mse: 105.1413\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 67.2686 - mae: 6.8723 - mse: 67.2686 - val_loss: 64.7131 - val_mae: 7.1087 - val_mse: 64.7131\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 40.0033 - mae: 5.1746 - mse: 40.0033 - val_loss: 37.3057 - val_mae: 5.2159 - val_mse: 37.3057\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 24.8501 - mae: 3.8943 - mse: 24.8501 - val_loss: 24.4891 - val_mae: 4.1051 - val_mse: 24.4891\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 18.7453 - mae: 3.3602 - mse: 18.7453 - val_loss: 18.5382 - val_mae: 3.4883 - val_mse: 18.5382\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 16.0900 - mae: 3.0915 - mse: 16.0900 - val_loss: 15.6186 - val_mae: 3.1735 - val_mse: 15.6186\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 14.3722 - mae: 2.9328 - mse: 14.3722 - val_loss: 14.2106 - val_mae: 3.0317 - val_mse: 14.2106\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 13.3358 - mae: 2.8258 - mse: 13.3358 - val_loss: 11.8973 - val_mae: 2.6878 - val_mse: 11.8973\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 12.4933 - mae: 2.7147 - mse: 12.4933 - val_loss: 11.2636 - val_mae: 2.6273 - val_mse: 11.2636\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 11.3333 - mae: 2.5581 - mse: 11.3333 - val_loss: 9.9093 - val_mae: 2.3993 - val_mse: 9.9093\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 10.7645 - mae: 2.4829 - mse: 10.7645 - val_loss: 9.8875 - val_mae: 2.4366 - val_mse: 9.8875\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 10.1685 - mae: 2.3814 - mse: 10.1685 - val_loss: 8.4449 - val_mae: 2.1744 - val_mse: 8.4449\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 9.9647 - mae: 2.3725 - mse: 9.9647 - val_loss: 8.1165 - val_mae: 2.1425 - val_mse: 8.1165\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 9.3236 - mae: 2.2822 - mse: 9.3236 - val_loss: 7.8936 - val_mae: 2.0806 - val_mse: 7.8936\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 9.0946 - mae: 2.2318 - mse: 9.0946 - val_loss: 7.6273 - val_mae: 2.0358 - val_mse: 7.6273\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 8.8517 - mae: 2.1755 - mse: 8.8518 - val_loss: 7.2586 - val_mae: 1.9800 - val_mse: 7.2586\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 8.5173 - mae: 2.1353 - mse: 8.5173 - val_loss: 7.4757 - val_mae: 2.0093 - val_mse: 7.4757\n",
      "Epoch 26/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 8.3428 - mae: 2.0762 - mse: 8.3428 - val_loss: 6.9360 - val_mae: 1.8987 - val_mse: 6.9360\n",
      "Epoch 27/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 8.4773 - mae: 2.1216 - mse: 8.4773 - val_loss: 7.1586 - val_mae: 1.9554 - val_mse: 7.1586\n",
      "Epoch 28/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 8.1789 - mae: 2.1048 - mse: 8.1789 - val_loss: 7.0248 - val_mae: 1.9230 - val_mse: 7.0248\n",
      "Epoch 29/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 8.0355 - mae: 2.0408 - mse: 8.0355 - val_loss: 7.5052 - val_mae: 2.0113 - val_mse: 7.5052\n",
      "Epoch 30/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 7.8537 - mae: 2.0443 - mse: 7.8537 - val_loss: 6.9663 - val_mae: 1.9421 - val_mse: 6.9663\n",
      "Epoch 31/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 7.9889 - mae: 2.0597 - mse: 7.9889 - val_loss: 6.8845 - val_mae: 1.9102 - val_mse: 6.8845\n",
      "Epoch 32/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 7.6409 - mae: 2.0025 - mse: 7.6409 - val_loss: 6.6342 - val_mae: 1.8572 - val_mse: 6.6342\n",
      "Epoch 33/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 7.7204 - mae: 2.0053 - mse: 7.7204 - val_loss: 7.7182 - val_mae: 2.0407 - val_mse: 7.7182\n",
      "Epoch 34/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 7.7370 - mae: 2.0076 - mse: 7.7370 - val_loss: 6.7574 - val_mae: 1.8894 - val_mse: 6.7574\n",
      "Epoch 35/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 7.4339 - mae: 1.9815 - mse: 7.4339 - val_loss: 6.7117 - val_mae: 1.8911 - val_mse: 6.7117\n",
      "Epoch 36/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 7.5133 - mae: 1.9979 - mse: 7.5133 - val_loss: 7.0794 - val_mae: 1.9255 - val_mse: 7.0794\n",
      "Epoch 37/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 7.5496 - mae: 1.9749 - mse: 7.5496 - val_loss: 6.6880 - val_mae: 1.8846 - val_mse: 6.6880\n",
      "Epoch 38/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 7.3791 - mae: 1.9468 - mse: 7.3791 - val_loss: 6.5498 - val_mae: 1.8349 - val_mse: 6.5498\n",
      "Epoch 39/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 7.4569 - mae: 2.0168 - mse: 7.4569 - val_loss: 6.9891 - val_mae: 1.9020 - val_mse: 6.9891\n",
      "Epoch 40/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 7.4656 - mae: 1.9843 - mse: 7.4656 - val_loss: 6.4156 - val_mae: 1.8286 - val_mse: 6.4156\n",
      "Epoch 41/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 7.2652 - mae: 1.9375 - mse: 7.2652 - val_loss: 7.2286 - val_mae: 1.9530 - val_mse: 7.2286\n",
      "Epoch 42/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 7.4911 - mae: 1.9685 - mse: 7.4911 - val_loss: 6.7512 - val_mae: 1.8704 - val_mse: 6.7512\n",
      "Epoch 43/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 7.3264 - mae: 1.9445 - mse: 7.3264 - val_loss: 7.0874 - val_mae: 1.9334 - val_mse: 7.0874\n",
      "Epoch 44/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 7.1177 - mae: 1.9248 - mse: 7.1177 - val_loss: 7.1837 - val_mae: 1.9324 - val_mse: 7.1837\n",
      "Epoch 45/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 7.2880 - mae: 1.9392 - mse: 7.2880 - val_loss: 6.9442 - val_mae: 1.8958 - val_mse: 6.9442\n",
      "Epoch 46/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 7.0255 - mae: 1.9300 - mse: 7.0255 - val_loss: 6.3761 - val_mae: 1.8204 - val_mse: 6.3761\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 36us/sample - loss: 7.1327 - mae: 1.9137 - mse: 7.1327 - val_loss: 6.6839 - val_mae: 1.8743 - val_mse: 6.6839\n",
      "Epoch 48/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 7.0700 - mae: 1.9105 - mse: 7.0700 - val_loss: 6.2960 - val_mae: 1.8110 - val_mse: 6.2960\n",
      "Epoch 49/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 7.0003 - mae: 1.9162 - mse: 7.0003 - val_loss: 6.8421 - val_mae: 1.8929 - val_mse: 6.8421\n",
      "Epoch 50/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 7.0144 - mae: 1.9066 - mse: 7.0144 - val_loss: 6.7591 - val_mae: 1.8851 - val_mse: 6.7591\n",
      "Epoch 51/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 7.0947 - mae: 1.9242 - mse: 7.0947 - val_loss: 6.4875 - val_mae: 1.8444 - val_mse: 6.4875\n",
      "Epoch 52/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 7.1233 - mae: 1.9432 - mse: 7.1233 - val_loss: 6.7950 - val_mae: 1.8856 - val_mse: 6.7950\n",
      "Epoch 53/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 6.9728 - mae: 1.9105 - mse: 6.9728 - val_loss: 6.8093 - val_mae: 1.8861 - val_mse: 6.8093\n",
      "Epoch 54/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 6.8068 - mae: 1.8573 - mse: 6.8068 - val_loss: 6.8124 - val_mae: 1.8890 - val_mse: 6.8124\n",
      "Epoch 55/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.9406 - mae: 1.8930 - mse: 6.9406 - val_loss: 6.1460 - val_mae: 1.7914 - val_mse: 6.1460\n",
      "Epoch 56/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.7640 - mae: 1.8988 - mse: 6.7640 - val_loss: 6.9741 - val_mae: 1.9068 - val_mse: 6.9741\n",
      "Epoch 57/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.8650 - mae: 1.8936 - mse: 6.8650 - val_loss: 7.3064 - val_mae: 1.9739 - val_mse: 7.3064\n",
      "Epoch 58/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.7241 - mae: 1.8604 - mse: 6.7241 - val_loss: 6.7788 - val_mae: 1.8952 - val_mse: 6.7788\n",
      "Epoch 59/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.8038 - mae: 1.8653 - mse: 6.8038 - val_loss: 6.5995 - val_mae: 1.8749 - val_mse: 6.5995\n",
      "Epoch 60/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.6399 - mae: 1.8397 - mse: 6.6399 - val_loss: 6.0837 - val_mae: 1.8051 - val_mse: 6.0837\n",
      "Epoch 61/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 6.6983 - mae: 1.8537 - mse: 6.6983 - val_loss: 6.4222 - val_mae: 1.8428 - val_mse: 6.4222\n",
      "Epoch 62/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.6541 - mae: 1.8650 - mse: 6.6541 - val_loss: 6.8971 - val_mae: 1.9057 - val_mse: 6.8971\n",
      "Epoch 63/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.6643 - mae: 1.8582 - mse: 6.6643 - val_loss: 6.1255 - val_mae: 1.8039 - val_mse: 6.1255\n",
      "Epoch 64/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.8830 - mae: 1.8729 - mse: 6.8830 - val_loss: 6.3856 - val_mae: 1.8402 - val_mse: 6.3856\n",
      "Epoch 65/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.6008 - mae: 1.8409 - mse: 6.6008 - val_loss: 7.1063 - val_mae: 1.9388 - val_mse: 7.1063\n",
      "Epoch 66/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.5392 - mae: 1.7967 - mse: 6.5392 - val_loss: 6.0456 - val_mae: 1.7908 - val_mse: 6.0456\n",
      "Epoch 67/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.5660 - mae: 1.8304 - mse: 6.5660 - val_loss: 7.5921 - val_mae: 2.0232 - val_mse: 7.5921\n",
      "Epoch 68/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 6.5758 - mae: 1.8453 - mse: 6.5758 - val_loss: 6.3211 - val_mae: 1.8369 - val_mse: 6.3211\n",
      "Epoch 69/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.6995 - mae: 1.8548 - mse: 6.6995 - val_loss: 6.1275 - val_mae: 1.8037 - val_mse: 6.1275\n",
      "Epoch 70/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.4633 - mae: 1.7995 - mse: 6.4633 - val_loss: 6.0894 - val_mae: 1.7891 - val_mse: 6.0894\n",
      "Epoch 71/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.6129 - mae: 1.8525 - mse: 6.6129 - val_loss: 6.4028 - val_mae: 1.8442 - val_mse: 6.4028\n",
      "Epoch 72/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.4906 - mae: 1.8248 - mse: 6.4906 - val_loss: 6.4681 - val_mae: 1.8651 - val_mse: 6.4681\n",
      "Epoch 73/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.4837 - mae: 1.8374 - mse: 6.4837 - val_loss: 6.3641 - val_mae: 1.8491 - val_mse: 6.3641\n",
      "Epoch 74/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.5348 - mae: 1.8255 - mse: 6.5348 - val_loss: 6.4131 - val_mae: 1.8511 - val_mse: 6.4131\n",
      "Epoch 75/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.4789 - mae: 1.8197 - mse: 6.4789 - val_loss: 6.2021 - val_mae: 1.8159 - val_mse: 6.2021\n",
      "Epoch 76/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.4813 - mae: 1.8481 - mse: 6.4813 - val_loss: 6.3878 - val_mae: 1.8466 - val_mse: 6.3878\n",
      "Epoch 77/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 6.4510 - mae: 1.8318 - mse: 6.4510 - val_loss: 6.2062 - val_mae: 1.8064 - val_mse: 6.2062\n",
      "Epoch 78/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.4243 - mae: 1.8019 - mse: 6.4243 - val_loss: 5.9794 - val_mae: 1.7652 - val_mse: 5.9794\n",
      "Epoch 79/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.4108 - mae: 1.8171 - mse: 6.4108 - val_loss: 6.2360 - val_mae: 1.8285 - val_mse: 6.2360\n",
      "Epoch 80/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.2947 - mae: 1.7856 - mse: 6.2947 - val_loss: 7.0109 - val_mae: 1.9009 - val_mse: 7.0109\n",
      "Epoch 81/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 6.3300 - mae: 1.7993 - mse: 6.3300 - val_loss: 5.9207 - val_mae: 1.7815 - val_mse: 5.9207\n",
      "Epoch 82/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.4080 - mae: 1.8120 - mse: 6.4080 - val_loss: 5.8765 - val_mae: 1.7623 - val_mse: 5.8765\n",
      "Epoch 83/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.5863 - mae: 1.8258 - mse: 6.5863 - val_loss: 5.9132 - val_mae: 1.7813 - val_mse: 5.9132\n",
      "Epoch 84/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.1921 - mae: 1.7844 - mse: 6.1921 - val_loss: 6.5632 - val_mae: 1.8789 - val_mse: 6.5632\n",
      "Epoch 85/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.2847 - mae: 1.7970 - mse: 6.2847 - val_loss: 7.1045 - val_mae: 1.9424 - val_mse: 7.1045\n",
      "Epoch 86/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.5614 - mae: 1.8393 - mse: 6.5614 - val_loss: 6.7044 - val_mae: 1.8731 - val_mse: 6.7044\n",
      "Epoch 87/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.1446 - mae: 1.7744 - mse: 6.1446 - val_loss: 7.1989 - val_mae: 1.9604 - val_mse: 7.1989\n",
      "Epoch 88/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.0589 - mae: 1.7540 - mse: 6.0589 - val_loss: 5.8594 - val_mae: 1.7577 - val_mse: 5.8594\n",
      "Epoch 89/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.1491 - mae: 1.7658 - mse: 6.1491 - val_loss: 6.0650 - val_mae: 1.8046 - val_mse: 6.0650\n",
      "Epoch 90/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 6.3544 - mae: 1.7998 - mse: 6.3544 - val_loss: 6.6303 - val_mae: 1.8961 - val_mse: 6.6303\n",
      "Epoch 91/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.1218 - mae: 1.7778 - mse: 6.1218 - val_loss: 6.4345 - val_mae: 1.8181 - val_mse: 6.4345\n",
      "Epoch 92/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.0611 - mae: 1.7554 - mse: 6.0611 - val_loss: 7.3317 - val_mae: 1.9728 - val_mse: 7.3317\n",
      "Epoch 93/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.3705 - mae: 1.8122 - mse: 6.3705 - val_loss: 6.7090 - val_mae: 1.8617 - val_mse: 6.7090\n",
      "Epoch 94/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.0874 - mae: 1.7637 - mse: 6.0874 - val_loss: 5.9381 - val_mae: 1.7730 - val_mse: 5.9381\n",
      "Epoch 95/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 48us/sample - loss: 6.1789 - mae: 1.7613 - mse: 6.1789 - val_loss: 5.9494 - val_mae: 1.7766 - val_mse: 5.9494\n",
      "Epoch 96/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.2221 - mae: 1.7829 - mse: 6.2221 - val_loss: 5.7671 - val_mae: 1.7438 - val_mse: 5.7671\n",
      "Epoch 97/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.2912 - mae: 1.7801 - mse: 6.2912 - val_loss: 5.9466 - val_mae: 1.7703 - val_mse: 5.9466\n",
      "Epoch 98/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.0742 - mae: 1.7641 - mse: 6.0742 - val_loss: 5.7379 - val_mae: 1.7403 - val_mse: 5.7379\n",
      "Epoch 99/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.1022 - mae: 1.7921 - mse: 6.1022 - val_loss: 6.5137 - val_mae: 1.8610 - val_mse: 6.5137\n",
      "Epoch 100/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.9413 - mae: 1.7585 - mse: 5.9413 - val_loss: 6.5044 - val_mae: 1.8518 - val_mse: 6.5044\n",
      "Epoch 101/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.2137 - mae: 1.7617 - mse: 6.2137 - val_loss: 6.5927 - val_mae: 1.8420 - val_mse: 6.5927\n",
      "Epoch 102/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.1314 - mae: 1.7457 - mse: 6.1314 - val_loss: 6.3135 - val_mae: 1.8232 - val_mse: 6.3135\n",
      "Epoch 103/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.9843 - mae: 1.7679 - mse: 5.9843 - val_loss: 6.6299 - val_mae: 1.8457 - val_mse: 6.6299\n",
      "Epoch 104/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 6.0994 - mae: 1.7567 - mse: 6.0994 - val_loss: 5.8953 - val_mae: 1.7595 - val_mse: 5.8953\n",
      "Epoch 105/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.0065 - mae: 1.7639 - mse: 6.0065 - val_loss: 6.2585 - val_mae: 1.8128 - val_mse: 6.2585\n",
      "Epoch 106/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.9688 - mae: 1.7254 - mse: 5.9688 - val_loss: 7.2754 - val_mae: 1.9599 - val_mse: 7.2754\n",
      "Epoch 107/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.0565 - mae: 1.7625 - mse: 6.0565 - val_loss: 5.9675 - val_mae: 1.7791 - val_mse: 5.9675\n",
      "Epoch 108/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.0423 - mae: 1.7474 - mse: 6.0423 - val_loss: 6.5588 - val_mae: 1.8401 - val_mse: 6.5588\n",
      "Epoch 109/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 6.2255 - mae: 1.7743 - mse: 6.2255 - val_loss: 5.7014 - val_mae: 1.7287 - val_mse: 5.7014\n",
      "Epoch 110/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.8629 - mae: 1.7306 - mse: 5.8629 - val_loss: 6.0095 - val_mae: 1.8019 - val_mse: 6.0095\n",
      "Epoch 111/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.8769 - mae: 1.7452 - mse: 5.8769 - val_loss: 6.4643 - val_mae: 1.8418 - val_mse: 6.4643\n",
      "Epoch 112/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 6.0149 - mae: 1.7438 - mse: 6.0149 - val_loss: 6.0214 - val_mae: 1.7832 - val_mse: 6.0214\n",
      "Epoch 113/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.9735 - mae: 1.7391 - mse: 5.9735 - val_loss: 5.7165 - val_mae: 1.7511 - val_mse: 5.7165\n",
      "Epoch 114/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 6.0583 - mae: 1.7677 - mse: 6.0583 - val_loss: 7.1492 - val_mae: 1.9327 - val_mse: 7.1492\n",
      "Epoch 115/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.8620 - mae: 1.7085 - mse: 5.8620 - val_loss: 5.7571 - val_mae: 1.7502 - val_mse: 5.7571\n",
      "Epoch 116/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.9642 - mae: 1.7390 - mse: 5.9642 - val_loss: 5.9041 - val_mae: 1.7627 - val_mse: 5.9041\n",
      "Epoch 117/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.0428 - mae: 1.7373 - mse: 6.0428 - val_loss: 6.1486 - val_mae: 1.8034 - val_mse: 6.1486\n",
      "Epoch 118/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 6.1396 - mae: 1.7557 - mse: 6.1396 - val_loss: 6.0749 - val_mae: 1.7904 - val_mse: 6.0749\n",
      "Epoch 119/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.8481 - mae: 1.7238 - mse: 5.8481 - val_loss: 5.8756 - val_mae: 1.7685 - val_mse: 5.8756\n",
      "Epoch 120/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.9838 - mae: 1.7548 - mse: 5.9838 - val_loss: 6.4878 - val_mae: 1.8249 - val_mse: 6.4878\n",
      "Epoch 121/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.7891 - mae: 1.7143 - mse: 5.7891 - val_loss: 6.0260 - val_mae: 1.7732 - val_mse: 6.0260\n",
      "Epoch 122/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.9713 - mae: 1.7399 - mse: 5.9713 - val_loss: 6.3338 - val_mae: 1.8186 - val_mse: 6.3338\n",
      "Epoch 123/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.9128 - mae: 1.7221 - mse: 5.9128 - val_loss: 6.4939 - val_mae: 1.8364 - val_mse: 6.4939\n",
      "Epoch 124/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.8161 - mae: 1.7229 - mse: 5.8161 - val_loss: 6.4612 - val_mae: 1.8349 - val_mse: 6.4612\n",
      "Epoch 125/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 6.1360 - mae: 1.7603 - mse: 6.1360 - val_loss: 6.3165 - val_mae: 1.8193 - val_mse: 6.3165\n",
      "Epoch 126/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.8721 - mae: 1.7077 - mse: 5.8721 - val_loss: 5.9110 - val_mae: 1.7669 - val_mse: 5.9110\n",
      "Epoch 127/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.7428 - mae: 1.7010 - mse: 5.7428 - val_loss: 6.6764 - val_mae: 1.8519 - val_mse: 6.6764\n",
      "Epoch 128/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.9901 - mae: 1.7484 - mse: 5.9901 - val_loss: 6.7189 - val_mae: 1.8498 - val_mse: 6.7189\n",
      "Epoch 129/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.8775 - mae: 1.7125 - mse: 5.8775 - val_loss: 5.6932 - val_mae: 1.7364 - val_mse: 5.6932\n",
      "Epoch 130/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.6518 - mae: 1.7327 - mse: 5.6518 - val_loss: 6.8537 - val_mae: 1.8699 - val_mse: 6.8537\n",
      "Epoch 131/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.8636 - mae: 1.7154 - mse: 5.8636 - val_loss: 5.6249 - val_mae: 1.7323 - val_mse: 5.6249\n",
      "Epoch 132/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.9598 - mae: 1.7566 - mse: 5.9598 - val_loss: 5.7001 - val_mae: 1.7431 - val_mse: 5.7001\n",
      "Epoch 133/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.6886 - mae: 1.7196 - mse: 5.6886 - val_loss: 6.5531 - val_mae: 1.8339 - val_mse: 6.5531\n",
      "Epoch 134/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.6696 - mae: 1.6936 - mse: 5.6696 - val_loss: 6.2859 - val_mae: 1.8331 - val_mse: 6.2859\n",
      "Epoch 135/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.8472 - mae: 1.6835 - mse: 5.8472 - val_loss: 5.7728 - val_mae: 1.7549 - val_mse: 5.7728\n",
      "Epoch 136/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.8023 - mae: 1.7227 - mse: 5.8023 - val_loss: 5.8950 - val_mae: 1.7749 - val_mse: 5.8950\n",
      "Epoch 137/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.8215 - mae: 1.7191 - mse: 5.8215 - val_loss: 6.2915 - val_mae: 1.8064 - val_mse: 6.2915\n",
      "Epoch 138/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.6537 - mae: 1.7042 - mse: 5.6537 - val_loss: 7.0538 - val_mae: 1.9139 - val_mse: 7.0538\n",
      "Epoch 139/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.9027 - mae: 1.7206 - mse: 5.9027 - val_loss: 6.1336 - val_mae: 1.7869 - val_mse: 6.1336\n",
      "Epoch 140/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.6758 - mae: 1.6915 - mse: 5.6758 - val_loss: 5.6326 - val_mae: 1.7151 - val_mse: 5.6326\n",
      "Epoch 141/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.6579 - mae: 1.7359 - mse: 5.6579 - val_loss: 6.6946 - val_mae: 1.8660 - val_mse: 6.6946\n",
      "Epoch 142/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.5904 - mae: 1.6802 - mse: 5.5904 - val_loss: 5.7092 - val_mae: 1.7637 - val_mse: 5.7092\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 48us/sample - loss: 5.7820 - mae: 1.7332 - mse: 5.7820 - val_loss: 6.9653 - val_mae: 1.8899 - val_mse: 6.9653\n",
      "Epoch 144/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.8106 - mae: 1.7243 - mse: 5.8106 - val_loss: 6.8068 - val_mae: 1.8630 - val_mse: 6.8068\n",
      "Epoch 145/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.7218 - mae: 1.6977 - mse: 5.7218 - val_loss: 6.1009 - val_mae: 1.7965 - val_mse: 6.1009\n",
      "Epoch 146/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.8128 - mae: 1.7172 - mse: 5.8128 - val_loss: 5.8754 - val_mae: 1.7646 - val_mse: 5.8754\n",
      "Epoch 147/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.6470 - mae: 1.7165 - mse: 5.6470 - val_loss: 5.7406 - val_mae: 1.7557 - val_mse: 5.7406\n",
      "Epoch 148/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.9554 - mae: 1.7145 - mse: 5.9554 - val_loss: 6.3806 - val_mae: 1.8081 - val_mse: 6.3806\n",
      "Epoch 149/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.5227 - mae: 1.6732 - mse: 5.5227 - val_loss: 5.8062 - val_mae: 1.7498 - val_mse: 5.8062\n",
      "Epoch 150/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 5.6264 - mae: 1.6818 - mse: 5.6264 - val_loss: 6.4439 - val_mae: 1.8118 - val_mse: 6.4439\n",
      "Epoch 151/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.7783 - mae: 1.6944 - mse: 5.7783 - val_loss: 6.4438 - val_mae: 1.8083 - val_mse: 6.4438\n",
      "Epoch 152/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.7487 - mae: 1.6797 - mse: 5.7487 - val_loss: 6.2772 - val_mae: 1.8004 - val_mse: 6.2772\n",
      "Epoch 153/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.7688 - mae: 1.7120 - mse: 5.7688 - val_loss: 5.7393 - val_mae: 1.7564 - val_mse: 5.7393\n",
      "Epoch 154/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.7726 - mae: 1.7097 - mse: 5.7726 - val_loss: 6.6549 - val_mae: 1.8601 - val_mse: 6.6549\n",
      "Epoch 155/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.7134 - mae: 1.6906 - mse: 5.7134 - val_loss: 5.9710 - val_mae: 1.7695 - val_mse: 5.9710\n",
      "Epoch 156/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.7048 - mae: 1.7187 - mse: 5.7048 - val_loss: 6.2265 - val_mae: 1.7797 - val_mse: 6.2265\n",
      "Epoch 157/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.5606 - mae: 1.6787 - mse: 5.5606 - val_loss: 6.1513 - val_mae: 1.7982 - val_mse: 6.1513\n",
      "Epoch 158/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.6247 - mae: 1.6936 - mse: 5.6247 - val_loss: 6.1592 - val_mae: 1.7895 - val_mse: 6.1592\n",
      "Epoch 159/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.6483 - mae: 1.6860 - mse: 5.6483 - val_loss: 6.1207 - val_mae: 1.7871 - val_mse: 6.1207\n",
      "Epoch 160/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.5283 - mae: 1.6811 - mse: 5.5283 - val_loss: 6.4031 - val_mae: 1.8296 - val_mse: 6.4031\n",
      "Epoch 161/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.6745 - mae: 1.6859 - mse: 5.6745 - val_loss: 5.7211 - val_mae: 1.7352 - val_mse: 5.7211\n",
      "Epoch 162/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.5338 - mae: 1.6680 - mse: 5.5338 - val_loss: 5.7440 - val_mae: 1.7575 - val_mse: 5.7440\n",
      "Epoch 163/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.6472 - mae: 1.6865 - mse: 5.6472 - val_loss: 6.5084 - val_mae: 1.8161 - val_mse: 6.5084\n",
      "Epoch 164/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.5328 - mae: 1.6518 - mse: 5.5328 - val_loss: 5.6250 - val_mae: 1.7306 - val_mse: 5.6250\n",
      "Epoch 165/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.3830 - mae: 1.6380 - mse: 5.3830 - val_loss: 6.1737 - val_mae: 1.7803 - val_mse: 6.1737\n",
      "Epoch 166/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.5591 - mae: 1.6728 - mse: 5.5591 - val_loss: 5.5941 - val_mae: 1.7431 - val_mse: 5.5941\n",
      "Epoch 167/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.5144 - mae: 1.6519 - mse: 5.5144 - val_loss: 6.5705 - val_mae: 1.8328 - val_mse: 6.5705\n",
      "Epoch 168/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.4874 - mae: 1.6750 - mse: 5.4874 - val_loss: 7.2804 - val_mae: 1.9365 - val_mse: 7.2804\n",
      "Epoch 169/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.6031 - mae: 1.6897 - mse: 5.6031 - val_loss: 6.0547 - val_mae: 1.7772 - val_mse: 6.0547\n",
      "Epoch 170/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.7807 - mae: 1.6974 - mse: 5.7807 - val_loss: 6.5241 - val_mae: 1.8267 - val_mse: 6.5241\n",
      "Epoch 171/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.4014 - mae: 1.6678 - mse: 5.4014 - val_loss: 5.9955 - val_mae: 1.7837 - val_mse: 5.9955\n",
      "Epoch 172/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.6279 - mae: 1.6910 - mse: 5.6279 - val_loss: 5.9015 - val_mae: 1.7566 - val_mse: 5.9015\n",
      "Epoch 173/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.5245 - mae: 1.6696 - mse: 5.5245 - val_loss: 5.6348 - val_mae: 1.7321 - val_mse: 5.6348\n",
      "Epoch 174/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.5135 - mae: 1.6423 - mse: 5.5135 - val_loss: 5.9253 - val_mae: 1.7605 - val_mse: 5.9253\n",
      "Epoch 175/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.6443 - mae: 1.6814 - mse: 5.6443 - val_loss: 6.6086 - val_mae: 1.8486 - val_mse: 6.6086\n",
      "Epoch 176/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.5168 - mae: 1.6911 - mse: 5.5168 - val_loss: 6.6894 - val_mae: 1.8360 - val_mse: 6.6894\n",
      "Epoch 177/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.4346 - mae: 1.6658 - mse: 5.4346 - val_loss: 6.5408 - val_mae: 1.8320 - val_mse: 6.5408\n",
      "Epoch 178/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.4340 - mae: 1.6583 - mse: 5.4340 - val_loss: 5.9830 - val_mae: 1.7664 - val_mse: 5.9830\n",
      "Epoch 179/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.5687 - mae: 1.6669 - mse: 5.5687 - val_loss: 6.2705 - val_mae: 1.8129 - val_mse: 6.2705\n",
      "Epoch 180/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.5238 - mae: 1.6455 - mse: 5.5238 - val_loss: 5.6756 - val_mae: 1.7286 - val_mse: 5.6756\n",
      "Epoch 181/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.4045 - mae: 1.6387 - mse: 5.4045 - val_loss: 5.4938 - val_mae: 1.7217 - val_mse: 5.4938\n",
      "Epoch 182/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.7073 - mae: 1.6973 - mse: 5.7073 - val_loss: 5.9482 - val_mae: 1.7846 - val_mse: 5.9482\n",
      "Epoch 183/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.4066 - mae: 1.6439 - mse: 5.4066 - val_loss: 6.8122 - val_mae: 1.8609 - val_mse: 6.8122\n",
      "Epoch 184/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.9994 - mae: 1.8887 - mse: 5.999 - 0s 44us/sample - loss: 5.5007 - mae: 1.6498 - mse: 5.5007 - val_loss: 5.6664 - val_mae: 1.7451 - val_mse: 5.6664\n",
      "Epoch 185/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.4624 - mae: 1.6560 - mse: 5.4624 - val_loss: 6.5104 - val_mae: 1.8222 - val_mse: 6.5104\n",
      "Epoch 186/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0875 - mae: 1.6070 - mse: 5.0875 - val_loss: 5.6463 - val_mae: 1.8096 - val_mse: 5.6463\n",
      "Epoch 187/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 5.4810 - mae: 1.6596 - mse: 5.4810 - val_loss: 5.3808 - val_mae: 1.7327 - val_mse: 5.3808\n",
      "Epoch 188/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 5.5526 - mae: 1.6770 - mse: 5.5526 - val_loss: 6.5385 - val_mae: 1.8237 - val_mse: 6.5385\n",
      "Epoch 189/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.4205 - mae: 1.6265 - mse: 5.4205 - val_loss: 5.6162 - val_mae: 1.7289 - val_mse: 5.6162\n",
      "Epoch 190/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.3130 - mae: 1.6262 - mse: 5.3130 - val_loss: 5.7318 - val_mae: 1.7626 - val_mse: 5.7318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.4550 - mae: 1.6682 - mse: 5.4550 - val_loss: 5.6682 - val_mae: 1.7478 - val_mse: 5.6682\n",
      "Epoch 192/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.2344 - mae: 1.6141 - mse: 5.2344 - val_loss: 5.9769 - val_mae: 1.7586 - val_mse: 5.9769\n",
      "Epoch 193/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.3818 - mae: 1.6207 - mse: 5.3818 - val_loss: 5.8019 - val_mae: 1.7421 - val_mse: 5.8019\n",
      "Epoch 194/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.5096 - mae: 1.6812 - mse: 5.5096 - val_loss: 5.7193 - val_mae: 1.7634 - val_mse: 5.7193\n",
      "Epoch 195/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.4076 - mae: 1.6602 - mse: 5.4076 - val_loss: 5.6588 - val_mae: 1.7375 - val_mse: 5.6588\n",
      "Epoch 196/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 5.4573 - mae: 1.6683 - mse: 5.4573 - val_loss: 6.9806 - val_mae: 1.8978 - val_mse: 6.9806\n",
      "Epoch 197/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.3675 - mae: 1.6525 - mse: 5.3675 - val_loss: 6.8901 - val_mae: 1.8643 - val_mse: 6.8901\n",
      "Epoch 198/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.5436 - mae: 1.6824 - mse: 5.5436 - val_loss: 6.1091 - val_mae: 1.7735 - val_mse: 6.1091\n",
      "Epoch 199/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2191 - mae: 1.6085 - mse: 5.2191 - val_loss: 5.5612 - val_mae: 1.7320 - val_mse: 5.5612\n",
      "Epoch 200/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.6246 - mae: 1.6671 - mse: 5.6246 - val_loss: 5.8953 - val_mae: 1.7469 - val_mse: 5.8953\n",
      "Epoch 201/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.2236 - mae: 1.5891 - mse: 5.2236 - val_loss: 5.3823 - val_mae: 1.7053 - val_mse: 5.3823\n",
      "Epoch 202/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.4356 - mae: 1.6584 - mse: 5.4356 - val_loss: 5.9150 - val_mae: 1.7680 - val_mse: 5.9150\n",
      "Epoch 203/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.3529 - mae: 1.6454 - mse: 5.3529 - val_loss: 6.1782 - val_mae: 1.7860 - val_mse: 6.1782\n",
      "Epoch 204/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.6134 - mae: 1.6715 - mse: 5.6134 - val_loss: 5.7304 - val_mae: 1.7550 - val_mse: 5.7304\n",
      "Epoch 205/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2567 - mae: 1.6098 - mse: 5.2567 - val_loss: 5.5063 - val_mae: 1.7019 - val_mse: 5.5063\n",
      "Epoch 206/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.3282 - mae: 1.6149 - mse: 5.3282 - val_loss: 6.1045 - val_mae: 1.7783 - val_mse: 6.1045\n",
      "Epoch 207/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.3469 - mae: 1.6490 - mse: 5.3469 - val_loss: 6.0032 - val_mae: 1.7640 - val_mse: 6.0032\n",
      "Epoch 208/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2555 - mae: 1.6101 - mse: 5.2555 - val_loss: 5.7706 - val_mae: 1.7435 - val_mse: 5.7706\n",
      "Epoch 209/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.4030 - mae: 1.6487 - mse: 5.4030 - val_loss: 5.5858 - val_mae: 1.7368 - val_mse: 5.5858\n",
      "Epoch 210/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.5052 - mae: 1.6405 - mse: 5.5052 - val_loss: 6.2034 - val_mae: 1.7880 - val_mse: 6.2034\n",
      "Epoch 211/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.1889 - mae: 1.6118 - mse: 5.1889 - val_loss: 6.2381 - val_mae: 1.7742 - val_mse: 6.2381\n",
      "Epoch 212/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.3241 - mae: 1.6182 - mse: 5.3241 - val_loss: 6.2488 - val_mae: 1.7994 - val_mse: 6.2488\n",
      "Epoch 213/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.4028 - mae: 1.5943 - mse: 5.4028 - val_loss: 7.4099 - val_mae: 1.9361 - val_mse: 7.4099\n",
      "Epoch 214/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.3092 - mae: 1.6377 - mse: 5.3092 - val_loss: 7.1892 - val_mae: 1.9511 - val_mse: 7.1892\n",
      "Epoch 215/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.3100 - mae: 1.6194 - mse: 5.3100 - val_loss: 6.2989 - val_mae: 1.8293 - val_mse: 6.2989\n",
      "Epoch 216/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.3397 - mae: 1.6052 - mse: 5.3397 - val_loss: 5.5827 - val_mae: 1.7520 - val_mse: 5.5827\n",
      "Epoch 217/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2462 - mae: 1.6113 - mse: 5.2462 - val_loss: 5.4955 - val_mae: 1.7485 - val_mse: 5.4955\n",
      "Epoch 218/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.3635 - mae: 1.6118 - mse: 5.3635 - val_loss: 5.7793 - val_mae: 1.7428 - val_mse: 5.7793\n",
      "Epoch 219/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 5.3589 - mae: 1.6314 - mse: 5.3589 - val_loss: 5.5165 - val_mae: 1.7456 - val_mse: 5.5165\n",
      "Epoch 220/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.3031 - mae: 1.6158 - mse: 5.3031 - val_loss: 6.0742 - val_mae: 1.7942 - val_mse: 6.0742\n",
      "Epoch 221/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2208 - mae: 1.6134 - mse: 5.2208 - val_loss: 6.0447 - val_mae: 1.7609 - val_mse: 6.0447\n",
      "Epoch 222/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2429 - mae: 1.5998 - mse: 5.2429 - val_loss: 6.0783 - val_mae: 1.7778 - val_mse: 6.0783\n",
      "Epoch 223/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.1937 - mae: 1.5954 - mse: 5.1937 - val_loss: 6.2422 - val_mae: 1.7660 - val_mse: 6.2422\n",
      "Epoch 224/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2574 - mae: 1.6053 - mse: 5.2574 - val_loss: 5.5411 - val_mae: 1.7421 - val_mse: 5.5411\n",
      "Epoch 225/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.2898 - mae: 1.6411 - mse: 5.2898 - val_loss: 5.4518 - val_mae: 1.7137 - val_mse: 5.4518\n",
      "Epoch 226/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2435 - mae: 1.6376 - mse: 5.2435 - val_loss: 6.5807 - val_mae: 1.8099 - val_mse: 6.5807\n",
      "Epoch 227/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2239 - mae: 1.5961 - mse: 5.2239 - val_loss: 6.0131 - val_mae: 1.7548 - val_mse: 6.0131\n",
      "Epoch 228/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.3150 - mae: 1.6387 - mse: 5.3150 - val_loss: 5.7490 - val_mae: 1.7442 - val_mse: 5.7490\n",
      "Epoch 229/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.1502 - mae: 1.5814 - mse: 5.1502 - val_loss: 6.8137 - val_mae: 1.8340 - val_mse: 6.8137\n",
      "Epoch 230/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.3645 - mae: 1.5966 - mse: 5.3645 - val_loss: 5.7193 - val_mae: 1.7364 - val_mse: 5.7193\n",
      "Epoch 231/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2511 - mae: 1.5762 - mse: 5.2511 - val_loss: 5.5993 - val_mae: 1.7509 - val_mse: 5.5993\n",
      "Epoch 232/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.1813 - mae: 1.5826 - mse: 5.1813 - val_loss: 6.2354 - val_mae: 1.7948 - val_mse: 6.2354\n",
      "Epoch 233/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.2524 - mae: 1.5979 - mse: 5.2524 - val_loss: 6.0027 - val_mae: 1.7704 - val_mse: 6.0027\n",
      "Epoch 234/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.0799 - mae: 1.5926 - mse: 5.0799 - val_loss: 5.6910 - val_mae: 1.7598 - val_mse: 5.6910\n",
      "Epoch 235/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2754 - mae: 1.6293 - mse: 5.2754 - val_loss: 6.1469 - val_mae: 1.7732 - val_mse: 6.1469\n",
      "Epoch 236/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2885 - mae: 1.6270 - mse: 5.2885 - val_loss: 5.4638 - val_mae: 1.6991 - val_mse: 5.4638\n",
      "Epoch 237/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.1759 - mae: 1.5902 - mse: 5.1759 - val_loss: 6.7776 - val_mae: 1.8420 - val_mse: 6.7776\n",
      "Epoch 238/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.2675 - mae: 1.6215 - mse: 5.2675 - val_loss: 5.4562 - val_mae: 1.6946 - val_mse: 5.4562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.3269 - mae: 1.6285 - mse: 5.3269 - val_loss: 5.8723 - val_mae: 1.7444 - val_mse: 5.8723\n",
      "Epoch 240/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.0257 - mae: 1.5687 - mse: 5.0257 - val_loss: 6.5589 - val_mae: 1.8288 - val_mse: 6.5589\n",
      "Epoch 241/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8662 - mae: 1.5497 - mse: 4.8662 - val_loss: 5.4710 - val_mae: 1.7122 - val_mse: 5.4710\n",
      "Epoch 242/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.0514 - mae: 1.5888 - mse: 5.0514 - val_loss: 6.6534 - val_mae: 1.8491 - val_mse: 6.6534\n",
      "Epoch 243/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.1908 - mae: 1.6011 - mse: 5.1908 - val_loss: 5.5190 - val_mae: 1.7347 - val_mse: 5.5190\n",
      "Epoch 244/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.2184 - mae: 1.6157 - mse: 5.2184 - val_loss: 6.6107 - val_mae: 1.8136 - val_mse: 6.6107\n",
      "Epoch 245/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.2519 - mae: 1.5803 - mse: 5.2519 - val_loss: 5.6995 - val_mae: 1.7296 - val_mse: 5.6995\n",
      "Epoch 246/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.0935 - mae: 1.5706 - mse: 5.0935 - val_loss: 5.4953 - val_mae: 1.7299 - val_mse: 5.4953\n",
      "Epoch 247/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.2135 - mae: 1.6181 - mse: 5.2135 - val_loss: 6.3025 - val_mae: 1.8005 - val_mse: 6.3025\n",
      "Epoch 248/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.1410 - mae: 1.6054 - mse: 5.1410 - val_loss: 6.0167 - val_mae: 1.7742 - val_mse: 6.0167\n",
      "Epoch 249/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.0894 - mae: 1.5793 - mse: 5.0894 - val_loss: 5.9860 - val_mae: 1.7543 - val_mse: 5.9860\n",
      "Epoch 250/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.0799 - mae: 1.5744 - mse: 5.0799 - val_loss: 6.6376 - val_mae: 1.8155 - val_mse: 6.6376\n",
      "Epoch 251/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.1332 - mae: 1.5881 - mse: 5.1332 - val_loss: 6.8895 - val_mae: 1.8426 - val_mse: 6.8895\n",
      "Epoch 252/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.2354 - mae: 1.6048 - mse: 5.2354 - val_loss: 6.2361 - val_mae: 1.7809 - val_mse: 6.2361\n",
      "Epoch 253/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0729 - mae: 1.5859 - mse: 5.0729 - val_loss: 5.7707 - val_mae: 1.7286 - val_mse: 5.7707\n",
      "Epoch 254/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0723 - mae: 1.5570 - mse: 5.0723 - val_loss: 5.5653 - val_mae: 1.7052 - val_mse: 5.5653\n",
      "Epoch 255/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9509 - mae: 1.5882 - mse: 4.9509 - val_loss: 5.6422 - val_mae: 1.7735 - val_mse: 5.6422\n",
      "Epoch 256/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.1721 - mae: 1.6021 - mse: 5.1721 - val_loss: 5.6713 - val_mae: 1.7334 - val_mse: 5.6713\n",
      "Epoch 257/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 5.1357 - mae: 1.5743 - mse: 5.1357 - val_loss: 5.9817 - val_mae: 1.7565 - val_mse: 5.9817\n",
      "Epoch 258/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.2639 - mae: 1.6220 - mse: 5.2639 - val_loss: 6.2106 - val_mae: 1.7836 - val_mse: 6.2106\n",
      "Epoch 259/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.9348 - mae: 1.5421 - mse: 4.9348 - val_loss: 7.5543 - val_mae: 1.9603 - val_mse: 7.5543\n",
      "Epoch 260/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.3504 - mae: 1.6023 - mse: 5.3504 - val_loss: 6.3263 - val_mae: 1.7916 - val_mse: 6.3263\n",
      "Epoch 261/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.8889 - mae: 1.5367 - mse: 4.8889 - val_loss: 5.5728 - val_mae: 1.7281 - val_mse: 5.5728\n",
      "Epoch 262/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.1126 - mae: 1.5854 - mse: 5.1126 - val_loss: 5.5572 - val_mae: 1.7438 - val_mse: 5.5572\n",
      "Epoch 263/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0789 - mae: 1.5650 - mse: 5.0789 - val_loss: 5.7515 - val_mae: 1.7257 - val_mse: 5.7515\n",
      "Epoch 264/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0706 - mae: 1.5656 - mse: 5.0706 - val_loss: 5.8637 - val_mae: 1.7662 - val_mse: 5.8637\n",
      "Epoch 265/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.1017 - mae: 1.5335 - mse: 5.1017 - val_loss: 5.7042 - val_mae: 1.7441 - val_mse: 5.7042\n",
      "Epoch 266/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.8722 - mae: 1.5585 - mse: 4.8722 - val_loss: 7.5147 - val_mae: 1.9585 - val_mse: 7.5147\n",
      "Epoch 267/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 12.5558 - mae: 2.1694 - mse: 12.555 - 0s 48us/sample - loss: 5.3684 - mae: 1.6141 - mse: 5.3684 - val_loss: 5.7969 - val_mae: 1.7480 - val_mse: 5.7969\n",
      "Epoch 268/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0336 - mae: 1.5620 - mse: 5.0336 - val_loss: 5.5101 - val_mae: 1.7265 - val_mse: 5.5101\n",
      "Epoch 269/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.2011 - mae: 1.5893 - mse: 5.2011 - val_loss: 6.5230 - val_mae: 1.8166 - val_mse: 6.5230\n",
      "Epoch 270/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.0073 - mae: 1.5512 - mse: 5.0073 - val_loss: 6.2574 - val_mae: 1.8073 - val_mse: 6.2574\n",
      "Epoch 271/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 5.0050 - mae: 1.5882 - mse: 5.0050 - val_loss: 6.5499 - val_mae: 1.8152 - val_mse: 6.5499\n",
      "Epoch 272/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0158 - mae: 1.5713 - mse: 5.0158 - val_loss: 6.0961 - val_mae: 1.8003 - val_mse: 6.0961\n",
      "Epoch 273/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.9524 - mae: 1.5332 - mse: 4.9524 - val_loss: 5.6050 - val_mae: 1.7193 - val_mse: 5.6050\n",
      "Epoch 274/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0393 - mae: 1.5664 - mse: 5.0393 - val_loss: 5.6580 - val_mae: 1.7551 - val_mse: 5.6580\n",
      "Epoch 275/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.4086 - mae: 1.6486 - mse: 5.4086 - val_loss: 5.5146 - val_mae: 1.7699 - val_mse: 5.5146\n",
      "Epoch 276/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.1053 - mae: 1.5864 - mse: 5.1053 - val_loss: 5.8532 - val_mae: 1.7459 - val_mse: 5.8532\n",
      "Epoch 277/1000\n",
      "250/250 [==============================] - 0s 80us/sample - loss: 4.9481 - mae: 1.5374 - mse: 4.9481 - val_loss: 5.7399 - val_mae: 1.7466 - val_mse: 5.7399\n",
      "Epoch 278/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.9326 - mae: 1.5417 - mse: 4.9326 - val_loss: 6.4853 - val_mae: 1.8165 - val_mse: 6.4853\n",
      "Epoch 279/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.0866 - mae: 1.5718 - mse: 5.0866 - val_loss: 6.9086 - val_mae: 1.8945 - val_mse: 6.9086\n",
      "Epoch 280/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.9250 - mae: 1.5392 - mse: 4.9250 - val_loss: 5.5153 - val_mae: 1.7055 - val_mse: 5.5153\n",
      "Epoch 281/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.0357 - mae: 1.5738 - mse: 5.0357 - val_loss: 5.9140 - val_mae: 1.7611 - val_mse: 5.9140\n",
      "Epoch 282/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 5.0970 - mae: 1.5915 - mse: 5.0970 - val_loss: 6.7890 - val_mae: 1.8558 - val_mse: 6.7890\n",
      "Epoch 283/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.1315 - mae: 1.5826 - mse: 5.1315 - val_loss: 6.1767 - val_mae: 1.7860 - val_mse: 6.1767\n",
      "Epoch 284/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8591 - mae: 1.5480 - mse: 4.8591 - val_loss: 5.4839 - val_mae: 1.7138 - val_mse: 5.4839\n",
      "Epoch 285/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.1247 - mae: 1.5702 - mse: 5.1247 - val_loss: 5.7959 - val_mae: 1.7653 - val_mse: 5.7959\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 40us/sample - loss: 4.9071 - mae: 1.5714 - mse: 4.9071 - val_loss: 6.7120 - val_mae: 1.8442 - val_mse: 6.7120\n",
      "Epoch 287/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.0789 - mae: 1.5499 - mse: 5.0789 - val_loss: 5.8343 - val_mae: 1.7414 - val_mse: 5.8343\n",
      "Epoch 288/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.8898 - mae: 1.5314 - mse: 4.8898 - val_loss: 6.8382 - val_mae: 1.8703 - val_mse: 6.8382\n",
      "Epoch 289/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 5.1147 - mae: 1.5770 - mse: 5.1147 - val_loss: 6.1246 - val_mae: 1.7589 - val_mse: 6.1246\n",
      "Epoch 290/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.8447 - mae: 1.5253 - mse: 4.8447 - val_loss: 6.1477 - val_mae: 1.7728 - val_mse: 6.1477\n",
      "Epoch 291/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9131 - mae: 1.5653 - mse: 4.9131 - val_loss: 5.5203 - val_mae: 1.7268 - val_mse: 5.5203\n",
      "Epoch 292/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.1322 - mae: 1.5735 - mse: 5.1322 - val_loss: 6.2983 - val_mae: 1.8184 - val_mse: 6.2983\n",
      "Epoch 293/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0175 - mae: 1.5519 - mse: 5.0175 - val_loss: 5.6594 - val_mae: 1.7604 - val_mse: 5.6594\n",
      "Epoch 294/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.9083 - mae: 1.5286 - mse: 4.9083 - val_loss: 5.5980 - val_mae: 1.7295 - val_mse: 5.5980\n",
      "Epoch 295/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0032 - mae: 1.5450 - mse: 5.0032 - val_loss: 5.7853 - val_mae: 1.7530 - val_mse: 5.7853\n",
      "Epoch 296/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.0656 - mae: 1.5650 - mse: 5.0656 - val_loss: 6.4028 - val_mae: 1.8147 - val_mse: 6.4028\n",
      "Epoch 297/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9712 - mae: 1.5516 - mse: 4.9712 - val_loss: 6.4727 - val_mae: 1.8239 - val_mse: 6.4727\n",
      "Epoch 298/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8665 - mae: 1.5218 - mse: 4.8665 - val_loss: 5.6830 - val_mae: 1.7699 - val_mse: 5.6830\n",
      "Epoch 299/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.0449 - mae: 1.5972 - mse: 5.0449 - val_loss: 7.2479 - val_mae: 1.9334 - val_mse: 7.2479\n",
      "Epoch 300/1000\n",
      "250/250 [==============================] - 0s 72us/sample - loss: 4.8964 - mae: 1.5204 - mse: 4.8964 - val_loss: 6.0590 - val_mae: 1.7714 - val_mse: 6.0590\n",
      "Epoch 301/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.9247 - mae: 1.5320 - mse: 4.9247 - val_loss: 5.7430 - val_mae: 1.7583 - val_mse: 5.7430\n",
      "Epoch 302/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9815 - mae: 1.5442 - mse: 4.9815 - val_loss: 5.9450 - val_mae: 1.7477 - val_mse: 5.9450\n",
      "Epoch 303/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 2.7541 - mae: 1.2959 - mse: 2.754 - 0s 52us/sample - loss: 5.0526 - mae: 1.5700 - mse: 5.0526 - val_loss: 7.5060 - val_mae: 1.9626 - val_mse: 7.5060\n",
      "Epoch 304/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9266 - mae: 1.5328 - mse: 4.9266 - val_loss: 6.4096 - val_mae: 1.8360 - val_mse: 6.4096\n",
      "Epoch 305/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0541 - mae: 1.5829 - mse: 5.0541 - val_loss: 7.8434 - val_mae: 1.9930 - val_mse: 7.8434\n",
      "Epoch 306/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.9151 - mae: 1.5573 - mse: 4.9151 - val_loss: 6.7392 - val_mae: 1.8752 - val_mse: 6.7392\n",
      "Epoch 307/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8476 - mae: 1.4986 - mse: 4.8476 - val_loss: 6.2267 - val_mae: 1.7901 - val_mse: 6.2267\n",
      "Epoch 308/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8120 - mae: 1.5516 - mse: 4.8120 - val_loss: 6.6063 - val_mae: 1.8334 - val_mse: 6.6063\n",
      "Epoch 309/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.8241 - mae: 1.5067 - mse: 4.8241 - val_loss: 6.9497 - val_mae: 1.8911 - val_mse: 6.9497\n",
      "Epoch 310/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8657 - mae: 1.5344 - mse: 4.8657 - val_loss: 5.7127 - val_mae: 1.7322 - val_mse: 5.7127\n",
      "Epoch 311/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.8569 - mae: 1.5102 - mse: 4.8569 - val_loss: 6.9256 - val_mae: 1.8713 - val_mse: 6.9256\n",
      "Epoch 312/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0106 - mae: 1.5081 - mse: 5.0106 - val_loss: 5.8419 - val_mae: 1.7618 - val_mse: 5.8419\n",
      "Epoch 313/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.8644 - mae: 1.5104 - mse: 4.8644 - val_loss: 5.8723 - val_mae: 1.7968 - val_mse: 5.8723\n",
      "Epoch 314/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9268 - mae: 1.5596 - mse: 4.9268 - val_loss: 6.0074 - val_mae: 1.7916 - val_mse: 6.0074\n",
      "Epoch 315/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6381 - mae: 1.5166 - mse: 4.6381 - val_loss: 5.4034 - val_mae: 1.7343 - val_mse: 5.4034\n",
      "Epoch 316/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.8939 - mae: 1.5391 - mse: 4.8939 - val_loss: 6.1693 - val_mae: 1.8155 - val_mse: 6.1693\n",
      "Epoch 317/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.7928 - mae: 1.5257 - mse: 4.7928 - val_loss: 5.5899 - val_mae: 1.7545 - val_mse: 5.5899\n",
      "Epoch 318/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 5.1081 - mae: 1.5595 - mse: 5.1081 - val_loss: 5.9483 - val_mae: 1.7802 - val_mse: 5.9483\n",
      "Epoch 319/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.8437 - mae: 1.5066 - mse: 4.8437 - val_loss: 5.6225 - val_mae: 1.7590 - val_mse: 5.6225\n",
      "Epoch 320/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 5.0178 - mae: 1.5468 - mse: 5.0178 - val_loss: 6.1827 - val_mae: 1.7836 - val_mse: 6.1827\n",
      "Epoch 321/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.9148 - mae: 1.5294 - mse: 4.9148 - val_loss: 6.2798 - val_mae: 1.8283 - val_mse: 6.2798\n",
      "Epoch 322/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8338 - mae: 1.5204 - mse: 4.8338 - val_loss: 6.9445 - val_mae: 1.8933 - val_mse: 6.9445\n",
      "Epoch 323/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.9797 - mae: 1.5535 - mse: 4.9797 - val_loss: 5.6439 - val_mae: 1.7229 - val_mse: 5.6439\n",
      "Epoch 324/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 5.0401 - mae: 1.5529 - mse: 5.0401 - val_loss: 5.9582 - val_mae: 1.7516 - val_mse: 5.9582\n",
      "Epoch 325/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6987 - mae: 1.4958 - mse: 4.6987 - val_loss: 6.4563 - val_mae: 1.8187 - val_mse: 6.4563\n",
      "Epoch 326/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.7488 - mae: 1.5217 - mse: 4.7488 - val_loss: 7.3151 - val_mae: 1.9681 - val_mse: 7.3151\n",
      "Epoch 327/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.9329 - mae: 1.5131 - mse: 4.9329 - val_loss: 5.4846 - val_mae: 1.7300 - val_mse: 5.4846\n",
      "Epoch 328/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.5825 - mae: 1.5110 - mse: 4.5825 - val_loss: 7.0329 - val_mae: 1.8720 - val_mse: 7.0329\n",
      "Epoch 329/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6205 - mae: 1.4942 - mse: 4.6205 - val_loss: 5.6026 - val_mae: 1.8548 - val_mse: 5.6026\n",
      "Epoch 330/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 5.1231 - mae: 1.5627 - mse: 5.1231 - val_loss: 5.6243 - val_mae: 1.7641 - val_mse: 5.6243\n",
      "Epoch 331/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.7871 - mae: 1.5155 - mse: 4.7871 - val_loss: 6.1158 - val_mae: 1.8185 - val_mse: 6.1158\n",
      "Epoch 332/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8970 - mae: 1.5323 - mse: 4.8970 - val_loss: 6.7576 - val_mae: 1.8534 - val_mse: 6.7576\n",
      "Epoch 333/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.9469 - mae: 1.5390 - mse: 4.9469 - val_loss: 5.6828 - val_mae: 1.7343 - val_mse: 5.6828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.9000 - mae: 1.5380 - mse: 4.9000 - val_loss: 5.4635 - val_mae: 1.7228 - val_mse: 5.4635\n",
      "Epoch 335/1000\n",
      "250/250 [==============================] - 0s 76us/sample - loss: 4.8906 - mae: 1.5265 - mse: 4.8906 - val_loss: 5.6558 - val_mae: 1.7512 - val_mse: 5.6558\n",
      "Epoch 336/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.6484 - mae: 1.4950 - mse: 4.6484 - val_loss: 5.8743 - val_mae: 1.7445 - val_mse: 5.8743\n",
      "Epoch 337/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.6887 - mae: 1.4951 - mse: 4.6887 - val_loss: 5.9668 - val_mae: 1.7669 - val_mse: 5.9668\n",
      "Epoch 338/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9534 - mae: 1.5422 - mse: 4.9534 - val_loss: 6.6649 - val_mae: 1.8702 - val_mse: 6.6649\n",
      "Epoch 339/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6993 - mae: 1.5000 - mse: 4.6993 - val_loss: 6.2739 - val_mae: 1.8269 - val_mse: 6.2739\n",
      "Epoch 340/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.7256 - mae: 1.5018 - mse: 4.7256 - val_loss: 5.6977 - val_mae: 1.7711 - val_mse: 5.6977\n",
      "Epoch 341/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.7653 - mae: 1.5072 - mse: 4.7653 - val_loss: 6.5506 - val_mae: 1.8526 - val_mse: 6.5506\n",
      "Epoch 342/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8525 - mae: 1.5183 - mse: 4.8525 - val_loss: 6.1510 - val_mae: 1.8164 - val_mse: 6.1510\n",
      "Epoch 343/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.7339 - mae: 1.4852 - mse: 4.7339 - val_loss: 6.7466 - val_mae: 1.8610 - val_mse: 6.7466\n",
      "Epoch 344/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8502 - mae: 1.5255 - mse: 4.8502 - val_loss: 5.8326 - val_mae: 1.7902 - val_mse: 5.8326\n",
      "Epoch 345/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9116 - mae: 1.5312 - mse: 4.9116 - val_loss: 5.7889 - val_mae: 1.7396 - val_mse: 5.7889\n",
      "Epoch 346/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.6909 - mae: 1.4983 - mse: 4.6909 - val_loss: 5.9871 - val_mae: 1.7682 - val_mse: 5.9871\n",
      "Epoch 347/1000\n",
      "250/250 [==============================] - 0s 116us/sample - loss: 4.7685 - mae: 1.4981 - mse: 4.7685 - val_loss: 5.7204 - val_mae: 1.7717 - val_mse: 5.7204\n",
      "Epoch 348/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.8256 - mae: 1.5450 - mse: 4.8256 - val_loss: 6.7220 - val_mae: 1.8898 - val_mse: 6.7220\n",
      "Epoch 349/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 4.7956 - mae: 1.5021 - mse: 4.7956 - val_loss: 6.1263 - val_mae: 1.7869 - val_mse: 6.1263\n",
      "Epoch 350/1000\n",
      "250/250 [==============================] - 0s 76us/sample - loss: 4.7819 - mae: 1.5222 - mse: 4.7819 - val_loss: 5.7267 - val_mae: 1.7837 - val_mse: 5.7267\n",
      "Epoch 351/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 4.7574 - mae: 1.5141 - mse: 4.7574 - val_loss: 6.3118 - val_mae: 1.8465 - val_mse: 6.3118\n",
      "Epoch 352/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8352 - mae: 1.5208 - mse: 4.8352 - val_loss: 7.2530 - val_mae: 1.8980 - val_mse: 7.2530\n",
      "Epoch 353/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.7379 - mae: 1.4782 - mse: 4.7379 - val_loss: 5.5238 - val_mae: 1.7247 - val_mse: 5.5238\n",
      "Epoch 354/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.5669 - mae: 1.5060 - mse: 4.5669 - val_loss: 7.7953 - val_mae: 2.0104 - val_mse: 7.7953\n",
      "Epoch 355/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9356 - mae: 1.5198 - mse: 4.9356 - val_loss: 5.9196 - val_mae: 1.8073 - val_mse: 5.9196\n",
      "Epoch 356/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.7118 - mae: 1.4861 - mse: 4.7118 - val_loss: 5.5638 - val_mae: 1.7357 - val_mse: 5.5638\n",
      "Epoch 357/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.7576 - mae: 1.5436 - mse: 4.7576 - val_loss: 5.7081 - val_mae: 1.7546 - val_mse: 5.7081\n",
      "Epoch 358/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.9030 - mae: 1.5067 - mse: 4.9030 - val_loss: 5.5318 - val_mae: 1.7337 - val_mse: 5.5318\n",
      "Epoch 359/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.6631 - mae: 1.4989 - mse: 4.6631 - val_loss: 7.1196 - val_mae: 1.9398 - val_mse: 7.1196\n",
      "Epoch 360/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.9544 - mae: 1.5389 - mse: 4.9544 - val_loss: 7.2981 - val_mae: 1.9301 - val_mse: 7.2981\n",
      "Epoch 361/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 4.7389 - mae: 1.5014 - mse: 4.7389 - val_loss: 5.9356 - val_mae: 1.7890 - val_mse: 5.9356\n",
      "Epoch 362/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.5544 - mae: 1.4519 - mse: 4.5544 - val_loss: 6.6327 - val_mae: 1.8927 - val_mse: 6.6327\n",
      "Epoch 363/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8029 - mae: 1.4873 - mse: 4.8029 - val_loss: 5.5459 - val_mae: 1.7542 - val_mse: 5.5459\n",
      "Epoch 364/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.6039 - mae: 1.4917 - mse: 4.6039 - val_loss: 5.7222 - val_mae: 1.7748 - val_mse: 5.7222\n",
      "Epoch 365/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.8373 - mae: 1.5359 - mse: 4.8373 - val_loss: 5.6312 - val_mae: 1.7304 - val_mse: 5.6312\n",
      "Epoch 366/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6355 - mae: 1.5018 - mse: 4.6355 - val_loss: 5.4941 - val_mae: 1.7835 - val_mse: 5.4941\n",
      "Epoch 367/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.7408 - mae: 1.5337 - mse: 4.7408 - val_loss: 5.8071 - val_mae: 1.7412 - val_mse: 5.8071\n",
      "Epoch 368/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.7505 - mae: 1.5245 - mse: 4.7505 - val_loss: 6.2474 - val_mae: 1.8171 - val_mse: 6.2474\n",
      "Epoch 369/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.5960 - mae: 1.4811 - mse: 4.5960 - val_loss: 5.6898 - val_mae: 1.8017 - val_mse: 5.6898\n",
      "Epoch 370/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6481 - mae: 1.4834 - mse: 4.6481 - val_loss: 6.0399 - val_mae: 1.8140 - val_mse: 6.0399\n",
      "Epoch 371/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 4.8473 - mae: 1.5241 - mse: 4.8473 - val_loss: 6.8163 - val_mae: 1.8638 - val_mse: 6.8163\n",
      "Epoch 372/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.6669 - mae: 1.5069 - mse: 4.6669 - val_loss: 6.3578 - val_mae: 1.8020 - val_mse: 6.3578\n",
      "Epoch 373/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.8353 - mae: 1.5140 - mse: 4.8353 - val_loss: 5.7051 - val_mae: 1.7673 - val_mse: 5.7051\n",
      "Epoch 374/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.5479 - mae: 1.4582 - mse: 4.5479 - val_loss: 6.1850 - val_mae: 1.8335 - val_mse: 6.1850\n",
      "Epoch 375/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.8085 - mae: 1.5339 - mse: 4.8085 - val_loss: 6.1402 - val_mae: 1.7746 - val_mse: 6.1402\n",
      "Epoch 376/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.6633 - mae: 1.4751 - mse: 4.6633 - val_loss: 6.9385 - val_mae: 1.9284 - val_mse: 6.9385\n",
      "Epoch 377/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6314 - mae: 1.4615 - mse: 4.6314 - val_loss: 6.5928 - val_mae: 1.8650 - val_mse: 6.5928\n",
      "Epoch 378/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 4.6985 - mae: 1.4955 - mse: 4.6985 - val_loss: 5.8492 - val_mae: 1.7706 - val_mse: 5.8492\n",
      "Epoch 379/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.5836 - mae: 1.4834 - mse: 4.5836 - val_loss: 5.6465 - val_mae: 1.7313 - val_mse: 5.6465\n",
      "Epoch 380/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.5673 - mae: 1.4939 - mse: 4.5673 - val_loss: 6.4168 - val_mae: 1.8448 - val_mse: 6.4168\n",
      "Epoch 381/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.7536 - mae: 1.4976 - mse: 4.7536 - val_loss: 5.7074 - val_mae: 1.7677 - val_mse: 5.7074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 4.5849 - mae: 1.4652 - mse: 4.5849 - val_loss: 5.4698 - val_mae: 1.7299 - val_mse: 5.4698\n",
      "Epoch 383/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9302 - mae: 1.5434 - mse: 4.9302 - val_loss: 5.6381 - val_mae: 1.7799 - val_mse: 5.6381\n",
      "Epoch 384/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5702 - mae: 1.4960 - mse: 4.5702 - val_loss: 5.6394 - val_mae: 1.7307 - val_mse: 5.6394\n",
      "Epoch 385/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.9251 - mae: 1.5214 - mse: 4.9251 - val_loss: 6.1195 - val_mae: 1.8051 - val_mse: 6.1195\n",
      "Epoch 386/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.5374 - mae: 1.4720 - mse: 4.5374 - val_loss: 6.5063 - val_mae: 1.8199 - val_mse: 6.5063\n",
      "Epoch 387/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4228 - mae: 1.4390 - mse: 4.4228 - val_loss: 5.5875 - val_mae: 1.7798 - val_mse: 5.5875\n",
      "Epoch 388/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6185 - mae: 1.5033 - mse: 4.6185 - val_loss: 5.8106 - val_mae: 1.8154 - val_mse: 5.8106\n",
      "Epoch 389/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4262 - mae: 0.9621 - mse: 1.426 - 0s 48us/sample - loss: 4.5088 - mae: 1.4660 - mse: 4.5088 - val_loss: 5.8806 - val_mae: 1.7651 - val_mse: 5.8806\n",
      "Epoch 390/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.6102 - mae: 1.4481 - mse: 4.6102 - val_loss: 5.6963 - val_mae: 1.7621 - val_mse: 5.6963\n",
      "Epoch 391/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6696 - mae: 1.5123 - mse: 4.6696 - val_loss: 6.4505 - val_mae: 1.8747 - val_mse: 6.4505\n",
      "Epoch 392/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5525 - mae: 1.4689 - mse: 4.5525 - val_loss: 5.7245 - val_mae: 1.7651 - val_mse: 5.7245\n",
      "Epoch 393/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5529 - mae: 1.4692 - mse: 4.5529 - val_loss: 5.5845 - val_mae: 1.7965 - val_mse: 5.5845\n",
      "Epoch 394/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.8042 - mae: 1.4971 - mse: 4.8042 - val_loss: 6.3223 - val_mae: 1.8259 - val_mse: 6.3223\n",
      "Epoch 395/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5408 - mae: 1.4702 - mse: 4.5408 - val_loss: 5.7160 - val_mae: 1.8618 - val_mse: 5.7160\n",
      "Epoch 396/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.7323 - mae: 1.4786 - mse: 4.7323 - val_loss: 5.8071 - val_mae: 1.7779 - val_mse: 5.8071\n",
      "Epoch 397/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5483 - mae: 1.4963 - mse: 4.5483 - val_loss: 7.2746 - val_mae: 1.9520 - val_mse: 7.2746\n",
      "Epoch 398/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4349 - mae: 1.4529 - mse: 4.4349 - val_loss: 6.0433 - val_mae: 1.7819 - val_mse: 6.0433\n",
      "Epoch 399/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.6077 - mae: 1.4908 - mse: 4.6077 - val_loss: 6.0783 - val_mae: 1.7884 - val_mse: 6.0783\n",
      "Epoch 400/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5330 - mae: 1.4652 - mse: 4.5330 - val_loss: 5.9009 - val_mae: 1.8249 - val_mse: 5.9009\n",
      "Epoch 401/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.6168 - mae: 1.4850 - mse: 4.6168 - val_loss: 6.0970 - val_mae: 1.8080 - val_mse: 6.0970\n",
      "Epoch 402/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.7689 - mae: 1.4562 - mse: 4.7689 - val_loss: 6.3092 - val_mae: 1.8317 - val_mse: 6.3092\n",
      "Epoch 403/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6503 - mae: 1.5020 - mse: 4.6503 - val_loss: 6.0868 - val_mae: 1.8149 - val_mse: 6.0868\n",
      "Epoch 404/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.5142 - mae: 1.4673 - mse: 4.5142 - val_loss: 6.0621 - val_mae: 1.8301 - val_mse: 6.0621\n",
      "Epoch 405/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.5936 - mae: 1.4631 - mse: 4.5936 - val_loss: 5.7114 - val_mae: 1.7723 - val_mse: 5.7114\n",
      "Epoch 406/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.6347 - mae: 1.4882 - mse: 4.6347 - val_loss: 6.0294 - val_mae: 1.8013 - val_mse: 6.0294\n",
      "Epoch 407/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.5017 - mae: 1.4969 - mse: 4.5017 - val_loss: 6.3964 - val_mae: 1.8299 - val_mse: 6.3964\n",
      "Epoch 408/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.6640 - mae: 1.4572 - mse: 4.6640 - val_loss: 6.0610 - val_mae: 1.8134 - val_mse: 6.0610\n",
      "Epoch 409/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.5351 - mae: 1.4451 - mse: 4.5351 - val_loss: 6.3702 - val_mae: 1.8119 - val_mse: 6.3702\n",
      "Epoch 410/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.5840 - mae: 1.4724 - mse: 4.5840 - val_loss: 7.1651 - val_mae: 1.9428 - val_mse: 7.1651\n",
      "Epoch 411/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.7397 - mae: 1.4757 - mse: 4.7397 - val_loss: 6.6615 - val_mae: 1.8365 - val_mse: 6.6615\n",
      "Epoch 412/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6772 - mae: 1.5142 - mse: 4.6772 - val_loss: 6.3251 - val_mae: 1.8055 - val_mse: 6.3251\n",
      "Epoch 413/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6620 - mae: 1.4897 - mse: 4.6620 - val_loss: 5.7636 - val_mae: 1.7980 - val_mse: 5.7636\n",
      "Epoch 414/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5954 - mae: 1.4899 - mse: 4.5954 - val_loss: 6.4045 - val_mae: 1.8487 - val_mse: 6.4045\n",
      "Epoch 415/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5429 - mae: 1.4581 - mse: 4.5429 - val_loss: 5.8740 - val_mae: 1.7874 - val_mse: 5.8740\n",
      "Epoch 416/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4166 - mae: 1.4293 - mse: 4.4166 - val_loss: 5.6521 - val_mae: 1.7597 - val_mse: 5.6521\n",
      "Epoch 417/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.6081 - mae: 1.4934 - mse: 4.6081 - val_loss: 6.3378 - val_mae: 1.8804 - val_mse: 6.3378\n",
      "Epoch 418/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.6143 - mae: 1.4791 - mse: 4.6143 - val_loss: 6.1814 - val_mae: 1.7872 - val_mse: 6.1814\n",
      "Epoch 419/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.3413 - mae: 1.4158 - mse: 4.3413 - val_loss: 6.8677 - val_mae: 1.9138 - val_mse: 6.8677\n",
      "Epoch 420/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 4.5093 - mae: 1.4795 - mse: 4.5093 - val_loss: 7.5884 - val_mae: 1.9588 - val_mse: 7.5884\n",
      "Epoch 421/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6052 - mae: 1.4544 - mse: 4.6052 - val_loss: 6.1810 - val_mae: 1.7974 - val_mse: 6.1810\n",
      "Epoch 422/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.4898 - mae: 1.4482 - mse: 4.4898 - val_loss: 7.2306 - val_mae: 1.9695 - val_mse: 7.2306\n",
      "Epoch 423/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4373 - mae: 1.4366 - mse: 4.4373 - val_loss: 6.5754 - val_mae: 1.8366 - val_mse: 6.5754\n",
      "Epoch 424/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.4851 - mae: 1.4360 - mse: 4.4851 - val_loss: 5.8110 - val_mae: 1.7771 - val_mse: 5.8110\n",
      "Epoch 425/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.5183 - mae: 1.4574 - mse: 4.5183 - val_loss: 7.4717 - val_mae: 1.9798 - val_mse: 7.4717\n",
      "Epoch 426/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.6468 - mae: 1.4809 - mse: 4.6468 - val_loss: 6.8560 - val_mae: 1.8819 - val_mse: 6.8560\n",
      "Epoch 427/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.5785 - mae: 1.4596 - mse: 4.5785 - val_loss: 5.9083 - val_mae: 1.7772 - val_mse: 5.9083\n",
      "Epoch 428/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4540 - mae: 1.4548 - mse: 4.4540 - val_loss: 6.5026 - val_mae: 1.8555 - val_mse: 6.5026\n",
      "Epoch 429/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 40us/sample - loss: 4.5200 - mae: 1.4603 - mse: 4.5200 - val_loss: 6.2425 - val_mae: 1.8291 - val_mse: 6.2425\n",
      "Epoch 430/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.3900 - mae: 1.4225 - mse: 4.3900 - val_loss: 5.5477 - val_mae: 1.7741 - val_mse: 5.5477\n",
      "Epoch 431/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.6259 - mae: 1.5061 - mse: 4.6259 - val_loss: 6.9158 - val_mae: 1.9040 - val_mse: 6.9158\n",
      "Epoch 432/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.5034 - mae: 1.4531 - mse: 4.5034 - val_loss: 6.5688 - val_mae: 1.8725 - val_mse: 6.5688\n",
      "Epoch 433/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4255 - mae: 1.4538 - mse: 4.4255 - val_loss: 6.5556 - val_mae: 1.8208 - val_mse: 6.5556\n",
      "Epoch 434/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4522 - mae: 1.4461 - mse: 4.4522 - val_loss: 6.6390 - val_mae: 1.8505 - val_mse: 6.6390\n",
      "Epoch 435/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4608 - mae: 1.4730 - mse: 4.4608 - val_loss: 5.9086 - val_mae: 1.7858 - val_mse: 5.9086\n",
      "Epoch 436/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.4343 - mae: 1.4408 - mse: 4.4343 - val_loss: 6.1248 - val_mae: 1.8372 - val_mse: 6.1248\n",
      "Epoch 437/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.5487 - mae: 1.4514 - mse: 4.5487 - val_loss: 7.3688 - val_mae: 1.9951 - val_mse: 7.3688\n",
      "Epoch 438/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4953 - mae: 1.4415 - mse: 4.4953 - val_loss: 5.8488 - val_mae: 1.8321 - val_mse: 5.8488\n",
      "Epoch 439/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.4154 - mae: 1.4511 - mse: 4.4154 - val_loss: 6.3690 - val_mae: 1.8165 - val_mse: 6.3690\n",
      "Epoch 440/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.4878 - mae: 1.4413 - mse: 4.4878 - val_loss: 6.0080 - val_mae: 1.8335 - val_mse: 6.0080\n",
      "Epoch 441/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4546 - mae: 1.4423 - mse: 4.4546 - val_loss: 6.6940 - val_mae: 1.8403 - val_mse: 6.6940\n",
      "Epoch 442/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4008 - mae: 1.4421 - mse: 4.4008 - val_loss: 6.6155 - val_mae: 1.8798 - val_mse: 6.6155\n",
      "Epoch 443/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.7537 - mae: 1.5106 - mse: 4.7537 - val_loss: 6.0450 - val_mae: 1.8374 - val_mse: 6.0450\n",
      "Epoch 444/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3060 - mae: 1.4424 - mse: 4.3060 - val_loss: 6.4136 - val_mae: 1.8549 - val_mse: 6.4136\n",
      "Epoch 445/1000\n",
      "250/250 [==============================] - 0s 80us/sample - loss: 4.4726 - mae: 1.4496 - mse: 4.4726 - val_loss: 7.0583 - val_mae: 1.9346 - val_mse: 7.0583\n",
      "Epoch 446/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 4.3320 - mae: 1.4259 - mse: 4.3321 - val_loss: 5.7243 - val_mae: 1.7573 - val_mse: 5.7243\n",
      "Epoch 447/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.6447 - mae: 1.4692 - mse: 4.6447 - val_loss: 5.7889 - val_mae: 1.7721 - val_mse: 5.7889\n",
      "Epoch 448/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5067 - mae: 1.4593 - mse: 4.5067 - val_loss: 6.5734 - val_mae: 1.8431 - val_mse: 6.5734\n",
      "Epoch 449/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3796 - mae: 1.4346 - mse: 4.3796 - val_loss: 5.8789 - val_mae: 1.8837 - val_mse: 5.8789\n",
      "Epoch 450/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3895 - mae: 1.4542 - mse: 4.3895 - val_loss: 6.2301 - val_mae: 1.8220 - val_mse: 6.2301\n",
      "Epoch 451/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2589 - mae: 1.4260 - mse: 4.2589 - val_loss: 6.2429 - val_mae: 1.8068 - val_mse: 6.2429\n",
      "Epoch 452/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5379 - mae: 1.4249 - mse: 4.5379 - val_loss: 5.6223 - val_mae: 1.7877 - val_mse: 5.6223\n",
      "Epoch 453/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3979 - mae: 1.4456 - mse: 4.3979 - val_loss: 5.8283 - val_mae: 1.8893 - val_mse: 5.8283\n",
      "Epoch 454/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4459 - mae: 1.4587 - mse: 4.4459 - val_loss: 5.9884 - val_mae: 1.7996 - val_mse: 5.9884\n",
      "Epoch 455/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.3438 - mae: 1.4448 - mse: 4.3438 - val_loss: 7.1422 - val_mae: 1.9498 - val_mse: 7.1422\n",
      "Epoch 456/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2722 - mae: 1.4369 - mse: 4.2722 - val_loss: 7.6446 - val_mae: 1.9744 - val_mse: 7.6446\n",
      "Epoch 457/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5280 - mae: 1.4855 - mse: 4.5280 - val_loss: 6.5830 - val_mae: 1.8562 - val_mse: 6.5830\n",
      "Epoch 458/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5546 - mae: 1.4648 - mse: 4.5546 - val_loss: 6.2438 - val_mae: 1.8193 - val_mse: 6.2438\n",
      "Epoch 459/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3870 - mae: 1.4403 - mse: 4.3870 - val_loss: 5.8493 - val_mae: 1.8060 - val_mse: 5.8493\n",
      "Epoch 460/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2985 - mae: 1.4356 - mse: 4.2985 - val_loss: 5.8486 - val_mae: 1.8647 - val_mse: 5.8486\n",
      "Epoch 461/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5296 - mae: 1.4157 - mse: 4.5296 - val_loss: 5.8174 - val_mae: 1.8666 - val_mse: 5.8174\n",
      "Epoch 462/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5006 - mae: 1.4629 - mse: 4.5006 - val_loss: 6.7090 - val_mae: 1.8954 - val_mse: 6.7090\n",
      "Epoch 463/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5413 - mae: 1.4397 - mse: 4.5413 - val_loss: 6.5556 - val_mae: 1.8380 - val_mse: 6.5556\n",
      "Epoch 464/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3095 - mae: 1.4340 - mse: 4.3095 - val_loss: 8.0568 - val_mae: 2.0341 - val_mse: 8.0568\n",
      "Epoch 465/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4659 - mae: 1.4225 - mse: 4.4659 - val_loss: 6.3625 - val_mae: 1.8290 - val_mse: 6.3625\n",
      "Epoch 466/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2814 - mae: 1.4157 - mse: 4.2814 - val_loss: 5.8503 - val_mae: 1.7860 - val_mse: 5.8503\n",
      "Epoch 467/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3259 - mae: 1.4189 - mse: 4.3259 - val_loss: 6.1868 - val_mae: 1.8389 - val_mse: 6.1868\n",
      "Epoch 468/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.4246 - mae: 1.4364 - mse: 4.4246 - val_loss: 7.6119 - val_mae: 2.0276 - val_mse: 7.6119\n",
      "Epoch 469/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4255 - mae: 1.4434 - mse: 4.4255 - val_loss: 7.5752 - val_mae: 1.9773 - val_mse: 7.5752\n",
      "Epoch 470/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2582 - mae: 1.3998 - mse: 4.2582 - val_loss: 5.8432 - val_mae: 1.8134 - val_mse: 5.8432\n",
      "Epoch 471/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5585 - mae: 1.4762 - mse: 4.5585 - val_loss: 6.0754 - val_mae: 1.8587 - val_mse: 6.0754\n",
      "Epoch 472/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4696 - mae: 1.4561 - mse: 4.4696 - val_loss: 6.1990 - val_mae: 1.8126 - val_mse: 6.1990\n",
      "Epoch 473/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.4007 - mae: 1.4552 - mse: 4.4007 - val_loss: 6.2994 - val_mae: 1.8604 - val_mse: 6.2994\n",
      "Epoch 474/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.2988 - mae: 1.4093 - mse: 4.2988 - val_loss: 6.5548 - val_mae: 1.8381 - val_mse: 6.5548\n",
      "Epoch 475/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.2849 - mae: 1.4188 - mse: 4.2849 - val_loss: 6.6732 - val_mae: 1.9198 - val_mse: 6.6732\n",
      "Epoch 476/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.5988 - mae: 1.4466 - mse: 4.5988 - val_loss: 6.6991 - val_mae: 1.8796 - val_mse: 6.6991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3225 - mae: 1.4011 - mse: 4.3225 - val_loss: 6.1020 - val_mae: 1.8083 - val_mse: 6.1020\n",
      "Epoch 478/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3831 - mae: 1.4348 - mse: 4.3831 - val_loss: 7.2040 - val_mae: 1.9317 - val_mse: 7.2040\n",
      "Epoch 479/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3868 - mae: 1.4114 - mse: 4.3868 - val_loss: 6.7311 - val_mae: 1.8662 - val_mse: 6.7311\n",
      "Epoch 480/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4245 - mae: 1.4373 - mse: 4.4245 - val_loss: 7.4663 - val_mae: 1.9729 - val_mse: 7.4663\n",
      "Epoch 481/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.2856 - mae: 1.4039 - mse: 4.2856 - val_loss: 6.0196 - val_mae: 1.7969 - val_mse: 6.0196\n",
      "Epoch 482/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4544 - mae: 1.4285 - mse: 4.4544 - val_loss: 7.2254 - val_mae: 1.9969 - val_mse: 7.2254\n",
      "Epoch 483/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4384 - mae: 1.4417 - mse: 4.4384 - val_loss: 6.7969 - val_mae: 1.8547 - val_mse: 6.7969\n",
      "Epoch 484/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.2397 - mae: 1.4211 - mse: 4.2397 - val_loss: 7.4315 - val_mae: 1.9888 - val_mse: 7.4315\n",
      "Epoch 485/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.5496 - mae: 1.4333 - mse: 4.5496 - val_loss: 7.0498 - val_mae: 1.9274 - val_mse: 7.0498\n",
      "Epoch 486/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.3818 - mae: 1.4221 - mse: 4.3818 - val_loss: 6.5421 - val_mae: 1.8375 - val_mse: 6.5421\n",
      "Epoch 487/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2852 - mae: 1.4172 - mse: 4.2852 - val_loss: 6.6001 - val_mae: 1.8513 - val_mse: 6.6001\n",
      "Epoch 488/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.3451 - mae: 1.4152 - mse: 4.3451 - val_loss: 6.1949 - val_mae: 1.8404 - val_mse: 6.1949\n",
      "Epoch 489/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.4134 - mae: 1.4353 - mse: 4.4134 - val_loss: 6.2294 - val_mae: 1.8426 - val_mse: 6.2295\n",
      "Epoch 490/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.3505 - mae: 1.4332 - mse: 4.3505 - val_loss: 6.0534 - val_mae: 1.7970 - val_mse: 6.0534\n",
      "Epoch 491/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.3830 - mae: 1.4174 - mse: 4.3830 - val_loss: 6.2389 - val_mae: 1.8599 - val_mse: 6.2389\n",
      "Epoch 492/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.2768 - mae: 1.4344 - mse: 4.2768 - val_loss: 6.3505 - val_mae: 1.8363 - val_mse: 6.3505\n",
      "Epoch 493/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.2596 - mae: 1.4082 - mse: 4.2596 - val_loss: 6.7635 - val_mae: 1.8992 - val_mse: 6.7635\n",
      "Epoch 494/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.3041 - mae: 1.4254 - mse: 4.3041 - val_loss: 6.0138 - val_mae: 1.8104 - val_mse: 6.0138\n",
      "Epoch 495/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3578 - mae: 1.4292 - mse: 4.3578 - val_loss: 6.2483 - val_mae: 1.8290 - val_mse: 6.2483\n",
      "Epoch 496/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3103 - mae: 1.4186 - mse: 4.3103 - val_loss: 6.0421 - val_mae: 1.8368 - val_mse: 6.0421\n",
      "Epoch 497/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2963 - mae: 1.4439 - mse: 4.2963 - val_loss: 5.9974 - val_mae: 1.7922 - val_mse: 5.9974\n",
      "Epoch 498/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2138 - mae: 1.4072 - mse: 4.2138 - val_loss: 7.0446 - val_mae: 1.8752 - val_mse: 7.0446\n",
      "Epoch 499/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.2589 - mae: 1.4159 - mse: 4.2589 - val_loss: 7.7547 - val_mae: 2.0045 - val_mse: 7.7547\n",
      "Epoch 500/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.4014 - mae: 1.4366 - mse: 4.4014 - val_loss: 6.4650 - val_mae: 1.8483 - val_mse: 6.4650\n",
      "Epoch 501/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.2318 - mae: 1.3896 - mse: 4.2318 - val_loss: 6.0822 - val_mae: 1.8362 - val_mse: 6.0822\n",
      "Epoch 502/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2082 - mae: 1.3962 - mse: 4.2082 - val_loss: 6.6707 - val_mae: 1.9214 - val_mse: 6.6707\n",
      "Epoch 503/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.5167 - mae: 1.4303 - mse: 4.5167 - val_loss: 6.4013 - val_mae: 1.8469 - val_mse: 6.4013\n",
      "Epoch 504/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.4274 - mae: 1.4349 - mse: 4.4274 - val_loss: 6.2109 - val_mae: 1.8433 - val_mse: 6.2109\n",
      "Epoch 505/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 4.4052 - mae: 1.4393 - mse: 4.4052 - val_loss: 7.4065 - val_mae: 1.9727 - val_mse: 7.4065\n",
      "Epoch 506/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.3103 - mae: 1.4171 - mse: 4.3103 - val_loss: 7.4400 - val_mae: 1.9727 - val_mse: 7.4400\n",
      "Epoch 507/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.1997 - mae: 1.3849 - mse: 4.1997 - val_loss: 5.8215 - val_mae: 1.7907 - val_mse: 5.8215\n",
      "Epoch 508/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2526 - mae: 1.4172 - mse: 4.2526 - val_loss: 6.8055 - val_mae: 1.8669 - val_mse: 6.8055\n",
      "Epoch 509/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3110 - mae: 1.4332 - mse: 4.3110 - val_loss: 6.3108 - val_mae: 1.8206 - val_mse: 6.3108\n",
      "Epoch 510/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.3687 - mae: 1.4486 - mse: 4.3687 - val_loss: 6.9758 - val_mae: 1.8886 - val_mse: 6.9758\n",
      "Epoch 511/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2811 - mae: 1.4082 - mse: 4.2811 - val_loss: 6.9761 - val_mae: 1.9209 - val_mse: 6.9761\n",
      "Epoch 512/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.1980 - mae: 1.3771 - mse: 4.1980 - val_loss: 6.7785 - val_mae: 1.9034 - val_mse: 6.7785\n",
      "Epoch 513/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.1197 - mae: 1.3779 - mse: 4.1197 - val_loss: 5.9622 - val_mae: 1.8968 - val_mse: 5.9622\n",
      "Epoch 514/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.3415 - mae: 1.4148 - mse: 4.3415 - val_loss: 5.9957 - val_mae: 1.7907 - val_mse: 5.9957\n",
      "Epoch 515/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3170 - mae: 1.4009 - mse: 4.3170 - val_loss: 7.2441 - val_mae: 1.9337 - val_mse: 7.2441\n",
      "Epoch 516/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 4.1875 - mae: 1.3782 - mse: 4.1875 - val_loss: 7.2454 - val_mae: 1.9458 - val_mse: 7.2454\n",
      "Epoch 517/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 3.1318 - mae: 1.3284 - mse: 3.131 - 0s 44us/sample - loss: 4.2718 - mae: 1.3959 - mse: 4.2718 - val_loss: 6.4978 - val_mae: 1.8908 - val_mse: 6.4978\n",
      "Epoch 518/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.2036 - mae: 1.4044 - mse: 4.2036 - val_loss: 7.2006 - val_mae: 1.9757 - val_mse: 7.2006\n",
      "Epoch 519/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2818 - mae: 1.4371 - mse: 4.2818 - val_loss: 6.3342 - val_mae: 1.8477 - val_mse: 6.3342\n",
      "Epoch 520/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2169 - mae: 1.3922 - mse: 4.2169 - val_loss: 7.4899 - val_mae: 1.9879 - val_mse: 7.4899\n",
      "Epoch 521/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2285 - mae: 1.3870 - mse: 4.2285 - val_loss: 6.2374 - val_mae: 1.8573 - val_mse: 6.2374\n",
      "Epoch 522/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.1301 - mae: 1.4183 - mse: 4.1301 - val_loss: 7.2223 - val_mae: 1.9525 - val_mse: 7.2223\n",
      "Epoch 523/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3508 - mae: 1.4335 - mse: 4.3508 - val_loss: 6.3890 - val_mae: 1.8352 - val_mse: 6.3890\n",
      "Epoch 524/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3054 - mae: 1.3856 - mse: 4.3054 - val_loss: 6.2275 - val_mae: 1.8132 - val_mse: 6.2275\n",
      "Epoch 525/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.2770 - mae: 1.4472 - mse: 4.2770 - val_loss: 6.0092 - val_mae: 1.8153 - val_mse: 6.0092\n",
      "Epoch 526/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.1683 - mae: 1.3964 - mse: 4.1683 - val_loss: 7.0417 - val_mae: 1.9482 - val_mse: 7.0417\n",
      "Epoch 527/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2199 - mae: 1.3944 - mse: 4.2199 - val_loss: 6.8826 - val_mae: 1.8986 - val_mse: 6.8826\n",
      "Epoch 528/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1579 - mae: 1.3758 - mse: 4.1579 - val_loss: 5.8407 - val_mae: 1.7941 - val_mse: 5.8407\n",
      "Epoch 529/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 4.4337 - mae: 1.4377 - mse: 4.4337 - val_loss: 7.2942 - val_mae: 1.9601 - val_mse: 7.2942\n",
      "Epoch 530/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 4.1769 - mae: 1.3856 - mse: 4.1769 - val_loss: 6.4259 - val_mae: 1.8566 - val_mse: 6.4259\n",
      "Epoch 531/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2604 - mae: 1.4101 - mse: 4.2604 - val_loss: 7.1382 - val_mae: 1.9283 - val_mse: 7.1382\n",
      "Epoch 532/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.1948 - mae: 1.4181 - mse: 4.1948 - val_loss: 7.5399 - val_mae: 1.9980 - val_mse: 7.5399\n",
      "Epoch 533/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.3269 - mae: 1.3948 - mse: 4.3269 - val_loss: 6.0025 - val_mae: 1.7926 - val_mse: 6.0025\n",
      "Epoch 534/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1677 - mae: 1.4121 - mse: 4.1677 - val_loss: 6.1927 - val_mae: 1.8499 - val_mse: 6.1927\n",
      "Epoch 535/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.1483 - mae: 1.3677 - mse: 4.1483 - val_loss: 6.6976 - val_mae: 1.8696 - val_mse: 6.6976\n",
      "Epoch 536/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.3446 - mae: 1.3925 - mse: 4.3446 - val_loss: 7.0536 - val_mae: 1.9018 - val_mse: 7.0536\n",
      "Epoch 537/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2087 - mae: 1.3914 - mse: 4.2087 - val_loss: 6.3231 - val_mae: 1.8222 - val_mse: 6.3231\n",
      "Epoch 538/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 4.1428 - mae: 1.3877 - mse: 4.1428 - val_loss: 6.6587 - val_mae: 1.8518 - val_mse: 6.6587\n",
      "Epoch 539/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.3537 - mae: 1.4179 - mse: 4.3537 - val_loss: 6.7299 - val_mae: 1.8742 - val_mse: 6.7299\n",
      "Epoch 540/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.1273 - mae: 1.3852 - mse: 4.1273 - val_loss: 6.7656 - val_mae: 1.8761 - val_mse: 6.7656\n",
      "Epoch 541/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2598 - mae: 1.3644 - mse: 4.2598 - val_loss: 6.8831 - val_mae: 1.9055 - val_mse: 6.8831\n",
      "Epoch 542/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0588 - mae: 1.3730 - mse: 4.0588 - val_loss: 6.2853 - val_mae: 1.7948 - val_mse: 6.2853\n",
      "Epoch 543/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3204 - mae: 1.4220 - mse: 4.3204 - val_loss: 6.2315 - val_mae: 1.8384 - val_mse: 6.2315\n",
      "Epoch 544/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2244 - mae: 1.3866 - mse: 4.2244 - val_loss: 6.0156 - val_mae: 1.7981 - val_mse: 6.0156\n",
      "Epoch 545/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9909 - mae: 1.3489 - mse: 3.9909 - val_loss: 7.0174 - val_mae: 1.9310 - val_mse: 7.0174\n",
      "Epoch 546/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.1105 - mae: 1.3730 - mse: 4.1105 - val_loss: 6.1554 - val_mae: 1.8419 - val_mse: 6.1554\n",
      "Epoch 547/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.1453 - mae: 1.3706 - mse: 4.1453 - val_loss: 6.1769 - val_mae: 1.8540 - val_mse: 6.1769\n",
      "Epoch 548/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.3079 - mae: 1.4210 - mse: 4.3079 - val_loss: 6.4850 - val_mae: 1.8574 - val_mse: 6.4850\n",
      "Epoch 549/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.0439 - mae: 1.3770 - mse: 4.0439 - val_loss: 6.2384 - val_mae: 1.8172 - val_mse: 6.2384\n",
      "Epoch 550/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1715 - mae: 1.3807 - mse: 4.1715 - val_loss: 5.9752 - val_mae: 1.8111 - val_mse: 5.9752\n",
      "Epoch 551/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.4320 - mae: 1.4134 - mse: 4.4320 - val_loss: 5.9446 - val_mae: 1.7748 - val_mse: 5.9446\n",
      "Epoch 552/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1112 - mae: 1.3836 - mse: 4.1112 - val_loss: 6.2479 - val_mae: 1.8550 - val_mse: 6.2479\n",
      "Epoch 553/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1919 - mae: 1.3684 - mse: 4.1919 - val_loss: 6.8446 - val_mae: 1.8871 - val_mse: 6.8446\n",
      "Epoch 554/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.0017 - mae: 1.3533 - mse: 4.0017 - val_loss: 6.0064 - val_mae: 1.8807 - val_mse: 6.0064\n",
      "Epoch 555/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.2065 - mae: 1.4346 - mse: 4.2065 - val_loss: 6.2876 - val_mae: 1.8568 - val_mse: 6.2876\n",
      "Epoch 556/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0689 - mae: 1.3395 - mse: 4.0689 - val_loss: 6.0918 - val_mae: 1.8116 - val_mse: 6.0918\n",
      "Epoch 557/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.1159 - mae: 1.3627 - mse: 4.1159 - val_loss: 6.6321 - val_mae: 1.8842 - val_mse: 6.6321\n",
      "Epoch 558/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.0825 - mae: 1.3688 - mse: 4.0825 - val_loss: 5.9632 - val_mae: 1.8388 - val_mse: 5.9632\n",
      "Epoch 559/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.2574 - mae: 1.4148 - mse: 4.2574 - val_loss: 6.4024 - val_mae: 1.8438 - val_mse: 6.4024\n",
      "Epoch 560/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0167 - mae: 1.3541 - mse: 4.0167 - val_loss: 6.8263 - val_mae: 1.9540 - val_mse: 6.8263\n",
      "Epoch 561/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1894 - mae: 1.3835 - mse: 4.1894 - val_loss: 5.9704 - val_mae: 1.7780 - val_mse: 5.9704\n",
      "Epoch 562/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2939 - mae: 1.3987 - mse: 4.2939 - val_loss: 6.0811 - val_mae: 1.8096 - val_mse: 6.0811\n",
      "Epoch 563/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9297 - mae: 1.3439 - mse: 3.9297 - val_loss: 6.0368 - val_mae: 1.8758 - val_mse: 6.0368\n",
      "Epoch 564/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 3.5503 - mae: 1.4225 - mse: 3.550 - 0s 44us/sample - loss: 4.1040 - mae: 1.4049 - mse: 4.1040 - val_loss: 6.3356 - val_mae: 1.8509 - val_mse: 6.3356\n",
      "Epoch 565/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.1907 - mae: 1.4063 - mse: 4.1907 - val_loss: 7.4273 - val_mae: 1.9702 - val_mse: 7.4273\n",
      "Epoch 566/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.1168 - mae: 1.3696 - mse: 4.1168 - val_loss: 7.0592 - val_mae: 1.9224 - val_mse: 7.0592\n",
      "Epoch 567/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9951 - mae: 1.3314 - mse: 3.9951 - val_loss: 6.5074 - val_mae: 1.8792 - val_mse: 6.5074\n",
      "Epoch 568/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.0636 - mae: 1.3542 - mse: 4.0636 - val_loss: 6.7747 - val_mae: 1.8709 - val_mse: 6.7747\n",
      "Epoch 569/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.3587 - mae: 1.3877 - mse: 4.3587 - val_loss: 6.4473 - val_mae: 1.8538 - val_mse: 6.4473\n",
      "Epoch 570/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0298 - mae: 1.3350 - mse: 4.0298 - val_loss: 6.4995 - val_mae: 1.8568 - val_mse: 6.4995\n",
      "Epoch 571/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.1082 - mae: 1.3483 - mse: 4.1082 - val_loss: 6.0131 - val_mae: 1.7977 - val_mse: 6.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 572/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0570 - mae: 1.3489 - mse: 4.0570 - val_loss: 6.5723 - val_mae: 1.8563 - val_mse: 6.5723\n",
      "Epoch 573/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.0876 - mae: 1.3673 - mse: 4.0876 - val_loss: 6.8594 - val_mae: 1.9410 - val_mse: 6.8594\n",
      "Epoch 574/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1844 - mae: 1.3805 - mse: 4.1844 - val_loss: 7.5312 - val_mae: 1.9618 - val_mse: 7.5312\n",
      "Epoch 575/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 4.0916 - mae: 1.3568 - mse: 4.0916 - val_loss: 6.6333 - val_mae: 1.8478 - val_mse: 6.6333\n",
      "Epoch 576/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1460 - mae: 1.3448 - mse: 4.1460 - val_loss: 6.9653 - val_mae: 1.9297 - val_mse: 6.9653\n",
      "Epoch 577/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.1742 - mae: 1.3523 - mse: 4.1742 - val_loss: 7.2998 - val_mae: 1.9892 - val_mse: 7.2998\n",
      "Epoch 578/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.0264 - mae: 1.3739 - mse: 4.0264 - val_loss: 7.4341 - val_mae: 1.9746 - val_mse: 7.4341\n",
      "Epoch 579/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 4.1174 - mae: 1.3509 - mse: 4.1174 - val_loss: 7.2574 - val_mae: 1.9515 - val_mse: 7.2574\n",
      "Epoch 580/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.1278 - mae: 1.3948 - mse: 4.1278 - val_loss: 6.9229 - val_mae: 1.9465 - val_mse: 6.9229\n",
      "Epoch 581/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1028 - mae: 1.3556 - mse: 4.1028 - val_loss: 6.3980 - val_mae: 1.8720 - val_mse: 6.3980\n",
      "Epoch 582/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.0620 - mae: 1.3566 - mse: 4.0620 - val_loss: 6.8349 - val_mae: 1.9529 - val_mse: 6.8349\n",
      "Epoch 583/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.0667 - mae: 1.3748 - mse: 4.0667 - val_loss: 6.4330 - val_mae: 1.8411 - val_mse: 6.4330\n",
      "Epoch 584/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.0641 - mae: 1.3890 - mse: 4.0641 - val_loss: 6.9033 - val_mae: 1.9251 - val_mse: 6.9033\n",
      "Epoch 585/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.0640 - mae: 1.3487 - mse: 4.0640 - val_loss: 6.6066 - val_mae: 1.9174 - val_mse: 6.6066\n",
      "Epoch 586/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0825 - mae: 1.3796 - mse: 4.0825 - val_loss: 6.7414 - val_mae: 1.8940 - val_mse: 6.7414\n",
      "Epoch 587/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9253 - mae: 1.3373 - mse: 3.9253 - val_loss: 7.2411 - val_mae: 1.9249 - val_mse: 7.2411\n",
      "Epoch 588/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.2190 - mae: 1.3487 - mse: 4.2190 - val_loss: 6.2637 - val_mae: 1.8283 - val_mse: 6.2637\n",
      "Epoch 589/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9771 - mae: 1.3720 - mse: 3.9771 - val_loss: 6.3352 - val_mae: 1.8489 - val_mse: 6.3352\n",
      "Epoch 590/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.1536 - mae: 1.3869 - mse: 4.1536 - val_loss: 7.4346 - val_mae: 1.9570 - val_mse: 7.4346\n",
      "Epoch 591/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9753 - mae: 1.3546 - mse: 3.9753 - val_loss: 7.4977 - val_mae: 1.9739 - val_mse: 7.4977\n",
      "Epoch 592/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.1008 - mae: 1.3692 - mse: 4.1008 - val_loss: 7.1541 - val_mae: 1.9326 - val_mse: 7.1541\n",
      "Epoch 593/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9402 - mae: 1.3272 - mse: 3.9402 - val_loss: 6.2153 - val_mae: 1.8251 - val_mse: 6.2153\n",
      "Epoch 594/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9419 - mae: 1.3665 - mse: 3.9419 - val_loss: 6.1859 - val_mae: 1.8292 - val_mse: 6.1859\n",
      "Epoch 595/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9845 - mae: 1.3711 - mse: 3.9845 - val_loss: 6.7705 - val_mae: 1.9108 - val_mse: 6.7705\n",
      "Epoch 596/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.0950 - mae: 1.3961 - mse: 4.0950 - val_loss: 6.3035 - val_mae: 1.8397 - val_mse: 6.3035\n",
      "Epoch 597/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8646 - mae: 1.3354 - mse: 3.8646 - val_loss: 7.5317 - val_mae: 1.9953 - val_mse: 7.5317\n",
      "Epoch 598/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9568 - mae: 1.3182 - mse: 3.9568 - val_loss: 6.5370 - val_mae: 1.8523 - val_mse: 6.5370\n",
      "Epoch 599/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8527 - mae: 1.3325 - mse: 3.8527 - val_loss: 6.3973 - val_mae: 1.9458 - val_mse: 6.3973\n",
      "Epoch 600/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 4.2485 - mae: 1.3853 - mse: 4.2485 - val_loss: 6.6972 - val_mae: 1.9455 - val_mse: 6.6972\n",
      "Epoch 601/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1334 - mae: 1.3798 - mse: 4.1334 - val_loss: 6.2225 - val_mae: 1.8418 - val_mse: 6.2225\n",
      "Epoch 602/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.9767 - mae: 1.3502 - mse: 3.9767 - val_loss: 7.0554 - val_mae: 1.9085 - val_mse: 7.0554\n",
      "Epoch 603/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.0206 - mae: 1.3751 - mse: 4.0206 - val_loss: 6.6940 - val_mae: 1.8870 - val_mse: 6.6940\n",
      "Epoch 604/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.1304 - mae: 1.3494 - mse: 4.1304 - val_loss: 7.0629 - val_mae: 1.9251 - val_mse: 7.0629\n",
      "Epoch 605/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.0541 - mae: 1.3477 - mse: 4.0541 - val_loss: 6.3456 - val_mae: 1.8343 - val_mse: 6.3456\n",
      "Epoch 606/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8819 - mae: 1.3255 - mse: 3.8819 - val_loss: 6.4027 - val_mae: 1.8521 - val_mse: 6.4027\n",
      "Epoch 607/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.0597 - mae: 1.3725 - mse: 4.0597 - val_loss: 6.3454 - val_mae: 1.8362 - val_mse: 6.3454\n",
      "Epoch 608/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1692 - mae: 1.3881 - mse: 4.1692 - val_loss: 7.7671 - val_mae: 2.0281 - val_mse: 7.7671\n",
      "Epoch 609/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.9689 - mae: 1.3440 - mse: 3.9689 - val_loss: 6.7865 - val_mae: 1.9229 - val_mse: 6.7865\n",
      "Epoch 610/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.9620 - mae: 1.3286 - mse: 3.9620 - val_loss: 6.4643 - val_mae: 1.8977 - val_mse: 6.4643\n",
      "Epoch 611/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.8083 - mae: 1.3055 - mse: 3.8083 - val_loss: 5.9060 - val_mae: 1.8305 - val_mse: 5.9060\n",
      "Epoch 612/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8953 - mae: 1.3604 - mse: 3.8953 - val_loss: 5.9686 - val_mae: 1.8527 - val_mse: 5.9686\n",
      "Epoch 613/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2987 - mae: 1.3545 - mse: 4.2987 - val_loss: 6.0352 - val_mae: 1.8261 - val_mse: 6.0352\n",
      "Epoch 614/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 4.0431 - mae: 1.3779 - mse: 4.0431 - val_loss: 6.5564 - val_mae: 1.8788 - val_mse: 6.5564\n",
      "Epoch 615/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.8949 - mae: 1.3470 - mse: 3.8949 - val_loss: 7.2391 - val_mae: 1.9515 - val_mse: 7.2391\n",
      "Epoch 616/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.2309 - mae: 1.3764 - mse: 4.2309 - val_loss: 6.3998 - val_mae: 1.8360 - val_mse: 6.3998\n",
      "Epoch 617/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.9530 - mae: 1.3316 - mse: 3.9530 - val_loss: 6.0204 - val_mae: 1.8275 - val_mse: 6.0204\n",
      "Epoch 618/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9568 - mae: 1.3599 - mse: 3.9568 - val_loss: 6.3721 - val_mae: 1.8589 - val_mse: 6.3721\n",
      "Epoch 619/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9869 - mae: 1.3551 - mse: 3.9869 - val_loss: 7.0763 - val_mae: 1.9555 - val_mse: 7.0763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9475 - mae: 1.3413 - mse: 3.9475 - val_loss: 7.0276 - val_mae: 1.9190 - val_mse: 7.0276\n",
      "Epoch 621/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8904 - mae: 1.3157 - mse: 3.8904 - val_loss: 7.2622 - val_mae: 2.0027 - val_mse: 7.2622\n",
      "Epoch 622/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9809 - mae: 1.3195 - mse: 3.9809 - val_loss: 6.9634 - val_mae: 1.9277 - val_mse: 6.9634\n",
      "Epoch 623/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0702 - mae: 1.3771 - mse: 4.0702 - val_loss: 7.2145 - val_mae: 1.9571 - val_mse: 7.2145\n",
      "Epoch 624/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 4.0001 - mae: 1.3295 - mse: 4.0001 - val_loss: 6.1287 - val_mae: 1.8150 - val_mse: 6.1287\n",
      "Epoch 625/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9129 - mae: 1.3227 - mse: 3.9129 - val_loss: 6.2376 - val_mae: 1.8267 - val_mse: 6.2376\n",
      "Epoch 626/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.7789 - mae: 1.2952 - mse: 3.7789 - val_loss: 7.4423 - val_mae: 2.0232 - val_mse: 7.4423\n",
      "Epoch 627/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.0320 - mae: 1.3317 - mse: 4.0320 - val_loss: 7.6213 - val_mae: 2.0155 - val_mse: 7.6213\n",
      "Epoch 628/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.8621 - mae: 1.2866 - mse: 3.8621 - val_loss: 6.6686 - val_mae: 1.8817 - val_mse: 6.6686\n",
      "Epoch 629/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0399 - mae: 1.3467 - mse: 4.0399 - val_loss: 6.3577 - val_mae: 1.8552 - val_mse: 6.3577\n",
      "Epoch 630/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.0044 - mae: 1.3537 - mse: 4.0044 - val_loss: 7.0355 - val_mae: 1.8951 - val_mse: 7.0355\n",
      "Epoch 631/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8730 - mae: 1.3078 - mse: 3.8730 - val_loss: 6.5878 - val_mae: 1.8946 - val_mse: 6.5878\n",
      "Epoch 632/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8961 - mae: 1.3141 - mse: 3.8961 - val_loss: 7.1375 - val_mae: 1.9640 - val_mse: 7.1375\n",
      "Epoch 633/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0759 - mae: 1.3434 - mse: 4.0759 - val_loss: 7.6055 - val_mae: 2.0496 - val_mse: 7.6055\n",
      "Epoch 634/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9639 - mae: 1.3353 - mse: 3.9639 - val_loss: 7.8607 - val_mae: 2.0193 - val_mse: 7.8607\n",
      "Epoch 635/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9970 - mae: 1.3634 - mse: 3.9970 - val_loss: 6.7295 - val_mae: 1.8946 - val_mse: 6.7295\n",
      "Epoch 636/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9764 - mae: 1.3608 - mse: 3.9764 - val_loss: 6.5548 - val_mae: 1.8680 - val_mse: 6.5548\n",
      "Epoch 637/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9558 - mae: 1.3445 - mse: 3.9558 - val_loss: 7.0562 - val_mae: 1.9580 - val_mse: 7.0562\n",
      "Epoch 638/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8625 - mae: 1.3336 - mse: 3.8625 - val_loss: 7.7462 - val_mae: 2.0347 - val_mse: 7.7462\n",
      "Epoch 639/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 4.0289 - mae: 1.3638 - mse: 4.0289 - val_loss: 7.2926 - val_mae: 1.9712 - val_mse: 7.2926\n",
      "Epoch 640/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8969 - mae: 1.3259 - mse: 3.8969 - val_loss: 7.1053 - val_mae: 1.9257 - val_mse: 7.1053\n",
      "Epoch 641/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8674 - mae: 1.2880 - mse: 3.8674 - val_loss: 7.4754 - val_mae: 1.9928 - val_mse: 7.4754\n",
      "Epoch 642/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9485 - mae: 1.3592 - mse: 3.9485 - val_loss: 6.6049 - val_mae: 1.8442 - val_mse: 6.6049\n",
      "Epoch 643/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.7732 - mae: 1.2912 - mse: 3.7732 - val_loss: 6.4090 - val_mae: 1.9019 - val_mse: 6.4090\n",
      "Epoch 644/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9634 - mae: 1.3344 - mse: 3.9634 - val_loss: 6.3352 - val_mae: 1.8524 - val_mse: 6.3352\n",
      "Epoch 645/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9880 - mae: 1.3388 - mse: 3.9880 - val_loss: 6.6993 - val_mae: 1.8730 - val_mse: 6.6993\n",
      "Epoch 646/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8427 - mae: 1.3216 - mse: 3.8427 - val_loss: 6.2583 - val_mae: 1.9055 - val_mse: 6.2583\n",
      "Epoch 647/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9733 - mae: 1.3507 - mse: 3.9733 - val_loss: 6.6374 - val_mae: 1.9231 - val_mse: 6.6374\n",
      "Epoch 648/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8851 - mae: 1.3258 - mse: 3.8851 - val_loss: 6.5914 - val_mae: 1.8787 - val_mse: 6.5914\n",
      "Epoch 649/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8143 - mae: 1.3005 - mse: 3.8143 - val_loss: 6.4508 - val_mae: 1.9088 - val_mse: 6.4508\n",
      "Epoch 650/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8848 - mae: 1.3260 - mse: 3.8848 - val_loss: 7.1788 - val_mae: 1.9833 - val_mse: 7.1788\n",
      "Epoch 651/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9920 - mae: 1.3288 - mse: 3.9920 - val_loss: 6.3449 - val_mae: 1.8751 - val_mse: 6.3449\n",
      "Epoch 652/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9459 - mae: 1.3150 - mse: 3.9459 - val_loss: 6.4909 - val_mae: 1.8936 - val_mse: 6.4909\n",
      "Epoch 653/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.8237 - mae: 1.3151 - mse: 3.8237 - val_loss: 6.3450 - val_mae: 1.8597 - val_mse: 6.3450\n",
      "Epoch 654/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9117 - mae: 1.3268 - mse: 3.9117 - val_loss: 6.2790 - val_mae: 1.8382 - val_mse: 6.2790\n",
      "Epoch 655/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9216 - mae: 1.3389 - mse: 3.9216 - val_loss: 6.7699 - val_mae: 1.8972 - val_mse: 6.7699\n",
      "Epoch 656/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9050 - mae: 1.3074 - mse: 3.9050 - val_loss: 7.0279 - val_mae: 1.9371 - val_mse: 7.0279\n",
      "Epoch 657/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.8502 - mae: 1.3122 - mse: 3.8502 - val_loss: 6.4323 - val_mae: 1.8871 - val_mse: 6.4323\n",
      "Epoch 658/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.7612 - mae: 1.2913 - mse: 3.7612 - val_loss: 6.7549 - val_mae: 1.9251 - val_mse: 6.7549\n",
      "Epoch 659/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.9406 - mae: 1.3161 - mse: 3.9406 - val_loss: 6.5582 - val_mae: 1.8780 - val_mse: 6.5582\n",
      "Epoch 660/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.7874 - mae: 1.3147 - mse: 3.7874 - val_loss: 6.5174 - val_mae: 1.8685 - val_mse: 6.5174\n",
      "Epoch 661/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8300 - mae: 1.3297 - mse: 3.8300 - val_loss: 6.9825 - val_mae: 1.9431 - val_mse: 6.9825\n",
      "Epoch 662/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8059 - mae: 1.2921 - mse: 3.8059 - val_loss: 6.5195 - val_mae: 1.8587 - val_mse: 6.5195\n",
      "Epoch 663/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 3.7737 - mae: 1.3366 - mse: 3.7737 - val_loss: 8.1322 - val_mae: 2.0758 - val_mse: 8.1322\n",
      "Epoch 664/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.8799 - mae: 1.2965 - mse: 3.8799 - val_loss: 7.3116 - val_mae: 1.9714 - val_mse: 7.3116\n",
      "Epoch 665/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9220 - mae: 1.3084 - mse: 3.9220 - val_loss: 6.3182 - val_mae: 1.8377 - val_mse: 6.3182\n",
      "Epoch 666/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9193 - mae: 1.3176 - mse: 3.9193 - val_loss: 6.2786 - val_mae: 1.8437 - val_mse: 6.2786\n",
      "Epoch 667/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8078 - mae: 1.2918 - mse: 3.8078 - val_loss: 6.5317 - val_mae: 1.9152 - val_mse: 6.5317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8994 - mae: 1.3668 - mse: 3.8994 - val_loss: 7.5077 - val_mae: 2.0377 - val_mse: 7.5077\n",
      "Epoch 669/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 3.7686 - mae: 1.2940 - mse: 3.7686 - val_loss: 7.2410 - val_mae: 2.0218 - val_mse: 7.2410\n",
      "Epoch 670/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6747 - mae: 1.3054 - mse: 3.6747 - val_loss: 7.0598 - val_mae: 1.9680 - val_mse: 7.0598\n",
      "Epoch 671/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.2206 - mae: 1.3609 - mse: 4.2206 - val_loss: 7.3162 - val_mae: 2.0302 - val_mse: 7.3162\n",
      "Epoch 672/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6793 - mae: 1.3065 - mse: 3.6793 - val_loss: 6.8443 - val_mae: 1.9042 - val_mse: 6.8443\n",
      "Epoch 673/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6566 - mae: 1.2760 - mse: 3.6566 - val_loss: 6.7335 - val_mae: 1.9223 - val_mse: 6.7335\n",
      "Epoch 674/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9721 - mae: 1.3243 - mse: 3.9721 - val_loss: 7.1369 - val_mae: 1.9447 - val_mse: 7.1369\n",
      "Epoch 675/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8056 - mae: 1.3337 - mse: 3.8056 - val_loss: 6.6724 - val_mae: 1.8710 - val_mse: 6.6724\n",
      "Epoch 676/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 4.0318 - mae: 1.3184 - mse: 4.0318 - val_loss: 6.4040 - val_mae: 1.8520 - val_mse: 6.4040\n",
      "Epoch 677/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8120 - mae: 1.3103 - mse: 3.8120 - val_loss: 7.0239 - val_mae: 1.9251 - val_mse: 7.0239\n",
      "Epoch 678/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6702 - mae: 1.2607 - mse: 3.6702 - val_loss: 6.4825 - val_mae: 1.8650 - val_mse: 6.4825\n",
      "Epoch 679/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.9067 - mae: 1.3222 - mse: 3.9067 - val_loss: 6.6991 - val_mae: 1.8972 - val_mse: 6.6991\n",
      "Epoch 680/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8819 - mae: 1.3315 - mse: 3.8819 - val_loss: 6.7589 - val_mae: 1.9601 - val_mse: 6.7589\n",
      "Epoch 681/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8714 - mae: 1.3238 - mse: 3.8714 - val_loss: 6.5286 - val_mae: 1.8530 - val_mse: 6.5286\n",
      "Epoch 682/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.6322 - mae: 1.2573 - mse: 3.6322 - val_loss: 6.5523 - val_mae: 1.8626 - val_mse: 6.5523\n",
      "Epoch 683/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.7379 - mae: 1.2955 - mse: 3.7379 - val_loss: 7.4041 - val_mae: 1.9481 - val_mse: 7.4041\n",
      "Epoch 684/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.9809 - mae: 1.3471 - mse: 3.9809 - val_loss: 6.8532 - val_mae: 1.8995 - val_mse: 6.8532\n",
      "Epoch 685/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.7733 - mae: 1.2995 - mse: 3.7733 - val_loss: 6.8759 - val_mae: 1.9190 - val_mse: 6.8759\n",
      "Epoch 686/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 3.6491 - mae: 1.2855 - mse: 3.6491 - val_loss: 7.0546 - val_mae: 1.9602 - val_mse: 7.0546\n",
      "Epoch 687/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8625 - mae: 1.3102 - mse: 3.8625 - val_loss: 7.0240 - val_mae: 1.9301 - val_mse: 7.0240\n",
      "Epoch 688/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.7629 - mae: 1.2929 - mse: 3.7629 - val_loss: 7.4016 - val_mae: 1.9840 - val_mse: 7.4016\n",
      "Epoch 689/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.8030 - mae: 1.2943 - mse: 3.8030 - val_loss: 6.4205 - val_mae: 1.8744 - val_mse: 6.4205\n",
      "Epoch 690/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 4.0185 - mae: 1.3604 - mse: 4.0185 - val_loss: 6.5940 - val_mae: 1.8708 - val_mse: 6.5940\n",
      "Epoch 691/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.9361 - mae: 1.3540 - mse: 3.9361 - val_loss: 7.1458 - val_mae: 1.9526 - val_mse: 7.1458\n",
      "Epoch 692/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.6590 - mae: 1.2957 - mse: 3.6590 - val_loss: 7.0361 - val_mae: 1.9238 - val_mse: 7.0361\n",
      "Epoch 693/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.8335 - mae: 1.3212 - mse: 3.8335 - val_loss: 7.1903 - val_mae: 1.9489 - val_mse: 7.1903\n",
      "Epoch 694/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.8121 - mae: 1.3071 - mse: 3.8121 - val_loss: 6.5377 - val_mae: 1.9043 - val_mse: 6.5377\n",
      "Epoch 695/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.7200 - mae: 1.3005 - mse: 3.7200 - val_loss: 6.7724 - val_mae: 1.8766 - val_mse: 6.7724\n",
      "Epoch 696/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.6841 - mae: 1.2830 - mse: 3.6841 - val_loss: 6.4452 - val_mae: 1.8857 - val_mse: 6.4452\n",
      "Epoch 697/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 4.1495 - mae: 1.3931 - mse: 4.1495 - val_loss: 7.5383 - val_mae: 2.0221 - val_mse: 7.5383\n",
      "Epoch 698/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.7083 - mae: 1.2627 - mse: 3.7083 - val_loss: 6.5238 - val_mae: 1.8864 - val_mse: 6.5238\n",
      "Epoch 699/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.6680 - mae: 1.2820 - mse: 3.6680 - val_loss: 6.5629 - val_mae: 1.8592 - val_mse: 6.5629\n",
      "Epoch 700/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.5995 - mae: 1.2814 - mse: 3.5995 - val_loss: 7.3918 - val_mae: 2.0292 - val_mse: 7.3918\n",
      "Epoch 701/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.7706 - mae: 1.3242 - mse: 3.7706 - val_loss: 6.9870 - val_mae: 1.9335 - val_mse: 6.9870\n",
      "Epoch 702/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6727 - mae: 1.2429 - mse: 3.6727 - val_loss: 6.2803 - val_mae: 1.8367 - val_mse: 6.2803\n",
      "Epoch 703/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.8633 - mae: 1.3033 - mse: 3.8633 - val_loss: 6.5178 - val_mae: 1.8811 - val_mse: 6.5178\n",
      "Epoch 704/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 3.6201 - mae: 1.2729 - mse: 3.6201 - val_loss: 6.9857 - val_mae: 1.9167 - val_mse: 6.9857\n",
      "Epoch 705/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.6727 - mae: 1.3043 - mse: 3.6727 - val_loss: 6.5098 - val_mae: 1.8808 - val_mse: 6.5098\n",
      "Epoch 706/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.7229 - mae: 1.2890 - mse: 3.7229 - val_loss: 6.2869 - val_mae: 1.8413 - val_mse: 6.2869\n",
      "Epoch 707/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6184 - mae: 1.2596 - mse: 3.6184 - val_loss: 6.4779 - val_mae: 1.8765 - val_mse: 6.4779\n",
      "Epoch 708/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.8321 - mae: 1.2909 - mse: 3.8321 - val_loss: 6.5325 - val_mae: 1.8727 - val_mse: 6.5325\n",
      "Epoch 709/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.7411 - mae: 1.3214 - mse: 3.7411 - val_loss: 7.0607 - val_mae: 1.9414 - val_mse: 7.0607\n",
      "Epoch 710/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5999 - mae: 1.2622 - mse: 3.5999 - val_loss: 6.1813 - val_mae: 1.8810 - val_mse: 6.1813\n",
      "Epoch 711/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 3.7696 - mae: 1.2665 - mse: 3.7696 - val_loss: 6.7448 - val_mae: 1.8821 - val_mse: 6.7448\n",
      "Epoch 712/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6635 - mae: 1.2952 - mse: 3.6635 - val_loss: 6.9498 - val_mae: 1.9022 - val_mse: 6.9498\n",
      "Epoch 713/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6280 - mae: 1.2595 - mse: 3.6280 - val_loss: 7.4310 - val_mae: 1.9670 - val_mse: 7.4310\n",
      "Epoch 714/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6580 - mae: 1.2624 - mse: 3.6580 - val_loss: 6.5277 - val_mae: 1.8875 - val_mse: 6.5277\n",
      "Epoch 715/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.6731 - mae: 1.2850 - mse: 3.6731 - val_loss: 6.4818 - val_mae: 1.8500 - val_mse: 6.4818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 3.8341 - mae: 1.3231 - mse: 3.8341 - val_loss: 7.2579 - val_mae: 1.9544 - val_mse: 7.2579\n",
      "Epoch 717/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.5785 - mae: 1.2565 - mse: 3.5785 - val_loss: 6.7313 - val_mae: 1.9061 - val_mse: 6.7313\n",
      "Epoch 718/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 3.7327 - mae: 1.2856 - mse: 3.7327 - val_loss: 6.6808 - val_mae: 1.9130 - val_mse: 6.6808\n",
      "Epoch 719/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.6054 - mae: 1.2640 - mse: 3.6054 - val_loss: 6.1193 - val_mae: 1.8477 - val_mse: 6.1193\n",
      "Epoch 720/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6570 - mae: 1.3037 - mse: 3.6570 - val_loss: 6.8686 - val_mae: 1.9029 - val_mse: 6.8686\n",
      "Epoch 721/1000\n",
      "250/250 [==============================] - 0s 76us/sample - loss: 3.6221 - mae: 1.2652 - mse: 3.6221 - val_loss: 8.3177 - val_mae: 2.0931 - val_mse: 8.3177\n",
      "Epoch 722/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.8813 - mae: 1.3059 - mse: 3.8813 - val_loss: 6.9371 - val_mae: 2.0084 - val_mse: 6.9371\n",
      "Epoch 723/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6722 - mae: 1.2792 - mse: 3.6722 - val_loss: 6.6358 - val_mae: 1.8985 - val_mse: 6.6358\n",
      "Epoch 724/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 3.7048 - mae: 1.2693 - mse: 3.7048 - val_loss: 7.2551 - val_mae: 1.9651 - val_mse: 7.2551\n",
      "Epoch 725/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.7027 - mae: 1.2894 - mse: 3.7027 - val_loss: 6.8576 - val_mae: 1.9347 - val_mse: 6.8576\n",
      "Epoch 726/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.8303 - mae: 1.3446 - mse: 3.8303 - val_loss: 6.5084 - val_mae: 1.8602 - val_mse: 6.5084\n",
      "Epoch 727/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6751 - mae: 1.2827 - mse: 3.6751 - val_loss: 7.5872 - val_mae: 2.0417 - val_mse: 7.5872\n",
      "Epoch 728/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 3.7264 - mae: 1.2938 - mse: 3.7264 - val_loss: 7.1025 - val_mae: 1.9375 - val_mse: 7.1025\n",
      "Epoch 729/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.8740 - mae: 1.2854 - mse: 3.8740 - val_loss: 6.9270 - val_mae: 1.9120 - val_mse: 6.9270\n",
      "Epoch 730/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4907 - mae: 1.2602 - mse: 3.4907 - val_loss: 8.6750 - val_mae: 2.1348 - val_mse: 8.6750\n",
      "Epoch 731/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.7434 - mae: 1.2805 - mse: 3.7434 - val_loss: 7.4370 - val_mae: 2.0152 - val_mse: 7.4370\n",
      "Epoch 732/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6547 - mae: 1.2810 - mse: 3.6547 - val_loss: 7.8195 - val_mae: 2.0188 - val_mse: 7.8195\n",
      "Epoch 733/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 3.8035 - mae: 1.2949 - mse: 3.8035 - val_loss: 6.6333 - val_mae: 1.8713 - val_mse: 6.6333\n",
      "Epoch 734/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5552 - mae: 1.2549 - mse: 3.5552 - val_loss: 6.5062 - val_mae: 1.8806 - val_mse: 6.5062\n",
      "Epoch 735/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8334 - mae: 1.3120 - mse: 3.8334 - val_loss: 6.8146 - val_mae: 1.9210 - val_mse: 6.8146\n",
      "Epoch 736/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.7878 - mae: 1.3045 - mse: 3.7878 - val_loss: 6.7660 - val_mae: 1.8947 - val_mse: 6.7660\n",
      "Epoch 737/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.7505 - mae: 1.3225 - mse: 3.7505 - val_loss: 8.1543 - val_mae: 2.0885 - val_mse: 8.1543\n",
      "Epoch 738/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5447 - mae: 1.2631 - mse: 3.5447 - val_loss: 6.8242 - val_mae: 1.8843 - val_mse: 6.8242\n",
      "Epoch 739/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.6609 - mae: 1.2632 - mse: 3.6609 - val_loss: 6.2836 - val_mae: 1.8424 - val_mse: 6.2836\n",
      "Epoch 740/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6561 - mae: 1.2944 - mse: 3.6561 - val_loss: 6.8122 - val_mae: 1.8968 - val_mse: 6.8122\n",
      "Epoch 741/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.7249 - mae: 1.2929 - mse: 3.7249 - val_loss: 6.3233 - val_mae: 1.8897 - val_mse: 6.3233\n",
      "Epoch 742/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5465 - mae: 1.2667 - mse: 3.5465 - val_loss: 7.5109 - val_mae: 2.0226 - val_mse: 7.5109\n",
      "Epoch 743/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5217 - mae: 1.2378 - mse: 3.5217 - val_loss: 7.7914 - val_mae: 2.0998 - val_mse: 7.7914\n",
      "Epoch 744/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 3.7201 - mae: 1.2738 - mse: 3.7201 - val_loss: 6.9280 - val_mae: 1.9536 - val_mse: 6.9280\n",
      "Epoch 745/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6116 - mae: 1.2550 - mse: 3.6116 - val_loss: 6.7204 - val_mae: 1.8934 - val_mse: 6.7204\n",
      "Epoch 746/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.7779 - mae: 1.3122 - mse: 3.7779 - val_loss: 6.9092 - val_mae: 1.9423 - val_mse: 6.9092\n",
      "Epoch 747/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.4774 - mae: 1.2155 - mse: 3.4774 - val_loss: 6.3174 - val_mae: 1.8448 - val_mse: 6.3174\n",
      "Epoch 748/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.7131 - mae: 1.2720 - mse: 3.7131 - val_loss: 6.7522 - val_mae: 1.9412 - val_mse: 6.7522\n",
      "Epoch 749/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.8033 - mae: 1.3423 - mse: 3.8033 - val_loss: 6.6183 - val_mae: 1.9119 - val_mse: 6.6183\n",
      "Epoch 750/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 3.7132 - mae: 1.2843 - mse: 3.7132 - val_loss: 6.8904 - val_mae: 1.9136 - val_mse: 6.8904\n",
      "Epoch 751/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6471 - mae: 1.2754 - mse: 3.6471 - val_loss: 6.5304 - val_mae: 1.8956 - val_mse: 6.5304\n",
      "Epoch 752/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.5431 - mae: 1.2524 - mse: 3.5431 - val_loss: 7.2882 - val_mae: 1.9576 - val_mse: 7.2881\n",
      "Epoch 753/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 3.4734 - mae: 1.2248 - mse: 3.4734 - val_loss: 7.1740 - val_mae: 1.9599 - val_mse: 7.1740\n",
      "Epoch 754/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.7485 - mae: 1.2911 - mse: 3.7485 - val_loss: 7.3238 - val_mae: 1.9529 - val_mse: 7.3238\n",
      "Epoch 755/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.5489 - mae: 1.2514 - mse: 3.5489 - val_loss: 7.3498 - val_mae: 1.9773 - val_mse: 7.3498\n",
      "Epoch 756/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6801 - mae: 1.2800 - mse: 3.6801 - val_loss: 7.0442 - val_mae: 1.9518 - val_mse: 7.0442\n",
      "Epoch 757/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6304 - mae: 1.2472 - mse: 3.6304 - val_loss: 6.9653 - val_mae: 1.9283 - val_mse: 6.9653\n",
      "Epoch 758/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.6793 - mae: 1.2615 - mse: 3.6793 - val_loss: 7.1563 - val_mae: 1.9592 - val_mse: 7.1563\n",
      "Epoch 759/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5518 - mae: 1.2316 - mse: 3.5518 - val_loss: 7.1975 - val_mae: 1.9615 - val_mse: 7.1975\n",
      "Epoch 760/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.5364 - mae: 1.2396 - mse: 3.5364 - val_loss: 8.2462 - val_mae: 2.0919 - val_mse: 8.2462\n",
      "Epoch 761/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.8321 - mae: 1.2878 - mse: 3.8321 - val_loss: 7.2347 - val_mae: 1.9629 - val_mse: 7.2347\n",
      "Epoch 762/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.5019 - mae: 1.2557 - mse: 3.5019 - val_loss: 7.5206 - val_mae: 2.0311 - val_mse: 7.5206\n",
      "Epoch 763/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.7191 - mae: 1.2349 - mse: 3.7191 - val_loss: 6.9419 - val_mae: 1.9239 - val_mse: 6.9419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 764/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 3.6601 - mae: 1.2361 - mse: 3.6601 - val_loss: 7.8989 - val_mae: 2.0308 - val_mse: 7.8989\n",
      "Epoch 765/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.5605 - mae: 1.2177 - mse: 3.5605 - val_loss: 6.9184 - val_mae: 1.9363 - val_mse: 6.9184\n",
      "Epoch 766/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.5717 - mae: 1.2665 - mse: 3.5717 - val_loss: 6.8196 - val_mae: 1.9233 - val_mse: 6.8196\n",
      "Epoch 767/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 3.6063 - mae: 1.2571 - mse: 3.6063 - val_loss: 6.7480 - val_mae: 1.8924 - val_mse: 6.7480\n",
      "Epoch 768/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6455 - mae: 1.2569 - mse: 3.6455 - val_loss: 6.4392 - val_mae: 1.8864 - val_mse: 6.4392\n",
      "Epoch 769/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.5234 - mae: 1.2474 - mse: 3.5234 - val_loss: 7.8597 - val_mae: 2.0462 - val_mse: 7.8597\n",
      "Epoch 770/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4337 - mae: 1.2376 - mse: 3.4337 - val_loss: 6.4463 - val_mae: 1.8960 - val_mse: 6.4463\n",
      "Epoch 771/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.8482 - mae: 1.3084 - mse: 3.8482 - val_loss: 6.4077 - val_mae: 1.9001 - val_mse: 6.4077\n",
      "Epoch 772/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.5773 - mae: 1.2750 - mse: 3.5773 - val_loss: 6.3995 - val_mae: 1.8515 - val_mse: 6.3995\n",
      "Epoch 773/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 3.4853 - mae: 1.2494 - mse: 3.4853 - val_loss: 8.7655 - val_mae: 2.1377 - val_mse: 8.7655\n",
      "Epoch 774/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 3.7591 - mae: 1.2602 - mse: 3.7591 - val_loss: 6.9477 - val_mae: 1.9744 - val_mse: 6.9477\n",
      "Epoch 775/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.5475 - mae: 1.2529 - mse: 3.5475 - val_loss: 7.2338 - val_mae: 1.9744 - val_mse: 7.2339\n",
      "Epoch 776/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5053 - mae: 1.2427 - mse: 3.5053 - val_loss: 7.9836 - val_mae: 2.1059 - val_mse: 7.9836\n",
      "Epoch 777/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 3.5333 - mae: 1.2337 - mse: 3.5333 - val_loss: 7.8874 - val_mae: 2.0502 - val_mse: 7.8874\n",
      "Epoch 778/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.4759 - mae: 1.2343 - mse: 3.4759 - val_loss: 6.8002 - val_mae: 1.9010 - val_mse: 6.8002\n",
      "Epoch 779/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.6436 - mae: 1.2661 - mse: 3.6436 - val_loss: 7.0581 - val_mae: 1.9814 - val_mse: 7.0581\n",
      "Epoch 780/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4823 - mae: 1.2261 - mse: 3.4823 - val_loss: 7.4371 - val_mae: 1.9697 - val_mse: 7.4371\n",
      "Epoch 781/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.5643 - mae: 1.2800 - mse: 3.5643 - val_loss: 7.3145 - val_mae: 1.9692 - val_mse: 7.3145\n",
      "Epoch 782/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6393 - mae: 1.2919 - mse: 3.6393 - val_loss: 6.8583 - val_mae: 1.9434 - val_mse: 6.8583\n",
      "Epoch 783/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4956 - mae: 1.2186 - mse: 3.4956 - val_loss: 7.2045 - val_mae: 1.9833 - val_mse: 7.2045\n",
      "Epoch 784/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6601 - mae: 1.2603 - mse: 3.6601 - val_loss: 7.1839 - val_mae: 1.9331 - val_mse: 7.1839\n",
      "Epoch 785/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.5212 - mae: 1.2252 - mse: 3.5212 - val_loss: 6.5881 - val_mae: 1.9284 - val_mse: 6.5881\n",
      "Epoch 786/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.5445 - mae: 1.2352 - mse: 3.5445 - val_loss: 7.4231 - val_mae: 1.9743 - val_mse: 7.4231\n",
      "Epoch 787/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.4732 - mae: 1.2484 - mse: 3.4732 - val_loss: 6.7549 - val_mae: 1.9208 - val_mse: 6.7549\n",
      "Epoch 788/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.5683 - mae: 1.2399 - mse: 3.5683 - val_loss: 6.7929 - val_mae: 1.9833 - val_mse: 6.7929\n",
      "Epoch 789/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3664 - mae: 1.2508 - mse: 3.3664 - val_loss: 6.4544 - val_mae: 1.8865 - val_mse: 6.4544\n",
      "Epoch 790/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.5069 - mae: 1.2292 - mse: 3.5069 - val_loss: 7.2204 - val_mae: 1.9810 - val_mse: 7.2204\n",
      "Epoch 791/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.4456 - mae: 1.2343 - mse: 3.4456 - val_loss: 6.6962 - val_mae: 1.9396 - val_mse: 6.6962\n",
      "Epoch 792/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.6379 - mae: 1.2561 - mse: 3.6379 - val_loss: 6.9759 - val_mae: 1.9451 - val_mse: 6.9759\n",
      "Epoch 793/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.6230 - mae: 1.2515 - mse: 3.6230 - val_loss: 6.7782 - val_mae: 1.9833 - val_mse: 6.7782\n",
      "Epoch 794/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.4996 - mae: 1.2419 - mse: 3.4996 - val_loss: 6.8289 - val_mae: 1.9228 - val_mse: 6.8289\n",
      "Epoch 795/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.5165 - mae: 1.2385 - mse: 3.5165 - val_loss: 6.9735 - val_mae: 1.9435 - val_mse: 6.9735\n",
      "Epoch 796/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.4095 - mae: 1.1950 - mse: 3.4095 - val_loss: 6.7523 - val_mae: 1.9352 - val_mse: 6.7523\n",
      "Epoch 797/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.7094 - mae: 1.2849 - mse: 3.7094 - val_loss: 7.4590 - val_mae: 2.0068 - val_mse: 7.4590\n",
      "Epoch 798/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4601 - mae: 1.2221 - mse: 3.4601 - val_loss: 7.2329 - val_mae: 1.9582 - val_mse: 7.2329\n",
      "Epoch 799/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3446 - mae: 1.2036 - mse: 3.3446 - val_loss: 7.1678 - val_mae: 1.9554 - val_mse: 7.1678\n",
      "Epoch 800/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6973 - mae: 1.2523 - mse: 3.6973 - val_loss: 6.5600 - val_mae: 1.8949 - val_mse: 6.5600\n",
      "Epoch 801/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3811 - mae: 1.2133 - mse: 3.3811 - val_loss: 7.6513 - val_mae: 2.0252 - val_mse: 7.6513\n",
      "Epoch 802/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4723 - mae: 1.2366 - mse: 3.4723 - val_loss: 6.4819 - val_mae: 1.8915 - val_mse: 6.4819\n",
      "Epoch 803/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4185 - mae: 1.2585 - mse: 3.4185 - val_loss: 7.5372 - val_mae: 1.9975 - val_mse: 7.5372\n",
      "Epoch 804/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4912 - mae: 1.2242 - mse: 3.4912 - val_loss: 6.4354 - val_mae: 1.8912 - val_mse: 6.4354\n",
      "Epoch 805/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.5022 - mae: 1.2568 - mse: 3.5022 - val_loss: 7.3579 - val_mae: 1.9666 - val_mse: 7.3579\n",
      "Epoch 806/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5064 - mae: 1.2697 - mse: 3.5064 - val_loss: 7.8666 - val_mae: 2.0520 - val_mse: 7.8666\n",
      "Epoch 807/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 3.4780 - mae: 1.2145 - mse: 3.4780 - val_loss: 7.0196 - val_mae: 1.9877 - val_mse: 7.0196\n",
      "Epoch 808/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.4612 - mae: 1.2535 - mse: 3.4612 - val_loss: 6.5789 - val_mae: 1.8979 - val_mse: 6.5789\n",
      "Epoch 809/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.4218 - mae: 1.2240 - mse: 3.4218 - val_loss: 7.3862 - val_mae: 2.0027 - val_mse: 7.3862\n",
      "Epoch 810/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.6865 - mae: 1.2565 - mse: 3.6865 - val_loss: 6.7952 - val_mae: 1.9479 - val_mse: 6.7952\n",
      "Epoch 811/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4574 - mae: 1.2680 - mse: 3.4574 - val_loss: 7.5884 - val_mae: 2.0133 - val_mse: 7.5884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 812/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.5851 - mae: 1.2452 - mse: 3.5851 - val_loss: 6.9414 - val_mae: 1.9278 - val_mse: 6.9414\n",
      "Epoch 813/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.4106 - mae: 1.2389 - mse: 3.4106 - val_loss: 6.9544 - val_mae: 1.9484 - val_mse: 6.9544\n",
      "Epoch 814/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3122 - mae: 1.2123 - mse: 3.3122 - val_loss: 8.1490 - val_mae: 2.0930 - val_mse: 8.1490\n",
      "Epoch 815/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.4143 - mae: 1.2249 - mse: 3.4143 - val_loss: 7.6210 - val_mae: 2.0248 - val_mse: 7.6210\n",
      "Epoch 816/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.6157 - mae: 1.2666 - mse: 3.6157 - val_loss: 7.1335 - val_mae: 1.9407 - val_mse: 7.1335\n",
      "Epoch 817/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.3673 - mae: 1.2284 - mse: 3.3673 - val_loss: 6.4954 - val_mae: 1.8771 - val_mse: 6.4954\n",
      "Epoch 818/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.5017 - mae: 1.2323 - mse: 3.5017 - val_loss: 7.4018 - val_mae: 2.0218 - val_mse: 7.4018\n",
      "Epoch 819/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5833 - mae: 1.2585 - mse: 3.5833 - val_loss: 7.4518 - val_mae: 1.9873 - val_mse: 7.4518\n",
      "Epoch 820/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4214 - mae: 1.2117 - mse: 3.4214 - val_loss: 7.1817 - val_mae: 2.0495 - val_mse: 7.1817\n",
      "Epoch 821/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4277 - mae: 1.2381 - mse: 3.4277 - val_loss: 6.3746 - val_mae: 1.8773 - val_mse: 6.3746\n",
      "Epoch 822/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4362 - mae: 1.2151 - mse: 3.4362 - val_loss: 6.9401 - val_mae: 1.9779 - val_mse: 6.9401\n",
      "Epoch 823/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3378 - mae: 1.1912 - mse: 3.3378 - val_loss: 6.4420 - val_mae: 1.8820 - val_mse: 6.4420\n",
      "Epoch 824/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 3.5290 - mae: 1.1570 - mse: 3.529 - 0s 48us/sample - loss: 3.6056 - mae: 1.2604 - mse: 3.6056 - val_loss: 7.4555 - val_mae: 2.0165 - val_mse: 7.4555\n",
      "Epoch 825/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4666 - mae: 1.2135 - mse: 3.4666 - val_loss: 8.0575 - val_mae: 2.0763 - val_mse: 8.0575\n",
      "Epoch 826/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4139 - mae: 1.2075 - mse: 3.4139 - val_loss: 7.4825 - val_mae: 2.0432 - val_mse: 7.4825\n",
      "Epoch 827/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3830 - mae: 1.2459 - mse: 3.3830 - val_loss: 8.4193 - val_mae: 2.2187 - val_mse: 8.4192\n",
      "Epoch 828/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2738 - mae: 1.2322 - mse: 3.2738 - val_loss: 7.5839 - val_mae: 2.0545 - val_mse: 7.5839\n",
      "Epoch 829/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3963 - mae: 1.1894 - mse: 3.3963 - val_loss: 6.4670 - val_mae: 1.8905 - val_mse: 6.4670\n",
      "Epoch 830/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5520 - mae: 1.2476 - mse: 3.5520 - val_loss: 6.9098 - val_mae: 1.9401 - val_mse: 6.9098\n",
      "Epoch 831/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4309 - mae: 1.2031 - mse: 3.4309 - val_loss: 7.1468 - val_mae: 1.9700 - val_mse: 7.1468\n",
      "Epoch 832/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4465 - mae: 1.2131 - mse: 3.4465 - val_loss: 7.9287 - val_mae: 2.0589 - val_mse: 7.9287\n",
      "Epoch 833/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.3859 - mae: 1.2242 - mse: 3.3859 - val_loss: 7.1934 - val_mae: 1.9598 - val_mse: 7.1934\n",
      "Epoch 834/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4723 - mae: 1.2125 - mse: 3.4723 - val_loss: 6.9722 - val_mae: 1.9648 - val_mse: 6.9722\n",
      "Epoch 835/1000\n",
      "250/250 [==============================] - 0s 80us/sample - loss: 3.2908 - mae: 1.1875 - mse: 3.2908 - val_loss: 7.4459 - val_mae: 1.9746 - val_mse: 7.4459\n",
      "Epoch 836/1000\n",
      "250/250 [==============================] - 0s 76us/sample - loss: 3.4891 - mae: 1.2374 - mse: 3.4891 - val_loss: 6.7972 - val_mae: 1.9670 - val_mse: 6.7972\n",
      "Epoch 837/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 3.4899 - mae: 1.2495 - mse: 3.4899 - val_loss: 7.8866 - val_mae: 2.0504 - val_mse: 7.8866\n",
      "Epoch 838/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 3.3468 - mae: 1.1951 - mse: 3.3468 - val_loss: 6.8855 - val_mae: 1.9668 - val_mse: 6.8855\n",
      "Epoch 839/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 3.3167 - mae: 1.2125 - mse: 3.3167 - val_loss: 8.4571 - val_mae: 2.1133 - val_mse: 8.4571\n",
      "Epoch 840/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.5235 - mae: 1.2020 - mse: 3.5235 - val_loss: 6.6336 - val_mae: 1.9323 - val_mse: 6.6336\n",
      "Epoch 841/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3782 - mae: 1.1969 - mse: 3.3782 - val_loss: 8.5485 - val_mae: 2.1340 - val_mse: 8.5485\n",
      "Epoch 842/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.4909 - mae: 1.2375 - mse: 3.4909 - val_loss: 7.2999 - val_mae: 1.9835 - val_mse: 7.2999\n",
      "Epoch 843/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3589 - mae: 1.2052 - mse: 3.3589 - val_loss: 7.0317 - val_mae: 1.9563 - val_mse: 7.0317\n",
      "Epoch 844/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.2472 - mae: 1.1828 - mse: 3.2472 - val_loss: 8.4190 - val_mae: 2.1268 - val_mse: 8.4190\n",
      "Epoch 845/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.5910 - mae: 1.2360 - mse: 3.5910 - val_loss: 7.2168 - val_mae: 1.9706 - val_mse: 7.2168\n",
      "Epoch 846/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4243 - mae: 1.2014 - mse: 3.4243 - val_loss: 7.4229 - val_mae: 2.0479 - val_mse: 7.4229\n",
      "Epoch 847/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4045 - mae: 1.2076 - mse: 3.4045 - val_loss: 7.6711 - val_mae: 2.0782 - val_mse: 7.6711\n",
      "Epoch 848/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1759 - mae: 1.1651 - mse: 3.1759 - val_loss: 7.2530 - val_mae: 1.9866 - val_mse: 7.2530\n",
      "Epoch 849/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4484 - mae: 1.1989 - mse: 3.4484 - val_loss: 6.3050 - val_mae: 1.8691 - val_mse: 6.3050\n",
      "Epoch 850/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2990 - mae: 1.2200 - mse: 3.2990 - val_loss: 6.5884 - val_mae: 1.9192 - val_mse: 6.5884\n",
      "Epoch 851/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4080 - mae: 1.2510 - mse: 3.4080 - val_loss: 7.5362 - val_mae: 2.0358 - val_mse: 7.5362\n",
      "Epoch 852/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4002 - mae: 1.2083 - mse: 3.4002 - val_loss: 6.6841 - val_mae: 1.9205 - val_mse: 6.6841\n",
      "Epoch 853/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3969 - mae: 1.2032 - mse: 3.3969 - val_loss: 7.9420 - val_mae: 2.0502 - val_mse: 7.9420\n",
      "Epoch 854/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.3097 - mae: 1.1781 - mse: 3.3097 - val_loss: 8.0659 - val_mae: 2.0830 - val_mse: 8.0659\n",
      "Epoch 855/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.3406 - mae: 1.2165 - mse: 3.3406 - val_loss: 8.4124 - val_mae: 2.1957 - val_mse: 8.4124\n",
      "Epoch 856/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1842 - mae: 1.1597 - mse: 3.1842 - val_loss: 6.5858 - val_mae: 1.9014 - val_mse: 6.5858\n",
      "Epoch 857/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2693 - mae: 1.2160 - mse: 3.2693 - val_loss: 6.8978 - val_mae: 1.9133 - val_mse: 6.8978\n",
      "Epoch 858/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.4589 - mae: 1.2538 - mse: 3.4589 - val_loss: 6.8425 - val_mae: 1.9616 - val_mse: 6.8425\n",
      "Epoch 859/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 40us/sample - loss: 3.2013 - mae: 1.1761 - mse: 3.2013 - val_loss: 7.2631 - val_mae: 1.9880 - val_mse: 7.2631\n",
      "Epoch 860/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4310 - mae: 1.2384 - mse: 3.4310 - val_loss: 7.2870 - val_mae: 2.0182 - val_mse: 7.2870\n",
      "Epoch 861/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.2808 - mae: 1.1716 - mse: 3.2808 - val_loss: 7.3060 - val_mae: 2.0064 - val_mse: 7.3060\n",
      "Epoch 862/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 3.4458 - mae: 1.2194 - mse: 3.4458 - val_loss: 7.7510 - val_mae: 2.0417 - val_mse: 7.7510\n",
      "Epoch 863/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3247 - mae: 1.1971 - mse: 3.3247 - val_loss: 8.8047 - val_mae: 2.1886 - val_mse: 8.8047\n",
      "Epoch 864/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.3443 - mae: 1.1797 - mse: 3.3443 - val_loss: 7.6997 - val_mae: 2.0351 - val_mse: 7.6997\n",
      "Epoch 865/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2141 - mae: 1.1671 - mse: 3.2141 - val_loss: 6.9782 - val_mae: 1.9569 - val_mse: 6.9782\n",
      "Epoch 866/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.1541 - mae: 1.1606 - mse: 3.1541 - val_loss: 7.2408 - val_mae: 2.0191 - val_mse: 7.2408\n",
      "Epoch 867/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3852 - mae: 1.2089 - mse: 3.3852 - val_loss: 7.9145 - val_mae: 2.1031 - val_mse: 7.9145\n",
      "Epoch 868/1000\n",
      "250/250 [==============================] - 0s 64us/sample - loss: 3.2315 - mae: 1.1858 - mse: 3.2315 - val_loss: 6.8935 - val_mae: 1.9575 - val_mse: 6.8935\n",
      "Epoch 869/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2634 - mae: 1.2185 - mse: 3.2634 - val_loss: 8.6398 - val_mae: 2.2041 - val_mse: 8.6398\n",
      "Epoch 870/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 3.2246 - mae: 1.1535 - mse: 3.2246 - val_loss: 7.0494 - val_mae: 2.0051 - val_mse: 7.0494\n",
      "Epoch 871/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4236 - mae: 1.2375 - mse: 3.4236 - val_loss: 7.1400 - val_mae: 2.0235 - val_mse: 7.1400\n",
      "Epoch 872/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.2452 - mae: 1.2167 - mse: 3.2452 - val_loss: 7.4044 - val_mae: 1.9727 - val_mse: 7.4044\n",
      "Epoch 873/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.3968 - mae: 1.2175 - mse: 3.3968 - val_loss: 7.2244 - val_mae: 2.0043 - val_mse: 7.2244\n",
      "Epoch 874/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.1878 - mae: 1.1588 - mse: 3.1878 - val_loss: 7.3387 - val_mae: 2.0808 - val_mse: 7.3387\n",
      "Epoch 875/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3736 - mae: 1.2583 - mse: 3.3736 - val_loss: 7.5308 - val_mae: 2.0378 - val_mse: 7.5308\n",
      "Epoch 876/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2997 - mae: 1.1654 - mse: 3.2997 - val_loss: 6.7225 - val_mae: 1.9272 - val_mse: 6.7225\n",
      "Epoch 877/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.5964 - mae: 1.2172 - mse: 3.5964 - val_loss: 7.2134 - val_mae: 1.9788 - val_mse: 7.2134\n",
      "Epoch 878/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2167 - mae: 1.1741 - mse: 3.2167 - val_loss: 7.3501 - val_mae: 2.0539 - val_mse: 7.3501\n",
      "Epoch 879/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4200 - mae: 1.2193 - mse: 3.4200 - val_loss: 7.3050 - val_mae: 1.9948 - val_mse: 7.3050\n",
      "Epoch 880/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1947 - mae: 1.1735 - mse: 3.1947 - val_loss: 7.7609 - val_mae: 2.0638 - val_mse: 7.7609\n",
      "Epoch 881/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.5208 - mae: 1.2228 - mse: 3.5208 - val_loss: 7.8173 - val_mae: 2.0412 - val_mse: 7.8173\n",
      "Epoch 882/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1917 - mae: 1.1457 - mse: 3.1917 - val_loss: 6.6692 - val_mae: 1.9273 - val_mse: 6.6692\n",
      "Epoch 883/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.4408 - mae: 1.2006 - mse: 3.4408 - val_loss: 6.9508 - val_mae: 1.9750 - val_mse: 6.9508\n",
      "Epoch 884/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.3371 - mae: 1.2201 - mse: 3.3371 - val_loss: 7.0055 - val_mae: 2.0056 - val_mse: 7.0055\n",
      "Epoch 885/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.3551 - mae: 1.1927 - mse: 3.3551 - val_loss: 7.4164 - val_mae: 2.0787 - val_mse: 7.4164\n",
      "Epoch 886/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.3776 - mae: 1.2050 - mse: 3.3776 - val_loss: 7.1018 - val_mae: 1.9859 - val_mse: 7.1018\n",
      "Epoch 887/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.0865 - mae: 1.1553 - mse: 3.0865 - val_loss: 6.8309 - val_mae: 1.9411 - val_mse: 6.8309\n",
      "Epoch 888/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1983 - mae: 1.1883 - mse: 3.1983 - val_loss: 8.2388 - val_mae: 2.0951 - val_mse: 8.2388\n",
      "Epoch 889/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.1649 - mae: 1.1525 - mse: 3.1649 - val_loss: 6.6560 - val_mae: 1.9235 - val_mse: 6.6560\n",
      "Epoch 890/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.2798 - mae: 1.2194 - mse: 3.2798 - val_loss: 7.0668 - val_mae: 2.0071 - val_mse: 7.0668\n",
      "Epoch 891/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.3801 - mae: 1.1798 - mse: 3.3801 - val_loss: 7.1205 - val_mae: 2.0488 - val_mse: 7.1205\n",
      "Epoch 892/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1746 - mae: 1.1683 - mse: 3.1746 - val_loss: 6.7573 - val_mae: 1.9318 - val_mse: 6.7573\n",
      "Epoch 893/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.2922 - mae: 1.1985 - mse: 3.2922 - val_loss: 7.4046 - val_mae: 2.0415 - val_mse: 7.4046\n",
      "Epoch 894/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2232 - mae: 1.2057 - mse: 3.2232 - val_loss: 6.8975 - val_mae: 1.9787 - val_mse: 6.8975\n",
      "Epoch 895/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1658 - mae: 1.1650 - mse: 3.1658 - val_loss: 7.3468 - val_mae: 2.0249 - val_mse: 7.3468\n",
      "Epoch 896/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3607 - mae: 1.2018 - mse: 3.3607 - val_loss: 6.9206 - val_mae: 1.9702 - val_mse: 6.9206\n",
      "Epoch 897/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2922 - mae: 1.2067 - mse: 3.2922 - val_loss: 7.6814 - val_mae: 2.0650 - val_mse: 7.6814\n",
      "Epoch 898/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.4773 - mae: 1.1887 - mse: 3.4773 - val_loss: 7.0314 - val_mae: 2.0043 - val_mse: 7.0314\n",
      "Epoch 899/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0965 - mae: 1.1579 - mse: 3.0965 - val_loss: 6.8142 - val_mae: 1.9560 - val_mse: 6.8142\n",
      "Epoch 900/1000\n",
      "250/250 [==============================] - 0s 36us/sample - loss: 3.2615 - mae: 1.2085 - mse: 3.2615 - val_loss: 7.4376 - val_mae: 2.0130 - val_mse: 7.4376\n",
      "Epoch 901/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3608 - mae: 1.2198 - mse: 3.3608 - val_loss: 6.5743 - val_mae: 1.9112 - val_mse: 6.5743\n",
      "Epoch 902/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3150 - mae: 1.2365 - mse: 3.3150 - val_loss: 8.0328 - val_mae: 2.1744 - val_mse: 8.0328\n",
      "Epoch 903/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.2333 - mae: 1.1571 - mse: 3.2333 - val_loss: 7.0585 - val_mae: 2.0257 - val_mse: 7.0585\n",
      "Epoch 904/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1842 - mae: 1.1585 - mse: 3.1842 - val_loss: 7.0079 - val_mae: 1.9690 - val_mse: 7.0079\n",
      "Epoch 905/1000\n",
      "250/250 [==============================] - 0s 68us/sample - loss: 3.2122 - mae: 1.1510 - mse: 3.2122 - val_loss: 7.0589 - val_mae: 2.0007 - val_mse: 7.0589\n",
      "Epoch 906/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2156 - mae: 1.1511 - mse: 3.2156 - val_loss: 7.1601 - val_mae: 2.0452 - val_mse: 7.1601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3935 - mae: 1.2121 - mse: 3.3935 - val_loss: 7.4027 - val_mae: 2.0277 - val_mse: 7.4027\n",
      "Epoch 908/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.1718 - mae: 1.1765 - mse: 3.1718 - val_loss: 8.4483 - val_mae: 2.1356 - val_mse: 8.4483\n",
      "Epoch 909/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.0574 - mae: 1.1177 - mse: 3.0574 - val_loss: 6.8822 - val_mae: 1.9836 - val_mse: 6.8822\n",
      "Epoch 910/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2723 - mae: 1.1942 - mse: 3.2723 - val_loss: 7.7217 - val_mae: 2.0450 - val_mse: 7.7217\n",
      "Epoch 911/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1591 - mae: 1.1926 - mse: 3.1591 - val_loss: 7.7764 - val_mae: 2.0569 - val_mse: 7.7764\n",
      "Epoch 912/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3076 - mae: 1.2016 - mse: 3.3076 - val_loss: 8.2330 - val_mae: 2.1405 - val_mse: 8.2330\n",
      "Epoch 913/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1876 - mae: 1.1527 - mse: 3.1876 - val_loss: 6.9972 - val_mae: 1.9639 - val_mse: 6.9972\n",
      "Epoch 914/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2992 - mae: 1.1780 - mse: 3.2992 - val_loss: 7.0964 - val_mae: 1.9991 - val_mse: 7.0964\n",
      "Epoch 915/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3144 - mae: 1.2035 - mse: 3.3144 - val_loss: 7.5440 - val_mae: 2.0310 - val_mse: 7.5440\n",
      "Epoch 916/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2062 - mae: 1.1749 - mse: 3.2062 - val_loss: 7.7240 - val_mae: 2.0474 - val_mse: 7.7240\n",
      "Epoch 917/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2070 - mae: 1.1861 - mse: 3.2070 - val_loss: 8.3603 - val_mae: 2.1109 - val_mse: 8.3603\n",
      "Epoch 918/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3355 - mae: 1.1979 - mse: 3.3355 - val_loss: 7.8274 - val_mae: 2.0472 - val_mse: 7.8274\n",
      "Epoch 919/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.0681 - mae: 1.1290 - mse: 3.0681 - val_loss: 7.3323 - val_mae: 2.0249 - val_mse: 7.3323\n",
      "Epoch 920/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2706 - mae: 1.1879 - mse: 3.2706 - val_loss: 8.1029 - val_mae: 2.1084 - val_mse: 8.1029\n",
      "Epoch 921/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.2985 - mae: 1.1606 - mse: 3.2985 - val_loss: 7.2408 - val_mae: 2.0394 - val_mse: 7.2408\n",
      "Epoch 922/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0591 - mae: 1.1576 - mse: 3.0591 - val_loss: 7.7452 - val_mae: 2.0518 - val_mse: 7.7452\n",
      "Epoch 923/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.2062 - mae: 0.8334 - mse: 1.206 - 0s 48us/sample - loss: 3.2714 - mae: 1.2245 - mse: 3.2714 - val_loss: 7.2217 - val_mae: 2.0038 - val_mse: 7.2217\n",
      "Epoch 924/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2180 - mae: 1.1957 - mse: 3.2180 - val_loss: 6.8855 - val_mae: 1.9515 - val_mse: 6.8855\n",
      "Epoch 925/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.1787 - mae: 1.1708 - mse: 3.1787 - val_loss: 7.2426 - val_mae: 2.0349 - val_mse: 7.2426\n",
      "Epoch 926/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1214 - mae: 1.1653 - mse: 3.1214 - val_loss: 7.4024 - val_mae: 2.0126 - val_mse: 7.4024\n",
      "Epoch 927/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1961 - mae: 1.1755 - mse: 3.1961 - val_loss: 6.9552 - val_mae: 1.9409 - val_mse: 6.9552\n",
      "Epoch 928/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.2707 - mae: 1.1546 - mse: 3.2707 - val_loss: 7.0516 - val_mae: 2.0105 - val_mse: 7.0516\n",
      "Epoch 929/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1949 - mae: 1.1965 - mse: 3.1949 - val_loss: 7.4928 - val_mae: 2.0300 - val_mse: 7.4928\n",
      "Epoch 930/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.0061 - mae: 1.1400 - mse: 3.0061 - val_loss: 6.9972 - val_mae: 1.9599 - val_mse: 6.9972\n",
      "Epoch 931/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.3106 - mae: 1.1638 - mse: 3.3106 - val_loss: 7.3731 - val_mae: 1.9929 - val_mse: 7.3731\n",
      "Epoch 932/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.0455 - mae: 1.1797 - mse: 3.0455 - val_loss: 7.4367 - val_mae: 2.0251 - val_mse: 7.4367\n",
      "Epoch 933/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1755 - mae: 1.1855 - mse: 3.1755 - val_loss: 7.1461 - val_mae: 2.0418 - val_mse: 7.1461\n",
      "Epoch 934/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.2553 - mae: 1.1727 - mse: 3.2553 - val_loss: 7.1893 - val_mae: 1.9974 - val_mse: 7.1893\n",
      "Epoch 935/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.3109 - mae: 1.1696 - mse: 3.3109 - val_loss: 7.6023 - val_mae: 2.0438 - val_mse: 7.6023\n",
      "Epoch 936/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0018 - mae: 1.1275 - mse: 3.0018 - val_loss: 7.6129 - val_mae: 2.0353 - val_mse: 7.6129\n",
      "Epoch 937/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.2133 - mae: 1.2080 - mse: 3.2133 - val_loss: 7.8920 - val_mae: 2.1194 - val_mse: 7.8920\n",
      "Epoch 938/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1298 - mae: 1.1868 - mse: 3.1298 - val_loss: 7.6375 - val_mae: 2.0706 - val_mse: 7.6375\n",
      "Epoch 939/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.2006 - mae: 1.1561 - mse: 3.2006 - val_loss: 7.1667 - val_mae: 1.9896 - val_mse: 7.1667\n",
      "Epoch 940/1000\n",
      "250/250 [==============================] - 0s 60us/sample - loss: 3.0397 - mae: 1.1262 - mse: 3.0397 - val_loss: 7.5538 - val_mae: 2.0268 - val_mse: 7.5538\n",
      "Epoch 941/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0560 - mae: 1.1559 - mse: 3.0560 - val_loss: 7.4700 - val_mae: 2.0707 - val_mse: 7.4700\n",
      "Epoch 942/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2357 - mae: 1.1602 - mse: 3.2357 - val_loss: 8.8201 - val_mae: 2.1899 - val_mse: 8.8201\n",
      "Epoch 943/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 2.9299 - mae: 1.1169 - mse: 2.9299 - val_loss: 6.6957 - val_mae: 1.9134 - val_mse: 6.6957\n",
      "Epoch 944/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.1661 - mae: 1.1556 - mse: 3.1661 - val_loss: 7.4017 - val_mae: 2.0129 - val_mse: 7.4017\n",
      "Epoch 945/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.0774 - mae: 1.1774 - mse: 3.0774 - val_loss: 7.3426 - val_mae: 2.0624 - val_mse: 7.3426\n",
      "Epoch 946/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1020 - mae: 1.1408 - mse: 3.1020 - val_loss: 8.2657 - val_mae: 2.1083 - val_mse: 8.2657\n",
      "Epoch 947/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.0010 - mae: 1.1399 - mse: 3.0010 - val_loss: 7.2995 - val_mae: 2.0828 - val_mse: 7.2995\n",
      "Epoch 948/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2796 - mae: 1.2242 - mse: 3.2796 - val_loss: 7.8605 - val_mae: 2.0580 - val_mse: 7.8605\n",
      "Epoch 949/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.2173 - mae: 1.1873 - mse: 3.2173 - val_loss: 8.5309 - val_mae: 2.1701 - val_mse: 8.5309\n",
      "Epoch 950/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2604 - mae: 1.1634 - mse: 3.2604 - val_loss: 7.1759 - val_mae: 2.0453 - val_mse: 7.1759\n",
      "Epoch 951/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.0599 - mae: 1.1529 - mse: 3.0599 - val_loss: 6.9016 - val_mae: 1.9494 - val_mse: 6.9016\n",
      "Epoch 952/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 2.9755 - mae: 1.1414 - mse: 2.9755 - val_loss: 7.1221 - val_mae: 2.0089 - val_mse: 7.1221\n",
      "Epoch 953/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.1810 - mae: 1.1787 - mse: 3.1810 - val_loss: 7.3446 - val_mae: 2.0738 - val_mse: 7.3446\n",
      "Epoch 954/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0689 - mae: 1.1868 - mse: 3.0689 - val_loss: 6.8155 - val_mae: 1.9911 - val_mse: 6.8155\n",
      "Epoch 955/1000\n",
      "250/250 [==============================] - 0s 56us/sample - loss: 3.0404 - mae: 1.1724 - mse: 3.0404 - val_loss: 7.9987 - val_mae: 2.1140 - val_mse: 7.9987\n",
      "Epoch 956/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.0413 - mae: 1.1347 - mse: 3.0413 - val_loss: 7.5339 - val_mae: 2.0209 - val_mse: 7.5339\n",
      "Epoch 957/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.1735 - mae: 1.1300 - mse: 3.1735 - val_loss: 7.4234 - val_mae: 2.0364 - val_mse: 7.4234\n",
      "Epoch 958/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.0564 - mae: 1.1519 - mse: 3.0564 - val_loss: 7.5266 - val_mae: 2.0622 - val_mse: 7.5266\n",
      "Epoch 959/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0983 - mae: 1.1785 - mse: 3.0983 - val_loss: 8.3297 - val_mae: 2.1261 - val_mse: 8.3297\n",
      "Epoch 960/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 2.9640 - mae: 1.1173 - mse: 2.9640 - val_loss: 6.7886 - val_mae: 1.9489 - val_mse: 6.7886\n",
      "Epoch 961/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.3030 - mae: 1.1765 - mse: 3.3030 - val_loss: 7.6865 - val_mae: 2.0376 - val_mse: 7.6865\n",
      "Epoch 962/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2103 - mae: 1.1561 - mse: 3.2103 - val_loss: 7.4494 - val_mae: 2.0407 - val_mse: 7.4494\n",
      "Epoch 963/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.0903 - mae: 1.1526 - mse: 3.0903 - val_loss: 8.3846 - val_mae: 2.1521 - val_mse: 8.3846\n",
      "Epoch 964/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0379 - mae: 1.1145 - mse: 3.0379 - val_loss: 8.2395 - val_mae: 2.1206 - val_mse: 8.2395\n",
      "Epoch 965/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1903 - mae: 1.1383 - mse: 3.1903 - val_loss: 7.0892 - val_mae: 1.9876 - val_mse: 7.0892\n",
      "Epoch 966/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.0432 - mae: 1.1591 - mse: 3.0432 - val_loss: 7.3141 - val_mae: 2.0479 - val_mse: 7.3141\n",
      "Epoch 967/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2364 - mae: 1.1724 - mse: 3.2364 - val_loss: 7.2495 - val_mae: 1.9867 - val_mse: 7.2495\n",
      "Epoch 968/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.1624 - mae: 1.1651 - mse: 3.1624 - val_loss: 7.4457 - val_mae: 2.0776 - val_mse: 7.4457\n",
      "Epoch 969/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1991 - mae: 1.1792 - mse: 3.1991 - val_loss: 7.9057 - val_mae: 2.1255 - val_mse: 7.9057\n",
      "Epoch 970/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 2.9738 - mae: 1.1134 - mse: 2.9738 - val_loss: 7.9672 - val_mae: 2.1342 - val_mse: 7.9672\n",
      "Epoch 971/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.2275 - mae: 1.1697 - mse: 3.2275 - val_loss: 7.4840 - val_mae: 2.1048 - val_mse: 7.4840\n",
      "Epoch 972/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.0725 - mae: 1.1346 - mse: 3.0725 - val_loss: 7.8510 - val_mae: 2.1018 - val_mse: 7.8510\n",
      "Epoch 973/1000\n",
      "250/250 [==============================] - 0s 72us/sample - loss: 3.1854 - mae: 1.1546 - mse: 3.1854 - val_loss: 8.4511 - val_mae: 2.1443 - val_mse: 8.4511\n",
      "Epoch 974/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1407 - mae: 1.1530 - mse: 3.1407 - val_loss: 7.0778 - val_mae: 1.9728 - val_mse: 7.0778\n",
      "Epoch 975/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 2.8914 - mae: 1.1132 - mse: 2.8914 - val_loss: 6.9448 - val_mae: 2.0030 - val_mse: 6.9448\n",
      "Epoch 976/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 2.9480 - mae: 1.1313 - mse: 2.9480 - val_loss: 6.8079 - val_mae: 1.9735 - val_mse: 6.8079\n",
      "Epoch 977/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0511 - mae: 1.1560 - mse: 3.0511 - val_loss: 7.0122 - val_mae: 1.9875 - val_mse: 7.0122\n",
      "Epoch 978/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0969 - mae: 1.1303 - mse: 3.0969 - val_loss: 7.6049 - val_mae: 2.0647 - val_mse: 7.6049\n",
      "Epoch 979/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.0265 - mae: 1.1416 - mse: 3.0265 - val_loss: 8.5697 - val_mae: 2.1877 - val_mse: 8.5697\n",
      "Epoch 980/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.0042 - mae: 1.1201 - mse: 3.0042 - val_loss: 6.9155 - val_mae: 1.9580 - val_mse: 6.9155\n",
      "Epoch 981/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 2.8978 - mae: 1.1562 - mse: 2.8978 - val_loss: 8.2985 - val_mae: 2.1317 - val_mse: 8.2985\n",
      "Epoch 982/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 3.2803 - mae: 1.1368 - mse: 3.280 - 0s 44us/sample - loss: 3.0816 - mae: 1.1308 - mse: 3.0816 - val_loss: 7.9758 - val_mae: 2.0924 - val_mse: 7.9758\n",
      "Epoch 983/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 3.1390 - mae: 1.1288 - mse: 3.1390 - val_loss: 7.8964 - val_mae: 2.1075 - val_mse: 7.8964\n",
      "Epoch 984/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 2.9139 - mae: 1.1165 - mse: 2.9139 - val_loss: 7.5496 - val_mae: 2.0564 - val_mse: 7.5496\n",
      "Epoch 985/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0229 - mae: 1.1222 - mse: 3.0229 - val_loss: 8.6466 - val_mae: 2.2247 - val_mse: 8.6466\n",
      "Epoch 986/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.2750 - mae: 1.1698 - mse: 3.2750 - val_loss: 7.8423 - val_mae: 2.1331 - val_mse: 7.8423\n",
      "Epoch 987/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.0447 - mae: 1.1407 - mse: 3.0447 - val_loss: 7.9532 - val_mae: 2.0803 - val_mse: 7.9532\n",
      "Epoch 988/1000\n",
      "250/250 [==============================] - 0s 52us/sample - loss: 3.0424 - mae: 1.1256 - mse: 3.0424 - val_loss: 7.2591 - val_mae: 2.0316 - val_mse: 7.2591\n",
      "Epoch 989/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1011 - mae: 1.1793 - mse: 3.1011 - val_loss: 7.9055 - val_mae: 2.1321 - val_mse: 7.9055\n",
      "Epoch 990/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0804 - mae: 1.1269 - mse: 3.0804 - val_loss: 6.9728 - val_mae: 1.9675 - val_mse: 6.9728\n",
      "Epoch 991/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 2.9638 - mae: 1.1007 - mse: 2.9638 - val_loss: 7.4636 - val_mae: 2.0387 - val_mse: 7.4636\n",
      "Epoch 992/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0892 - mae: 1.1593 - mse: 3.0892 - val_loss: 7.0573 - val_mae: 1.9586 - val_mse: 7.0573\n",
      "Epoch 993/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1824 - mae: 1.1842 - mse: 3.1824 - val_loss: 7.7679 - val_mae: 2.0915 - val_mse: 7.7679\n",
      "Epoch 994/1000\n",
      "250/250 [==============================] - 0s 40us/sample - loss: 2.9035 - mae: 1.1306 - mse: 2.9035 - val_loss: 7.1634 - val_mae: 1.9765 - val_mse: 7.1634\n",
      "Epoch 995/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.2000 - mae: 1.1612 - mse: 3.2000 - val_loss: 7.1991 - val_mae: 2.0268 - val_mse: 7.1991\n",
      "Epoch 996/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.0862 - mae: 1.1168 - mse: 3.0862 - val_loss: 7.0371 - val_mae: 1.9830 - val_mse: 7.0371\n",
      "Epoch 997/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.0559 - mae: 1.1074 - mse: 3.0559 - val_loss: 8.1126 - val_mae: 2.1027 - val_mse: 8.1126\n",
      "Epoch 998/1000\n",
      "250/250 [==============================] - 0s 48us/sample - loss: 3.1196 - mae: 1.1659 - mse: 3.1196 - val_loss: 7.0574 - val_mae: 1.9738 - val_mse: 7.0574\n",
      "Epoch 999/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1151 - mae: 1.1396 - mse: 3.1151 - val_loss: 7.8617 - val_mae: 2.0871 - val_mse: 7.8617\n",
      "Epoch 1000/1000\n",
      "250/250 [==============================] - 0s 44us/sample - loss: 3.1860 - mae: 1.1640 - mse: 3.1860 - val_loss: 7.0312 - val_mae: 1.9915 - val_mse: 7.0312\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "### START CODING HERE ### \n",
    "# fit nn_reg1 on X_train, y_train, epochs=EPOCHS, validation_split=0.2, verbose=1\n",
    "nn_reg1_history = nn_reg1.fit(X_train, y_train, epochs=EPOCHS, validation_split=0.2, verbose=1)\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "79/79 - 0s - loss: 6.5014 - mae: 1.8273 - mse: 6.5014\n",
      "Testing set Mean Abs Error:  1.83 MPG\n"
     ]
    }
   ],
   "source": [
    "### START CODING HERE ### \n",
    "# Evaluate nn_reg1 using .evaluate() method on X_test, y_test and verbose=2\n",
    "loss1, mae1, mse1 = nn_reg1.evaluate(X_test, y_test, verbose=2)\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3.086180</td>\n",
       "      <td>1.116782</td>\n",
       "      <td>3.086180</td>\n",
       "      <td>7.037119</td>\n",
       "      <td>1.982971</td>\n",
       "      <td>7.037119</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3.055885</td>\n",
       "      <td>1.107350</td>\n",
       "      <td>3.055885</td>\n",
       "      <td>8.112583</td>\n",
       "      <td>2.102671</td>\n",
       "      <td>8.112583</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3.119614</td>\n",
       "      <td>1.165912</td>\n",
       "      <td>3.119615</td>\n",
       "      <td>7.057411</td>\n",
       "      <td>1.973811</td>\n",
       "      <td>7.057411</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3.115137</td>\n",
       "      <td>1.139583</td>\n",
       "      <td>3.115137</td>\n",
       "      <td>7.861722</td>\n",
       "      <td>2.087122</td>\n",
       "      <td>7.861722</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3.186033</td>\n",
       "      <td>1.163986</td>\n",
       "      <td>3.186034</td>\n",
       "      <td>7.031176</td>\n",
       "      <td>1.991511</td>\n",
       "      <td>7.031176</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       mae       mse  val_loss   val_mae   val_mse  epoch\n",
       "995  3.086180  1.116782  3.086180  7.037119  1.982971  7.037119    995\n",
       "996  3.055885  1.107350  3.055885  8.112583  2.102671  8.112583    996\n",
       "997  3.119614  1.165912  3.119615  7.057411  1.973811  7.057411    997\n",
       "998  3.115137  1.139583  3.115137  7.861722  2.087122  7.861722    998\n",
       "999  3.186033  1.163986  3.186034  7.031176  1.991511  7.031176    999"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your numbers might be a little different due to the randomness!\n",
    "hist1 = pd.DataFrame(nn_reg1_history.history)\n",
    "hist1['epoch'] = nn_reg1_history.epoch\n",
    "hist1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your plots might be slightly different, i.e. they should look very similar to the plots below!\n",
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [MPG]')\n",
    "  plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,5])\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_history(nn_reg1_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based on the above plots, it looks like that there is not too much improvement after around 100 epochs. Later when we study Chapter 11, you will learn that there is a technique called `EarlyStopping` that can be used here which stops training if there is not much improvement after a fixed number of epochs. Moreover for now, you should fine-tune the hyperparameters of the network to see if you can see any improvements. Report the results of your hyperparameter tuning in the following cell. This is what's called <b>Grid Search</b> in hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODING HERE ### \n",
    "# Build another regression neural network with the same architecture,\n",
    "# but you later compile it with different hyperparameters\n",
    "nn_reg2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=[len(X_train.keys())], activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "# Fine-tune the optimizer as follows:\n",
    "# First, try a different optimizer - SGD with the learning_rate = 0.001\n",
    "# Then, switch optimizer to Adam,\n",
    "# and use three different values of learning_rate in the order of 10 or 10^(-1) like 0.01, 0.1 and 1.\n",
    "# You may try other values for learning_rate.\n",
    "# Report the results of your hyperparameter tuning in the following cell.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = .001)\n",
    "\n",
    "# Compile nn_reg2 with loss='mae', optimizer=optimizer and metrics=['mae', 'mse']\n",
    "nn_reg2.compile(optimizer=optimizer, loss='mae', metrics=['mae','mse'])\n",
    "\n",
    "# Fit nn_reg2 on X_train, y_train, epochs=EPOCHS, validation_split=0.2, verbose=0\n",
    "nn_reg2_history = nn_reg2.fit(X_train, y_train, epochs=EPOCHS, validation_split=0.2, verbose=0)\n",
    "### END CODING HERE ###\n",
    "\n",
    "plot_history(nn_reg2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "79/79 - 0s - loss: 1.6796 - mae: 1.6796 - mse: 6.1643\n",
      "Testing set Mean Abs Error:  1.68 MPG\n"
     ]
    }
   ],
   "source": [
    "### START CODING HERE ### \n",
    "# Evaluate nn_reg2 using .evaluate() method on X_test, y_test and verbose=2\n",
    "loss2, mae2, mse2 = nn_reg2.evaluate(X_test, y_test, verbose=2)\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the results of your hyperparameter tuning HERE:\n",
    "\n",
    "SGD - Testing Set mae: 1.68 MPG\n",
    "<br>\n",
    "Adam learning_rate 0.01 - Testing Set mae: 1.97 MPG\n",
    "<br>\n",
    "Adam learning_rate 0.1 - Testing Set mae: 2.08 MPG\n",
    "<br>\n",
    "Adam learning_rate 1.0 - Testing Set mae: 5.81 MPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can check the quality of the model predictions by the following plot. Use this plot to answer Part II Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the best hyperparameters you found for compiling nn_reg2, then run this cell\n",
    "nn_reg2_preds = nn_reg2.predict(X_test).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(y_test, nn_reg2_preds)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "lims = [0, 50]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ANSWER THE FOLLOWING QUESTIONS HERE:</b>\n",
    "\n",
    "Q1- How do you interprete the plot above in terms of the model performance (Predictions vs True Values)? GIVE COMPLETE ANSWER!\n",
    "\n",
    "The plot of Predicted vs True values is close to a 1:1. This indicates that the model is performing well because it is predicting realistic values.\n",
    "\n",
    "Q2 - How do you interprete the first regression model's plots of mse and mae, i.e. `plot_history(nn_reg1_history)`? What is the impact of choosing `mse` vs `mae`? Why the axis scales are different for `mse` and `mae`? GIVE COMPLETE ANSWER!\n",
    "\n",
    "The first model's plots of mse and mae indicate that as the number of Epochs increases, there is diminished improvement to the error. After 100 or so Epochs the error can actually increase as the model overfits. Both MSE and MAE can visualize this, but MSE makes the changes in error more dramatic because they are squared. This is also why the MSE axis is larger than MAE, the squared values result in larger numbers.\n",
    "\n",
    "Q3 - What is the role of `validation_split` hyperparameter in `fit` method? What does it change exactly and why is it used? GIVE COMPLETE ANSWER!\n",
    "\n",
    "The validation_split hyperparameter declares how large of a portion of the data will be reserved for validation. It is the portion of data that will be used to evaluate the loss at the end of each Epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Part III - <font color=green>Extra Credit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Notice:</b> This part is totally optional and for earning <b><font color=green>extra credit</font></b> in the \"Assignment\" section of your final grade. Attempt this part only if you have enough time and you're inclined to challenge yourself a bit!<br>\n",
    "\n",
    "[Download the video games dataset](https://raw.githubusercontent.com/fereydoonvafaei/UMBC-CMSC-478-Fall-2019/master/Assignment-4/video.csv)<br> \n",
    "\n",
    "You can read about the data [here](https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings). <br>\n",
    "\n",
    "Build a neural network that can predict the \"<b>Rating</b>\" of each game based on other features. Alternatively, you may predict either the global sales or regional sales (in North America, Europe, etc) for each row/video game. Perform any necessary preprocessing steps needed on the dataset. <br>\n",
    "\n",
    "You should create a separate notebook for Extra Credit attempt and submit it via a separate link in Blackboard. If you can get good results based on the instructor's judgement of your work, you may earn up to 50 points of extra credit for A5 that can be used for the missing points of \"Assignment\" section of your final grade.<br>\n",
    "\n",
    "<b>Note:</b> Extra credits for A5 can only be used to compensate for \"Assignment\" section NOT for any other sections of the final grade such as quizzes or exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16719, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
       "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
       "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
       "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
       "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
       "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "1           NaN        NaN         NaN       NaN    NaN  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "4           NaN        NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data = pd.read_csv('video.csv')\n",
    "print(video_data.shape)\n",
    "video_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Super Mario Bros.</td>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii Play</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Platform  Year_of_Release     Genre Publisher  \\\n",
       "0             Wii Sports      Wii           2006.0    Sports  Nintendo   \n",
       "2         Mario Kart Wii      Wii           2008.0    Racing  Nintendo   \n",
       "3      Wii Sports Resort      Wii           2009.0    Sports  Nintendo   \n",
       "6  New Super Mario Bros.       DS           2006.0  Platform  Nintendo   \n",
       "7               Wii Play      Wii           2006.0      Misc  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "6     11.28      9.14      6.50         2.88         29.80          89.0   \n",
       "7     13.96      9.18      2.93         2.84         28.92          58.0   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "6          65.0        8.5       431.0  Nintendo      E  \n",
       "7          41.0        6.6       129.0  Nintendo      E  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data.dropna(inplace=True)\n",
    "print(video_data.shape)\n",
    "video_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "For Assignment 5, your notebook will be run and graded with a maximum of 100 points. Make sure that you get the correct outputs for all cells that you implement and answer ALL questions COMPLETELY. Also, your notebook should be written with no grammatical and spelling errors and should be nicely-formatted and easy-to-read.\n",
    "\n",
    "The breakdown of the 100 points is as follows:\n",
    "\n",
    "Part I implementaion has 40 points:\n",
    "- 10 points: preprocessing steps.\n",
    "- 15 points: nn_clf implementation, and compile.\n",
    "- 15 points: correct ROC curve for nn_clf.\n",
    "\n",
    "Part I questions have 10 points (5 points each).\n",
    "\n",
    "Part II implementaion has 35 points:\n",
    "- 10 points: preprocessing steps.\n",
    "- 10 points: nn_reg1 implementation, and compile.\n",
    "- 15 points: nn_reg2 implementation, and compile including hyperparameter tuning.\n",
    "\n",
    "Part II questions have 15 points (5 points each).\n",
    "\n",
    "Part III is optional and for Extra Credit only - up to 50 extra points based on the quality of your work.\n",
    "\n",
    "Follow the instructions of each section carefully. Up to 10 points may be deducted if your submitted notebook is not easy to read and follow or if it has grammatical and spelling errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Submit and Due Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-A5.ipynb```. Submit the file using the ```Assignment-5``` link on Blackboard.\n",
    "\n",
    "If you attempt the Extra Credit in Part III, create a separate notebook including all the necessary code, name it `Lastname-A5-EC.ipynb` and submit it using the ```A5-Extra-Credit``` link on Blackboard.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * correct implementation, correct answer to the questions, and\n",
    "  * readability of the notebook.\n",
    "  \n",
    "<font color=red><b>Due Date: Monday December 2nd 11:59PM.</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
