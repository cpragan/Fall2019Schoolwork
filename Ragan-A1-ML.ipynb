{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC478 Machine Learning\n",
    "\n",
    "# Assignment-1: Binary Classification and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Connor Ragan AN72374* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your first ML assignment! So far, you've learned about the basic and fundamental concepts in Machine Learning such as supervised learning (e.g. classification) vs unsupervised learning (clustering), regression, overfitting, and model evaluation. You learned that one of the most common approaches in supervised learning is classification and regression. In this assignment, you are going to build and train a classification model for diagnosing breast cancer, as well as a regression model and how it is impacted by overfitting.\n",
    "\n",
    "Pedagogically, this assignment will help you:\n",
    "- better understand the concepts you learned and how to use ML models in pratice. \n",
    "- brush up your Python skills - and possibly learn a couple of new \"Pythonic\" tricks!\n",
    "- pratice reading documentation. This is a very important skill in AI/ML/Data Science collaborative environments and teams.\n",
    "\n",
    "So, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification means you are classifying only two classes/labels. You are going to build a binary classifier that can classify breats cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is importing the breast cancer data set from scikit learn. It is one of the datasets that scikit learn provides for practicing machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset by calling the related function from what you just imported\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what is the type of the variable `data` which holds our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Bunch` is a container object for datasets. It works like a [dictionary data structure in Python](https://docs.python.org/3/tutorial/datastructures.html#dictionaries). Since this is a classification (supervised learning) ML model, you have bothe the data and the labels for training and testing, and everything has been stored in `data` variable. We can extract features and labels from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize our data\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "0\n",
      "mean radius\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "print(label_names)\n",
    "print(labels[0])\n",
    "print(feature_names[0])\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two classes (aka labels) here are `malignant` and `benign` which refers to the tumors you are going to classify. They are represented in the labels as 0 and 1 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the lectures, the data for supervised learning (both classification and regression) is split into training set and test set. We do this by importing another module from scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can split the data. The split ratio we are going to choose is 0.7 for training and 0.3 for testing, but we only need to specify one of them `test_size` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we can now choose which classifier from the built-in classifiers in sklearn we want to choose. We are going to choose Stochastic Gradient Descent Classifier (SGDC) similar to what we did in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the following cell checking how you should do it from the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=42000, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "\n",
    "# Call SGDClassifier with a random_state of 42\n",
    "sgd_clf = SGDClassifier(random_state=42000)\n",
    "\n",
    "# Fit the model to train and train_labels\n",
    "sgd_clf.fit(train, train_labels)\n",
    "\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, make predictions with the model you just trained on test and store the results in test_predictions\n",
    "\n",
    "### START CODING HERE ###\n",
    "test_predictions = sgd_clf.predict(test)\n",
    "### START CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions HERE: \n",
    "\n",
    "Q1 - What is the data type of test_pred? Add a new cell above this and type your code, and then type your answer here.\n",
    "\n",
    "test_pred is type numpy.ndarray\n",
    "\n",
    "Q2 - What is the shape of your test_pred? Why? Add another cell above this and type your code to get the answer and then explain your answer here.\n",
    "\n",
    "The shape is one-dimensional with 171 elements, because it is just the model's predictions about each individual data point in test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86746988 0.31325301 0.48192771]\n"
     ]
    }
   ],
   "source": [
    "### START CODING HERE ###\n",
    "\n",
    "# Import the necessary module from sklearn for accuracy_score and \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# compute the accuracy, store it in acc variable\n",
    "acc = cross_val_score(sgd_clf, train, train_labels, cv=3, scoring=\"recall\")\n",
    "\n",
    "# Print the accuracy \n",
    "print(acc)\n",
    "\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions HERE:\n",
    "\n",
    "Q3 - What is your accuracy in %? \n",
    "\n",
    "Above 77%\n",
    "\n",
    "Q4 - Change your accuracy to precision and type the result here.\n",
    "\n",
    "Above 90%\n",
    "\n",
    "Q5 - Change the precision to recall and type the results here.\n",
    "\n",
    "Above 65%\n",
    "\n",
    "Q6 - Compare precision and recall. Which one do you think is more important in cancer diagnosis?\n",
    "\n",
    "Precision is how well the model identifies a positive and does not give false positives. Recall is how well the model identifies positives and does not miss any. Recall is more important in cancer diagnosis because the consequences of missing something are far worse (could be death) than the consequences of incorrectly labeling something as cancerous (likely just stressful to the patient until obtaining a second opinion.  \n",
    "\n",
    "Q7 - Change the random_state of your classifier and try three different values. Compare and discuss your results. Can you improve the accuracy by changing that parameter? Can you improve the recall without affecting precision? Explain! \n",
    "\n",
    "random_state = 420\n",
    "accuracy above 84%\n",
    "precision above 80%\n",
    "recall above 80%\n",
    "\n",
    "random_state = 4200\n",
    "accuracy above 83%\n",
    "precision above 92%\n",
    "recall above 77%\n",
    "\n",
    "random_state = 42000\n",
    "accuracy above 57%\n",
    "precision above 91%\n",
    "recall above 31%\n",
    "\n",
    "Changing the random_state can affect accuracy, precision, and recall as the above shows. You cannot improve either recall or precision without negatively affecting the other measure. This is because your model will favor one type of error over another (either false positives or false negatives) which precision and recall are measures of. They are inversely related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Regression and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to display how overfitting occurs in regression. First, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "degrees = [1, 4, 15]\n",
    "\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n",
    "                                             include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, X[:, np.newaxis], y,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
    "        degrees[i], -scores.mean(), scores.std()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions HERE:\n",
    "\n",
    "Q1 - How do you compare the three plots above? \n",
    "\n",
    "Mean Squared Area for the plots can be compared to see that the center plot is the closest to the data. \n",
    "\n",
    "Q2 - Which one has overfitting? Why?\n",
    "\n",
    "The last plot has overfitting, because you can see that the samples lie on or near the model, but you can also see that the model in it's entirety is dramatically far from the true function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "For assignment 1, your notebook will be run and graded manually with a maximum of 100 points. Make sure that you get the desired outputs for all cells that you implemented. Also, your notebook should be written with no grammatical and spelling errors and should be nicely-formatted and easy-to-read.\n",
    "\n",
    "The breakdown of the 100 points is as follows:\n",
    "\n",
    "Part I has 80 points:\n",
    "- 45 points: correct implementation\n",
    "- 35 points: correct answers to 7 questions\n",
    "\n",
    "Part II has 10 points:\n",
    "\n",
    "The remaining 10 points will be based on your writing and formatting as instructed in the notebook.  Follow the instructions of each section carefully. Points will be deducted if your submitted notebook is not easy to read and follow or if it has grammatical and spelling errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
